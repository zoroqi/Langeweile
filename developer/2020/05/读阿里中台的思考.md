# 读阿里中台的思考

最近闲着无聊看到\<企业IT架构转型之道:阿里巴巴中台战略思想与架构实战\>这本书决定看一下, 读完结论是前三分之一可以可以看看知道为啥阿里的技术架构的演变和为什么会产生中台架构, 简单总结是一种单个服务过于庞杂的一种迫不得已. 后三分之二是一些实际问题的通用解决方案, 包括服务治理, 数据库事务, 流程优化, 监控, 预警, 审计, 当然这些都是基于中台进行的解释.

内容很详实建议直接看希望的部分, 书很薄通读大概只需要8个小时左右, 全看懂就不一定了.

非技术上的重点, 而且这个点比技术要重要很多, 就是淘宝(阿里)的共享平台(中台)建设得到了非技术的管理层的强有力保障, 防止多个团队重复建设. 书中介绍在淘宝和天猫刚分割成两个平台的时候提出了共享平台,但中台资源不足加上团队主要是淘宝团队, 最后导致平台建设了但没啥用, 淘宝和天猫还是建设了很多重复的东西, 因为中台没有提到足够的支撑. 最后在聚划算的机缘下把中台强推广出来的, 淘宝和天猫要接入聚划算必须通过共享平台, 不可以直接接入聚划算, 而这是行政命令. 从单个开发角度来讲这丫就是有病, 何必扰一步这多麻烦, 直接接入多快, 但从更高的角度(管理和技术)来看这是都是一种重复建设, 是一种浪费, 代码冗余度变大, 维护成本骤增. 这里看出[康威定律](https://zh.wikipedia.org/zh-hans/%E5%BA%B7%E5%A8%81%E5%AE%9A%E5%BE%8B)还是很管用的

从更高的理论出发建议读一下[DDD](https://zh.wikipedia.org/wiki/%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91)的两本著作\<实现领域驱动设计\>和\<领域驱动设计:软件核心复杂性应对之道\>, 阿里的中台对这两本书的最好体现.

阿里的中台全称应该是叫做"**业务**中台", 重音要落在业务上, 核心也是业务. 中台建设核心是对业务沉淀, 采用需求\-\>开发\-\>运营\-\>需求的循环式, 而运营是很重要的一环, 系统不能建设一次就进入了运维期, 要不断的将业务固化到系统内, 并可以将业务能力对外输出. 而这里可以参考一个叫做[Kaizen](https://zh.wikipedia.org/wiki/%E6%94%B9%E5%96%84%E6%B3%95), 的一种管理办法将所有可以固化到代码的东西都尽量固化下来[标注2], 一种持续的改进. 阿里的技术中间件只能叫中间件而不叫中台, 因为没有公司具体的业务, 更多的一种通用解决方案, 对中台提供更具体更稳定的支撑.

中台更倾向于一种生产线的东西, 减少人的操作或让人的操作固定化的一种模式. 中台不是一次性的建设而是一个循环, 生产线是一个持续优化的东西, 为了做到**六标准偏差**不得不进行持续优化, 重复建设是不现实只能采用一种持续方案, 发现的任何问题和优化点都最终落实在成产流程上, 而不是一个表面东西. 中台建设也是相同的, 将运营的想法, 业务创新点, 业务模型, 都要通过代码, 数据, 文档固化下来, 不能让这些知识始终保留在那几个人脑中. (浓浓压榨味道)

对个人开发来说没必要思考这种东西, 这还是让架构去想吧. 针对代码来说做好模块化和分层化, 坚持"单一职责原则"和"高内聚低耦合"进行代码设计, 这两句话是一种平衡的状态, 实际控制好这两句话并不容易. 在任何时候可以快速应对服务拆分就是最好的, 做好持续代码优化(性能和结构). 多看新框架, 从中找到偷懒的实现方式, 新的设计方式和更好的通用解决方案.

## 标注
1. 我的感受是,**最大的浪费不是重复建设,而是不断重复建设.**在早期往往一个新业务的上线除了**数据可以被重复使用之外,服务却不能被重复使用.**其实服务的重用将比数据重用带来更多好处,数据只是原始生产资料,服务则包含逻辑,是工厂的加工车间,如果加工过程也一样可以复制,将带来生产效率的大幅度提升.
2. **系统的建设要从生产型模型升级到运营型模型,从版本模型升级到迭代模型.运营型模型最大的优势是所有的积累都被沉淀,而生产型模型会因为10%的差异而重新建设100%的系统.每次都是新的故事,新的逻辑,新的代码,而这些都来自几个人的脑子.运营型模型的逻辑则来自于无数客户,供应商,工程师的的脑子,并经过不断的积累,那么差距就显而易见.**
3. 本章从阿里巴巴为何启动中台战略说起,谈到阿里巴巴共享业务事业部从建立,摸索及系列演变,到最终成为阿里巴巴业务中台战略中核心组成部分的过程.深入分析阿里巴巴共享业务事业部发展历程中所遇到的一系列问题和困境,而这些问题也恰恰是当今很多传统企业信息系统建设过程中所遇到的问题,找出这些问题的症结是根治这些问题的必修课.
4. 笔者对Supercell模式的理解是这家游戏公司经过6年的时间将游戏开发过程中公共,通用的游戏开发素材,算法做了很好的沉淀,企业的文化充分鼓励员工进行创新,甚至进行试错,才使得他们在开发的众多游戏中以最快时间找到那些用户真正喜爱的游戏.
5. 正是因为以上两大问题,在2009年,共享业务事业部应运而生,主要成员来自于之前的淘宝技术团队,在组织架构上单独成为一个跟淘宝,天猫同样级别的事业部(图1-1右二),集团希望以这样的方式更好地让技术团队同时支持淘宝和天猫的业务,同时也将两套电商的业务做了梳理和沉淀,将两个平台中公共的,通用的业务功能沉淀到了共享业务事业部,避免有些功能的重复建设和维护,更合理地利用技术资源.
6. 这时就出现了对于共享业务事业部历史转折点的一个举措,集团要求三大电商平台如果要与聚划算平台进行业务对接,必须通过共享业务事业部!正是有了这"点睛之指",使得共享业务事业部有了一个极强的业务抓手,将原本与三大电商的业务对话权不平衡的天平拉到一个相对公平的水平(图1-2下左)
    * 这就不是服务架构问题,康维定律依旧有用
7. 在电商平台上有过购物经历的读者都能想到,一个标准的电商平台至少提供了会员服务,商品的信息,交易支付,不管是B2B,C2C或者B2C的电商平台都需要提供,为什么阿里巴巴的三大电商平台会独立建设和维护,这其中没有任何公共和通用的功能吗?
8. 我想导致这种建设模式的因素有很多,个人认为其中主要原因是开发团队考虑到电商模式的不同,所以需要独立建设;或者是新的业务团队认为在之前的电商平台基础上改造成支持新模式的电商平台会有太多的技术和业务的历史包袱,还不如重新构建.
9. 其实对于"烟囱式"系统建设带来的弊端在十年前就已经有人提出,以这样的方式建设系统对企业的"伤害"有三大弊端: 1)重复功能建设和维护带来的重复投资.大家都不用太仔细去梳理这些"烟囱式"建设起来的系统,就能发现大量的功能和业务在多个系统中同时存在,单单从开发和运维两方面成本投入的角度,对于企业来说就是一种很显性的成本和资源浪费.但这一点对企业带来的伤害却是最小的,只是成本的损失.
10. 2)打通"烟囱式"系统间交互的集成和协作成本高昂.
11. 3)不利于业务的沉淀和持续发展.从传统IT系统建设的生命周期来看,一旦系统上线以后,就进入了运维阶段.在运维阶段,也会有对系统功能完善和新业务需求的升级;因此我们看到了平均周期均在几个月,甚至半年进行一次功能的升级.
12. 面对这样的业务需求和系统处境,业界早在十几年前就提出了SOA的理念,出现了各大厂商纷纷推出了各自的ESB产品及解决方案,重点就是来解决此类异构系统之间交互的问题.一时间,各大企业纷纷上马SOA项目,构建企业服务总线,基于服务的方式实现了这些"烟囱"间交互的问题.
13. 上面提到很多企业通过ESB系统很好地实现了多个独立系统间的打通,不可否认ESB的架构很好地屏蔽了服务接口变化给服务消费者带来的影响,是解决不同系统间实现互联互通的很好的架构,但这样的项目在企业中落地后,后面的发展就让SOA价值的体现出现本末倒置的现象!
14. 企业实施SOA集成项目上线后,各个系统按照标准封装的这些"服务"就进入一个"稳定"状态.这里的"稳定"当然不是指服务运行的稳定,而是这些服务对外提供的功能变得"稳定",也就是说,很多服务在初次上线后,在接下来几年的时间里就几乎没有新的服务功能的增加或提升.
15. **产生这种现象的根本原因就要追溯到企业实施SOA的方式,典型的项目实施模式,在确定了贯穿多个系统的主业务流程后,就要求各个相关的系统进行服务的封装和改造,这种模式就是典型的"自顶向下"的建设模式,而这个时候,各个需要提供服务封装和改造的系统无不均属于各自的运维期,对于服务开发相关的工作,运维人员的心态往往是协助和配合,并且多数情况下这些服务封装的工作跟运维人员自身的KPI考核是没有多大关系的.正是基于这样的背景,我们很少看到在功能性和扩展性方面做得足够好的服务.另一个更严重的问题则是当此期SOA成功实施结束后,后续有新的业务系统希望接入这些服务,而新的业务系统又发现现有的服务不能很好地满足他们的要求,希望提供更多功能或更好体验的服务要求时,在现实中就会出现下面两种情况:**
16. **1)服务提供者团队不管是从KPI考核的角度,还是从认知上认为服务封装的任务已经完成,所以当他们收到新的服务需求时,心理上是拒绝的,会出于多一事不如少一事的心态,告诉新业务系统的需求方:"我们目前仅能提供这样的服务",导致最终的结果是新业务系统认为该服务不可用,逼着他们在自己的系统中重新又实现了一套跟这个服务差不多的功能模块,也就是产生了一个新的烟囱. 2)服务提供者团队拥有不错做事的态度,也愿意改造服务以满足新业务的需求,但受限于之前服务设计时的通用性和业务前瞻性的不足,造成如果要满足新业务的需求,就要对现有服务的数据模型,业务逻辑做较大的改造,在改造带来的风险和满足新业务需求的选择中,更多的团队选择了放弃对新业务需求的支持,而保持现有服务提供的稳定,其结果跟第一种情况完全一样.**
17. 不管是传统项目建设方式带来业务迭代能力的不足,还是现有企业内SOA"项目制"建设的效果最终导致三个弊端,而其中第三个弊端"IT系统建设中实现的业务得不到沉淀和持续发展"是对企业伤害最大的.
18. 且不论这样推倒式重建对于现有业务带来影响的大小,多少基础功能的重复建设和资源投入,更重要的是对于之前多年业务的沉淀能保留多少,这对于企业来说可能是最大的资产流失
19. 但我所说的懂业务是指,能对业务的下一步发展有着自己的理解和看法,对业务流程如何进一步优化能更好地提升业务,甚至对企业现有的业务提出创新的想法,为企业带来新的业务增长点.
20. 回归SOA的本质——服务重用
21. 服务不需要"业务稳定",而需要不停的滋养,只有在滋养中才能从最初仅提供单薄业务功能的服务逐渐成长为企业最为宝贵的IT资产,而服务所需的滋养正是来自新的业务不断进行服务的接入.
22. 而我想说的是,服务最不需要"业务稳定"!一个服务如果一味追求功能的不变,一定程度上就是固步自封,这样的做法是在逼着其他系统去建同样的"轮子",当越来越多的系统都采用自建"轮子"的方式满足自身系统对这部分业务的需求时,之前的这个服务慢慢就少有人问津,当有更好的服务出现或该服务完全满足不了当前业务发展的要求时,也就是这个服务离开历史舞台的时刻.
23. 关于创新,我想说这不是一件容易的事情,而且企业真正需要的创新一定是来自于企业内部,而不会由外面所谓的专家告诉你如何创新.经常看到有些公司或专业人士拿着国外同行业公司或从搜索平台上搜索到的一些新概念和架构,就正儿八经地在企业面前大谈特谈如何进行业务转型和创新,我觉得这样的人是不负责任的,因为创新是没有定式的,如果把在其他企业身上证明是好的创新搬到这家企业身上,可能效果完全不一样,而且这样的做法也失去了创新中的"新"字,一件新事物或模式的产生可以称其为创新,同样干这事的第二个就很难再用创新形容了.
24. 试想一下,如果之前有一个好的业务想法,从头到尾建设所需的资源投入可能是20个人,4个月的时间,还有可能建设的系统达不到预期的市场效果,那这样一个典型的业务试错的成本是非常高昂的,任何一个企业都很难支持这样的试错方式.如果企业打造了很好的业务中台,可以让3个人基于中台提供的核心服务在2周的时间内就能建设一个系统并推向市场,看看市场的反馈来决定是否加大对这个新业务的投入,我想任何一家企业的领导都是很乐意做这样的投入和尝试的.
    * 小公司不现实
25. 团队协同效率最高.相比于一个几十人,上百人的团队完成一项任务,几个人之间的协同成本一定是最低的.科学证明,人数是7个人的团队协同效率是最高的.当团队进行作战时,最短时间内达成意见的统一和行动步调的一致,是团队强大战斗力充分展现的必要条件.
26. 以上介绍的中台阵型对于业务快速创新和业务试错的最有代表性的一个事例要属阿里巴巴的团购业务.在2010年,随着当时市场上团购业务的蓬勃发展,阿里巴巴集团也决定构建自己的团购平台,当时在市场上早已经有了如美团,高朋等专业的团购网站,这一个新兴的业务模式,对阿里巴巴公司来说某种程度上也是一种尝试,所以当时阿里巴巴投入了包含产品经理,运营,开发的十几名员工进行基于淘宝和天猫商品的团购平台的建设,最终这个团购平台在1个半月后就成功上线! 其他同类型的团购平台建设所投入的研发资源可能是阿里投入资源的几十倍,上线时间可能是阿里上线准备时间的好几倍,为什么会产生这样大的资源悬殊?最大的功劳就来自于已经正常运转两年的阿里共享服务体系.原本精心沉淀和打造的用户中心,商品中心,交易中心,评价中心等服务能力在其中都扮演了非常重要的角色,正因为利用了这些原本已经建设好的专业服务,使得阿里巴巴在投入如此少的人力资源和时间的情况下收获了其他公司数倍,甚至几十倍资源投入产出的结果
27. 在这样的一个组织中,最为核心的角色就是业务架构师,在阿里巴巴共享服务各服务中心的业务负责人一般为此角色,业务架构师的能力模型正是那种典型的即懂技术,也对负责的业务领域有相当理解的.这些架构师一般是从技术开发出身,在多年业务领域的需求浸染中,不断形成了对该业务全面的知识体系以及自身的理解,对该业务在集团内的职能定位,市场发展趋势都有一定的全局认识,能从业务的视角带领团队朝着服务中心的核心能力打造,专业,成熟的方向前进.
28. 去中心化"服务架构成为今天绝大多数互联网平台所采用的服务框架.
29. 当时SOA的理念已经在业界非常风行,其中以传统软件厂商提出的以ESB(企业服务总线)实现SOA的方案为主流,这也是为什么几乎所有传统企业的客户都认为ESB是SOA理念的最佳实践,甚至是唯一的实现.这是一种"中心化"服务框架.
30. 回顾一下SOA的主要特性: ·面向服务的分布式计算. ·服务间松散耦合. ·支持服务的组装. ·服务注册和自动发现. ·以服务契约方式定义服务交互方式.
31. 2."雪崩"效应束缚了"中心化"服务框架的扩展能力
32. 1.服务调用方式的不同带来业务的响应和扩展成本
33. 集成了HSF服务框架对服务提供者或服务调用者进行配置服务器发现,服务注册,订阅,失效转移等相关功能,
34. ·地址服务器.在HSF服务框架中肩负着给服务提供者和服务调用者提供部署环境中所有配置服务器和Diamond服务器的服务器列表信息,是由Nginx(是一个高性能的HTTP和反向代理服务器)提供该服务能力.在部署HSF服务环境时,会将整个环境中的配置服务器集群(服务器IP列表)和Diamond服务器集群信息设置在地址服务器上,在实际生产部署中,也会部署多台地址服务器提供负载均衡和高可用性的服务,服务提供者和调用者通过统一域名(比如"xxx.tbsite.net")的方式访问这些地址服务器,通过DNS轮询,实现地址服务器访问的高可用性.
35. ·配置服务器.配置服务器主要负责记录环境内所有服务发布(服务提供者的IP地址和服务端口信息)和服务订阅(服务调用者的IP地址和服务端口信息)信息,并将服务相关信息推送到服务节点上.为了追求服务发布和订阅的推送效率,所有的服务发布和订阅信息均是保存在内存中.
36. 我个人比较赞同Martin Fowler[1]对于微服务架构的典型特征的描述: ·分布式服务组成的系统. ·按照业务而不是技术来划分组织. ·做有生命的产品而不是项目. ·智能化服务端点与傻瓜式服务编排. ·自动化运维. ·系统容错. ·服务快速演化.
37. ·智能化服务端点与傻瓜式服务编排.更加强调了能力向服务端的迁移,而不是像传统ESB的方式,将整体服务架构中的所有核心能力都运行在ESB上.
38. 笔者认为"微服务"中的这个"微"字给很多人带来了很多误解.从字面意思上,"微"会让人联想到一个微服务就应该是功能足够单一,甚至出现一个服务的实现可能只需要几十或者上百行代码的说法,这应该是最误导人的观点.从技术角度出发,确实可以通过简短的代码实现功能单一的服务,但从一个整体架构考虑,如果是以这样的方式实现各个微服务,则在整个服务体系范畴当中包含太多功能边界,那么对于服务运营的分工和边界就很难界定,给服务接下来的持续运营和维护带来困扰;另外拆分过于细化的服务,势必将带来大量无谓的分布式事务调用,给业务的实现带来额外的工作量和风险.
39. ·微服务化的应用架构如何进行有效的服务管控.在分布式服务体系下,服务链路跟踪,链路分析,实时业务指标的监控等问题,也都是实现微服务架构时一定会面临的问题,扩大到更大范围就是整体服务平台的管控能力.
40. 而这些远不是单单的Docker平台能解决的问题:
41. ·分布式事务难题.服务化后的应用如何解决随之而来的分布式事务问题,一定需要针对业务的需求在事务一致性和性能间做好平衡,一套稳定,成熟的分布式事务解决方案也是构建微服务架构首先要思考好的技术方向问题
42. ·自动化运维和平台稳定性.微服务架
43. ·微服务的服务设计.微服务中服务边界的划分一定是从业务的维度,以什么样的服务颗粒度定义服务?以什么样数据模型支撑服务能力的线性扩展?如何保持设计出的服务具有很好的业务前瞻性?
44. 一般来说,服务能力包括两个层次,一个层次是底层PaaS的能力,PaaS层解决大型架构在分布式,可靠性,可用性,容错,监控以及运维层面上的通用需求;第二个层次是业务能力,业务服务能力提供云化的核心业务支撑能力,这层能力建设的好与坏,直接决定了是否能真正支持上层业务达到敏捷,稳定,高效.
45. 共享服务中心的架构目的是通过业务拆分来降低系统的复杂性;通过服务共享来提供可重用性;通过服务化来达到业务支持的敏捷性;通过统一的数据架构来消除数据交互的屏障.
46. 从运营层面来看,服务中心应该是一个完整的业务模型,要有数据运营和业务整合的价值,前面在介绍淘宝的服务中心时,一直在强调服务中心的发展变化性和可运营性,比如淘宝的商品中心,绝对不只是简单的商品增删改查的服务接口,而是建立一个全球最大的商品库,同时提供该商品库的管理运营的方法和配套工具服务.
47. **总体上,我们从这三个维度出发来决定服务中心的设计和评估.下面我们具体介绍在实际项目中总结的一些基本原则.**
    1. **高内聚,低耦合原则** 这是系统设计一开始就会强调的一个基本原则,不过很多时候在实践中我们都在不知不觉中就违背了这个原则.高内聚是从服务中心的业务界域来说
    2. **数据完整性原则** 这个原则其实和上面的"高内聚,低耦合"一脉相承,是把这个思想穿透到数据模型层面,因为服务化架构一个很重要的业务价值就是数据模型统一.这里特别想强调大数据的思维,不光只是业务逻辑的关键数据,还要考虑到业务的相关性数据;不光是实时在线数据,还要考虑到离线计算的数据.
    3. **业务可运营性原则** 服务中心首先是从业务出发,单纯的技术层面抽象出来的服务框架一般不作为一个可运营的服务中心.单纯的技术型的服务中心可以存在,但不是这里讨论的重点,我们期望服务中心是承载业务逻辑,沉淀业务数据,产生业务价值的业务单元.
        1. 业务的运营性有两个层面含义,一是指业务本身的活力,当业务处于快速生长期,这时候的运营目标是满足上层的业务需求,这个时候属于沉淀阶段
        2. 第二个层面的运营是指业务内部的孕育出来的创新想法,比如淘宝基于大数据分析技术生长起来的商品巡检技术,前台类目自动聚合推荐技术等.
    4. 渐进性的建设原则 渐进性的建设原则是从降低风险和实施难度这个角度出发,服务化架构本来就是一种敏捷的实践,我们是推荐小步快跑的方式逐步推进,不是轰轰烈烈地推翻重来.其实在分布式架构体系下,在企业互联网架构体系下,试错的成本已经降到足够低,渐进式的建设也是服务中心建设的一个重要原则.
53. 尽量减少事务边界
    * 事务原理
54. 此时我们来解释一下这里"事务边界"的定义,所谓的事务边界即是指单个SQL语句在后端数据库上同时执行的数量,
55. 事务边界的数量越大,会给系统带来以下弊端: ·系统的锁冲突概率越高.
56. ·系统越难以扩展.
57. ·整体性能越低.
58. 针对这类场景问题,最常用的是采用"异构索引表"的方式解决,即采用异步机制将原表内的每一次创建或更新,都换另一个维度保存一份完整的数据表或索引表.本质上这是互联网公司很多时候都采用的一个解决思路:"拿空间换时间"
59. 4.异构索引表尽量降低全表扫描频率
61. 如果在"尽量减小事务边界"与"数据尽可能平均拆分"两个原则间发生了冲突,那么请选择"数据尽可能平均拆分"作为优先考虑原则,因为事务边界的问题相对来说更好解决,无论是做全表扫描或做异构索引复制都是可以解决的.而写入或单机容量如果出现不均衡,那么处理起来难度就比较大
62. 针对这类场景,解决平台性能问题的核心就是数据库事务的异步化.通俗来说,就是将大事务拆分成小事务,降低数据库的资源被长时间事务锁占用而造成的数据库瓶颈,就能大大提升平台的处理吞吐量和事务操作的响应时间.
63. 当然,在此过程中,一定要考虑到程序异常时对业务的回滚或重试机制,保障整个还款过程结果的最终一致.
64. 关于数据库事务,相关的文档资料已经非常多,这里不做赘述,核心是体现数据库ACID(原子性,一致性,隔离性和持久性)属性,即作为一个事务中包含的所有逻辑处理操作在作用到数据库上时,只有这个事务中所有的操作都成功,对数据库的修改才会永久更新到数据库中,任何一个操作失败,对于数据库之前的修改都会失效.
65. CAP定理并不意味着所有系统的设计都必须抛弃三个要素之中的一个.CAP三者可以在一定程度上衡量,并不是非黑即白的,例如可用性从0%到100%有不同等级.显然我们有几种组合选择问题.
66. BASE是指基本可用(Basically Available),柔性状态(Soft State),最终一致性(Eventual Consistency).
67. ·"基本可用"是指分布式系统在出现故障的时候,允许损失部分可用性,即保证核心可用.
68. ·"柔性状态"是指允许系统存在中间状态,而该中间状态不会影响系统整体可用性.
69. 4.柔性事务如何解决分布式事务问题 (1)引入日志和补偿机制
70. 类似传统数据库,柔性事务的原子性主要由日志保证.事务日志记录事务的开始,结束状态,可能还包括事务参与者信息.参与者节点也需要根据重做或回滚需求记录REDO/UNDO日志.当事务重试,回滚时,可以根据这些日志最终将数据恢复到一致状态
71. 为避免单点,事务日志是记录在分布式节点上的,数据REDO/UNDO日志一般记录在业务数据库上,可以保证日志与业务操作同时成功/失败.通常柔性事务能通过日志记录找回事务的当前执行状态,并根据状态决定是重试异常步骤(正向补偿),还是回滚前序步骤(反向补偿).
73. (2)可靠消息传递 在分布式环境下,由于"网络通信危险期"(见下面阅读框中内容)的存在,节点间的消息传递会有"成功","失败","不知道成功还是失败"三种状态.
74. 根据"不知道成功还是失败"状态的处理,消息投递只有两种模式:1)消息仅投递一次,但是可能会没有收到;2)消息至少投递一次,但可能会投递多次.在业务一致性的高优先级下,第一种投递方式肯定是无法接受的,因此只能选择第二种投递方式.
75. 由于消息可能会重复投递,这就要求消息处理程序必须实现幂等(幂等=同一操作反复执行多次结果不变),这一要求跟传统应用开发相比是非常具有互联网特征的一种模式,在很多的应用场景下,都会要求程序实现幂等.
76. 现在大家都知道造成数据库性能和吞吐率瓶颈往往是因为强事务带来的资源锁.
77. 实现事务隔离的方法有很多,在实际的业务场景中可灵活选择以下几种典型的实现方式.
78. 基于以上柔性事务实现分布式事务的思路以及从多年对互联网业务场景特性的深度剖析,从阿里巴巴内部共发展和演变出三套成熟的分布式事务解决方案,下面分别介绍. (1)消息分布式事务
79. 从本质上来说,对比柔性事务解决分布式事务的思路,消息服务在其中扮演了事务日志的职能,对全局事务有一个统一的记录和调度能力;事务的参与者通过对消息订阅关系建立了事务间的关联.在采用消息服务实现分布式事务的场景如果出现异常时,一般会采用正向补偿的方式,即不会像传统事务方式出现异常时依次进行回滚,会通过消息的不断重试或人工干预的方式让该事务链路继续朝前执行,而避免出现事务回滚.
80. XTS是TCC(Try/Confirm/Cancel)型事务(如图6-13所示),属于典型的补偿型事务.
81. 两阶段提交的方案可以保证最强的ACID要求,开发者因此不需要仔细考虑自己的应用到底可以接受什么级别的ACID;同时,两阶段提交的方案开发简单,开发者只需要指定事务的边界即可.而最终一致性方案往往意味着更高的事务处理性能及处理吞吐率,但有些实现方案需要开发人员更全面地了解前端业务以实现事务的正向补偿或反向回滚,也会付出有损事务隔离性的代价.所以一定要在业务上精确分析自己的ACID需求,寻找性能与ACID的折中点,采取最合适的方案.
82. 今天阿里巴巴的淘宝平台都运行在云平台上,在云平台中不可忽略的一个问题是为了最大程度地增加机器的利用率,会采用超配的方式,即一台物理机上创建的虚拟机CPU核数的总和会超过物理机实际的CPU核数.
83. 大部分都是长尾应用,即使在双十一零点,有些应用的流量也是非常低的.这些应用所在的服务器计算能力其实是有剩余的.合理的超配,可以提升机器的资源利用率.
84. 分布式服务环境调用链路局部问题会被放大到整个链路.
85. 单点,局部问题会被放大成面.
86. 面对这种影响整体服务体系稳定性的隐患,阿里巴巴中间件团队实现了针对分布式服务系统的流量调度平台,用于屏蔽所有机器的软硬件差异,根据机器的实时服务能力来分配机器的实时流量.对实时服务能力好的机器多分配流量;对实时服务能力差的机器减少流量分配;对实时服务能力不可用的机器迁移流量.
87. 流量调度的核心是通过秒级获取服务器系统运行指标以及业务指标,通过流量调度平台设置的决策算法以及规则,当发现满足规则条件的指标状态发生时,对线上环境的服务器进行下线等操作,以屏蔽这些单点或局部出现故障的应用实例对整体平台产生扩展式的影响.
88. ·系统指标信息:CPU,Load等. ·业务指标信息:HTTP响应时间,HSF服务调用响应时间,HTTP QPS,HSF QPS,Tomcat线程池使用信息,HSF线程池使用信息.
89. 类似于传统的规则引擎运行流程(如图8-14所示),当从数据源生成相关消息发送到业务规则平台所监听的消息队列后,就自动触发了规则执行流程. 通过事件的类型和状
90. BCP平台实现了以下4个主要目标: 1)高实时性地发现业务脏数据或错误逻辑实现,第一时间发现并及时通知技术保障人员,而不是等客户反馈. 2)方便地接入各种业务规则,通过脚本规则编写的方式,让各应用快速接入业务审计平台. 3)整合订正工具,形成规范的赃数据订正流程. 4)业务上线的实时监控,新上线业务可以很方便地进行校验. 要实现业务的实时审计并不简单,如果是在应用层上进行业务规则的判断,一方面会对应用有非常大的代码侵入,很难灵活地进行业务规则的修改;另一方面也会对应用的性能产生影响,因为原本只是业务校验的代码执行进入到了业务处理的流程中.为了更高效率地让应用快速接入业务审计平台,同时减少对应用带来的代码侵入以及性能的影响,BCP平台通过事件模式,把业务数据变化触发的消息(如精卫,MQ等平台消息)转换为相应业务类型的事件,放入到事件执行队列进行规则检查,BCP提供了通用的事件监听框架,实现了与MQ(消息服务)对于数据库的对接,是对于数据变更的日志信息接入到了BCP平台中,
91. 传统企业如何能在开放共享时代来临时,找到适合自身企业发展的最佳位置,就应该现在着眼于企业内部核心业务能力的打造,在业务发展过程中不断沉淀企业核心业务,当有一天需要通过能力开放的方式拓展企业业务边界或构建生态的时候,这些沉淀的服务将会是企业最大的资产.
