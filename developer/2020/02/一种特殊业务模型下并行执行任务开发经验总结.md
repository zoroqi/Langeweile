# 一种特殊业务模型下并行执行任务开发经验总结

> 开发经验, 总结, 并发, 异步

从工作到现在, 主要工作内容还是CRUD比较多, 遇到异步执行的操作不多. api接口还是从头到尾单个线程同步执行完, 工作性质就是map/reduce, 做数据转换然后拼接合并.

这里异步任务拆分指的也是api请求后的拆分成多个任务, 异步执行这些任务, 同步等待这些任务, 合并结果返回给调用方. 这种操作经常是一次拆分成多个任务, 甚至拆分成20多个任务并发执行. 通常随着任务追加, 这种执行会根据入参和数据库配置改变执行任务的数量会发生变化. 在工作中接受几个类似业务代码, 维护起来那是一个累啊, 做任何改动都是异常费劲.

### 工作中遇到的执行方案

在工作中接触了几种方案:

1. java的一个版本

依赖于Spring框架的@Async注解. 通过这种方式快速构建异步任务, 最后拿住Future, 等待执行结果. 实际代码根据参数和系统配置执行异步任务在10\~25个之间, 之后超时同步等待执行.

这种实现遇到最大的问题, 在get出现异常的时候根本不知道是哪一个任务挂掉了. 是基于线程池必然出现排队现象, 也不知道任务排队时间是多少, 单个任务实际运行时间也不知道. 为了应对需求变更也不够灵活, 当写道25个任务的时候, 这个异步执行代码已经接近500行代码了, 里边充满了if/else来支持配置和参数变动. 这里other步骤中还存在一些可以并行化的处理代码.

当我接收代码, 加个执行耗时就丫的用一种很不优雅的方式实现的, "为每一个分支对应添加一个对应标签", 真TMD费死劲了. 之后时间宽裕后修改了中方式进行统一解决, 对未来的支持也有很好的支持.

```java
@Component
public class TaskServiceImpl {
    @Async
    public Future<Tuple<String,String>> asyncTask1(int param) {
        // Tuple, key:任务名, value:结果
        return new AsyncResult<>(Tuple.build("1",param+""));
    }
    @Async
    public Future<Tuple<String,String>> asyncTask2(int param) {
         return new AsyncResult<>(Tuple.build("2",param*2+""));
    }
        @Async
    public Future<Tuple<String,String>> asyncTask3(int param) {
         return new AsyncResult<>(Tuple.build("3",param*3+""));
    }
}

@Service
public class ApiServiceImpl {
    @Autowired
    private TaskServiceImpl taskService;

    public Map<String,String> api(int param) {
        List<Future> tasks = new ArrayList<>();
        if (param > 10) {
            tasks.add(taskService.asyncTask1(param));
        }
        tasks.add(taskService.asyncTask2(param));
        if (param > 20) {
            tasks.add(taskService.asyncTask3(param));
        }
        Map<String,String> result = new HashMap<>();
        long totalTimeout = 1000L;
        long start = System.nanoTime();
        for (Future f : tasks) {
            try {
                long remaining = System.nanoTime();
                Tuple<String,String> r = f.get(remaining > 0 ? remaining : 0, TimeUnit.NANOSECONDS)
                result.put(r.one, r.two);
            } cache(Exception e) {
                // TODO
            }
        }
        // other
        return result;
    }
}

```

2. golang的一个版本

主要业务是根据参数和配置, 调用第三方api并将结果进行汇总计算, 平均一个请求最终会调用8\~10个api接口, 每个接口会多次调用, 总共调用50\~60次接口.

实现方式主要采用go直接发起任务, 通过闭包,锁, waitgroup实现整个逻辑, 这里不知道当初第一版为啥不用chan去实现, 也没有用到context这个结构. 这里面对的几个问题, 一是锁的使用和整体超时控制存在问题(代码有点久了忘了超时怎么控制了, 印象中没有做控制. 靠调用第三方api接口超时去控制, 这个服务特殊请求参数可以导致接口耗时达到3min, 依赖接口慢). 第二个问题不知道一个请求过来需要执行那些任务, 要根据配置和入参做一步一步排查, 接受光理解这些配置就用了很久的时间.

我在接收代码的时候, 我只是维护不需要在做功能上的开发了, 所以就没有进一步的优化, 光理解业务就用了两周, 一个请求大概会拆分成80\~90个goroutine. 最要要命的是这些goroutine还存在共享的锁. 最重要共享返回结果集合, 中间多个任务之间还存在耦合需要对跨goroutine做任务同步 , 看到最后发现这个代码真的是伟大啊, 竟然没有产生死锁, 完美运行, 前人的脑容量不可估计.

```golang
type taskResult struct {
    name string
    r    string
}

func api(param int) []string{
    taskResults := make([]taskResult)
    lock := sync.Mutex{}
    wait := sync.WaitGroup{}
    if (param > 10) {
        wait.Add(1)
        go asyncTask(){
            defer wait.Done()
            r := taskResult{name:"asyncTask1", r:strconv.Itoa(param)}
            lock.lock()
            defer lock.unlock()
            // 加入到结果切片中
            taskResults = append(taskResults,r)
        }
    }
    // asyncTask2, asyncTask3....
    wait.Wait()
    result := make([]string,len(taskResults))
    for i, r := range taskResults {
        result[i] = r.r
    }

    return result
}
```

## 个人经验

在这种业务下很多时候回随着时间讲任务进行拆分和合并, 大部分任务执行流程都是相似的. 我个人经验是将功能拆分成三部分, 第一部分以计算参数和需要执行那些任务为主, 第二部分就是纯粹发起批量任务, 第三部分就是数据合并和后续处理.

### java版本

这个实现依赖线程池invokeAll中间的一个内部逻辑, 会创建一个完整的Future的ArrayList, 这样可以和入参taskName保持一致, 这样可以方便对执行失败的任务进行定位和追踪. 这是设计模式中模板模式最简单的一个使用. 这里的优势在于相比于使用@Async可以对Callable进行一定定制(主要没去研究spring中Async如何灵活配置), 这样可以添加很多日志, 包括运行耗时, 失败监控, 将部分部分串行处理移入并行处理

依赖于jdk8的function和spring的bean机制做的简单组合, 采用模板方式最讨厌的一个弊端就是模板要改就要命了.

基于jdk7和非spring框架下, 那就靠着接口和hashmap结合也可以实现类似的功能.

```java
// 基于spring版本
@Component
public class TaskServiceImpl {
    @Bean("asyncTask1")
    public Function<Integer,String> asyncTask1() {
        return (p) -> p+"";
    }
    @Bean("asyncTask2")
    public Future<Tuple<Integer,String>> asyncTask2() {
         return (p) -> p*2+"";
    }
    @Bean("asyncTask3")
    public Future<Tuple<Integer,String>> asyncTask3() {
         return (p) -> p*3+"";
    }
}

@Service
public class ApiServiceImpl {
    @Resource(name = "pool")
    private ThreadPoolExecutor threadPool;

    @Autowired
    private ApplicationContext context;

    public Map<String,String> api(int param) {
        List<String> tasks = new ArrayList<>();
        if (param > 10) {
            tasks.add("asyncTask1");
        }
        tasks.add("asyncTask2");
        if (param > 20) {
            tasks.add("asyncTask3");
        }
        Map<String,String> result =
    }

    private Map<String,String> execute(List<String> taskName, int param) {
        List<Callable<String>> tasks = new ArrayList();
        for (String t : taskName) {
            // 需要注意找不到bean的情况
            Function<Integer,String> func = (Function<Integer,String>) context.getBean(t);
            tasks.add(() -> {
                return func.apply(param);
            })
        }
        List<Future<String> r = threadPool.invokeAll(tasks,1,TimeUnit.SECONDS);
        Map<String,String> result = new HashMap<>();
        int index = 0;
        for (Future<String> f : r) {
            // 基于invokeAll的实现这里可以做唯一映射
            result.put(taskName.get(index,0 ,TimeUnit.SECONDS);, f.get())
        }
        return result;
    }
}
```

依赖会使用到线程池, 这里就涉及到了溢出策略, 可以启动的线程是有限的, 内存也是有限的, 所以队列不可能无限的长, 在线上服务使用的Discard的策略, 使用后发现这个策略不是很好, 这个策略会导致invokeAll会产生最大超时, 而实际是空等待. 建议使用默认的异常策略, 会自己常见一个需要手动cancel的Discard策略. 而这里有一个新的方法, 外部线程正在同步等待invokeAll操作, 这个线程是可以执行一个任务的, 这样在任务过多的时候可以保证小部分任务完成执行, 不至于完全没有任务执行, 这里可以通过ThreadLocal去尝试进行时间或数量控制, 但这里会导致一个问题, 等待时间可能超过最大时间.


golang可以采用类似方式, go可以更灵活, 但基本思路是一样的. 我可能是基于 map[string]func task(p int, wait &sync.WaitGroup, result chan string) 实现运行方式实现, 现在感觉不是很优雅, 之后想到更好的方式在写go的版本.

## 总结

第一次写这种东西, 只是工作中的一个总结, 感觉不是啥有用的东西. 开始写东西总不能只有读书笔记, 写点技术有关的. 当前没啥深度慢慢来吧.

在这个业务下, 第一保证是接口可以完成执行. 第二任务是保证尽量多的任务执行完成, 因为这种业务缺失一个异步任务并不会产生太大的负面影响, 只是影响结果的质量. 业务会随时间添加任务和动态配置任务是这种业务的发展方向, 有过出现需要灵活组合任务的时候, 更加需要将计算参数和执行拆分开来.

在扩展一下, 任务拆分后需要在多个机器行执行的时候也需要进行如下步骤进行执行, 先创建任务记录, 在开始执行, 执行完后修改状态.









