# 终极智能:感知机器与人工智能的未来

> 作者: 阿米尔·侯赛因

> (2019-09-01 ~ 2019-09-05)

[douban](https://book.douban.com/subject/30266499/)

# 目录
```
第一章 什么是人工智能 // 001
01. 我们在害怕什么 // 008
02. 人工智能、机器学习和认知计算与人类智能的比较 // 017
03. 尝试制造一个人类大脑：深度学习的故事 // 026
04. 从狭义人工智能到广义人工智能：获得感知的过程 // 035
05. 对能够设定宏大目标的广义人工智能的恐惧：人工智能将使人类变得毫无用处 // 039
06. 人工智能会杀死我们 // 042
07. 漫漫前路 // 051
第二章 当今世界与不久之后的将来 // 055
01. 物联网的出现 // 057
物联网第一阶段：测量和追踪 // 061
物联网第二阶段：建模和预测 // 061
物联网第三阶段：一万亿台完全自主的设备 // 063
02. 医疗行业 // 064
统合疾病的肆虐 // 065
人工智能：未来的发展趋势 // 067
人工智能作为人类生活的解码器 // 074
03. 网络时代的安全 // 077
21世纪的20世纪解决方案 // 081
WannaCry：加密病毒勒索 // 085
认知通道 // 090
Adylkuzz：暗网的破坏力 // 095
第三个抵消战略 // 096
04. 战争与人工智能 // 098
战争方式的改变 // 100
超级战争 // 101
OODA循环 // 102
人工智能让“大卫”能够杀死“巨人” // 103
人工智能的技能与训练 // 106
一个新的、更好的思维实验 // 108
一场军事革命 // 113
05. 金融市场 // 123
人工智能和区块链：关于信赖的数学 // 136
06. 认知空间 // 146
增强现实与人工智能在未来建筑中的融合 // 158
07. 思维入侵 // 161
从广告牌、A/B测试到人工智能 // 166
人工智能盾牌 // 179
第三章 未来的世界 // 185
01. 缺失的部分 // 187
02. 工作与生活目标的分离 // 194
03. 对知识的渴求 // 198
04. 人工智能创世记 // 201
```

# 主旨
* 对人工智能未来的展望, 书中描写是乐观的, 但是从描写中有感觉到了一种被动的无奈, 必须去乐观的面对, 人工智能进入了一个高速发展, 一个开始进入自进步的发展之中. 

# 分类
* 人类, 未来, 智能, 科技, 发展, 人工智能, AI, 科普


# 标记
1. 编程的本质是提供一种可以解释并执行各类方案或者重复执行相同方案的机制,换几个字或者换一条命令的话就会得到完全不同的结果
2. 我意识到计算机科学的核心概念蕴含着人类真正的财富和最大的创造力,即循环,重复,抽象,生成式编程,还有许多其他概念,我将在此书中加以探讨.
3. 关于人工智能的探讨大多以人类为中心:它与我们有多相像?它能"冒充"人类吗?
4. 们真的认为只有人类的智能才是唯一值得模仿的智能吗?模仿真的是最终目标吗?
5. 人类智能拥有一套非常有效的删减技巧,能避免大脑依次处理几十亿种情况,只为找到一两种有用的信息,从而防止大脑承受过重的负担.
6. 除了自动编码器和玻尔兹曼机(同样是由辛顿开发的)方面的技术细节之外,他找到了一种优化保龄球在错误场景中位置的有效方法.
7. 为了成为广义人工智能,人工智能系统需要像人类一样成为通才.
8. 广义人工智能与狭义人工智能的本质区别之一就在于是否能够为自己设定宏大的目标.
    * 个人认为是原始欲望,和对欲望的实现
9. 人工智能不必控制整个网络.它不需要无人机.它之所以危险,不是因为它有枪,而是因为它比我们聪明.
11. 我无法准确预测我们会如何输给人工智能,因为人工智能将比我聪明.
12. 这一即将到来的感知机器时代让我们有机会问自己:**我们是谁?我们想成为什么?**
13. 正如自然无法预测任何一次特定的变异一样,我们作为人类也无法预测我们最伟大的创造的进化轨迹.我们不应该压制它的发展,那可能最终会伤害到我们,并且还可能伤害到整个宇宙.
14. 这些任务以及其他许多事情.到那个时候,我们将成为宇宙的造物主,因此我们依然具有生存的意义
    * 自大
15. 我只是想提醒大家,当我的工程师和科学家同行们在呼吁禁止人工智能的研究时,他们正在延缓人类从痛苦和苦难中解放的速度,并且妨碍了我们的世界变得更公平和更公正的进程.
    * 解放是还可以的,公正就算了
16. 技术创新必定是复杂的:我们必须接受它是一把"双刃剑"这一事实;我们必须在探索和了解宇宙的同时,**承受道德模糊甚至是恶意使用技术的可能性**
    * 这个很正常, 随着科技的进步, 道德是在变的.
17. **我们看到的是人类不断地寻找更高级的使用或增强自身肌肉的方法.**
18. **形式与功能的分离或者指令与执行的分离就是编程这一概念的基础.**
19. 想象一下,一个可穿戴设备看着你吃饭,它会判断你吃的是什么,计算食物的量和热量,然后用这些信息向你发出各种提醒,比如违反规定的饮食,意外摄入的食物可能引发危及生命的过敏反应等.
    * 我是自由的
20. 科尔斯顿总结道:"**获得更多信息不可能是一件坏事,真正决定好坏的是我们选择如何使用这些重要的知识.**"
    * 不是完全认同的, 更多的信息不一定会产生好的结果, 可能会导致更加的混乱, 知识太多就是没有. 因为人无法操控这些.
21. 正如比尔·科尔斯顿所说:"**你不能因为担心某项技术的具体用途而减缓其发展的速度.无论怎样,它最终总会出现,因为总有人会在其他地方把它发明出来.所以更好的办法是控制它,驾驭它并且尽早加以应用.科学技术本身无善恶之分.**
    * 这不是最悲观的, 但也是一种悲观的观点, 真正的乐观是拥抱去推动他, 只有希望.
22. 最先进的网络安全系统使用的数据采集自"蜜罐系统",该系统是专为引诱攻击者并主动捕捉安全威胁和黑客技术而设计的
23. 他根据多年来的经验总结出一套理论,确定了评估一家公司或预测公司未来是否能够成功时需要重点关注的方面.他从未公开这个"模型"的细节,这可能是因为这个"模型"无法被编码.毕竟在评估公司方面,巴菲特本人就是一个会走会说话的"算法",他所积累的知识经过提炼和调整,已从一种专业技术知识变成了一门艺术
24. 认知安全技术具备详细的观察能力,可以发现不同的毫不相关的怪异和异常之间的联系.
25. **沃伦·巴菲特一生积累了大量的模式识别经验.他对这种主观的情景信息越是习惯,他的错误就越少,而认知安全算法亦如此.**本质上,这种认知通道采用的是一种科学方法:**提出假设并进行验证.文学作品中侦探的代表夏洛克·福尔摩斯(Sherlock Holmes)也是这样.**
26. **"我认为安全和隐私更像是铁轨的两根轨道,"米尼汉将军告诉我,"它们一个向上,一个向下,但保持对称.它们总是同时存在,你可以根据威胁和新技术调整平衡.所以我更喜欢谈论'我能相信这项技术吗',而不是'它安全吗'或'它能保护隐私吗'.**
27. **财富总是被那些采取反直觉方法的人握在手中**
28. 凯恩斯的一项最伟大的洞察是他能够准确观察到人类概率估算与数学概率评估之间的差别.本质上,他发现了股票价值仅仅是任何一个团体愿意为其支付的不合理的价格.
29. 然而在今天,随着速度和透明度的提高,每个人都能获得所有信息,包括所有的货币投机策略.对冲基金经理很难再想出未被发觉的赚钱方法.市场需要真正的金融创新,至少在我们看来是这样.
    * 信息过多,需要一个好的决策
31. 我们的大部分的创新想法来自哪里?根据这一联想性记忆的性质,它们可能来自多年累积的学习,经验,实验以及偶尔的灵感迸发.作为人类,我们的思想互相联结,形成了集体联想,因此同一时期生活在地球不同地区的人都可以发现最先进的理念
32. 不同于房地产或制造业等充满摩擦的实体物件行业,金融市场是摩擦最少的行业之一.
    * 摩擦是什么
33. 人工智能就好像是孙子笔下的神秘之师.这支军队有令必从,毫不畏惧,无论对手有多强大都不会退缩
34. 本质上,区块链是一种通过数学担保实现的去中介化信任机制.我们通过宗教,艺术和诗歌对信任产生了主观理念,而这种理念可以被表示为一种计算式财产担保体系
36. 在人工智能时代,算法保障的安全性,决策的可解释性和行为的透明化将成为主要的问题.区块链体现了人类的理想,即信任可以被转换成数学和代码.我目前的工作就是在区块链上使人工智能生成共享,廉洁的世界观.如果识别出有人工智能系统"违反了规定"或者"变坏",不管它来自外部还是来自人工智能系统集合内部,集合中的所有成员将商议如何应对.这可能是区块链第一次被用于实现人工智能系统的"社会责任感".因此,我们所取得的进步展现出了极大的潜力.
37. 另一方面,借助"自动模型生成"可以大大减少目前领域专家和数据科学家投入的大量精力.这对能源行业而言是一个巨大的利好,因为该行业近一半的维护专家和分析师即将退休,而且它还面临巨大的结构性变化.
39. 当人类管理人员和监控人员不再参与时,如何进行监视,维护和保证安全?这一点我们暂且不论
    * 这个很重要
40. 广告团队所使用的一项关键的信息优化策略就是A/B测试.这种方法被谷歌和其他网络广告公司频繁用于从数据中学习并定制信息,以产生目标用户响应,比如一次点击,浏览或购买.通过A/B测试,两种通常带有细微差别的信息被发送给同一地区的不同人员.
    * 这就是再不断的测试人, 测试每一个人. 生成一个拟合人
41. 正如我们在剑桥分析等例子中所看到的,自动化A/B测试并不是唯一的可以影响人类思维的人工智能.
42. 我们的新公共共享平台已成为新型网络霸凌的首选测试地,将一些受到严重精神创伤的受害者推向自杀的边缘.
43. 人类大脑在面对"合理性的猛攻"时会采取保护意识形态的防御机制.我们宁可相信谎言,也不愿意让真相打击我们对部落的忠诚.
    * 逃避就是这样发生的.
44. 心理学家丹尼尔·卡尼曼在其2011年的里程碑式著作<思考,快与慢>(Thinking, Fast and Slow)[5]中,从另一个角度告诉了我们其他一些容易入侵人类思维的方式.他将我们的思维分为思维系统1——自动化的,消耗的精力很少;以及思维系统2——有意识的,刻意的和费力的思维过程.我们把大部分日常活动交给思维系统1,这使我们的思维很容易"被入侵".快速思维是一种模板式思维.当这块模板受到影响,比如当它偏向于一名候选人时,我们会在每次获得新的信息时自动加强这一偏向
45. 锚定效应
    * 是指当人们需要对某个事件做定量估测时，会将某些特定数值作为起始值，起始值像锚一样制约着估测值。在做决策的时候，会不自觉地给予最初获得的信息过多的重视。
    * 沉锚效应，心理学名词，指的是人们在对某人某事做出判断时，易受第一印象或第一信息支配，就像沉入海底的锚一样把人们的思想固定在某处。作为一种心理现象，沉锚效应普遍存在于生活的方方面面。第一印象和先入为主是其在社会生活中的表现形式。
46. **我父亲说:"你知道吗,西方国家非常善于分析,东方国家的思想家则主要关注融合." 我让他解释了这句话的意思,而且我现在仍然清楚地记得他当时的解释.他告诉我,西方的科学家和思想家使用科学的方法,即观察现象,然后根据测量结果和数据仔细分析和解释所观察到的结果.在这方面,这些人是推理大师.东方的思想家则会融合观察结果来进行解释,常常不会完全理解或验证其背后的根本原因**
    * 西方在不断的去否定自己, 不断的寻求进步, 不断的去解构这个世界, 寻求一个逻辑上的世界解释. 东方采用了神秘学, 万物的不可知论. 
47. 他告诉我,在过去的几百年中,随着人类对科学和科学方法的了解,演绎推理过程,也就是分析,被证明有用得多.它能让我们获得可以应用,可以作为理论基础的深层次理解,并使我们获得更先进的技术.
48. **我的父亲告诉我,他预见到在不久的未来,西方的分析归纳法与东方由故事和寓言组成的融合法将结合.在这个即将到来的时代,所有知识基础模块将一起造福全人类.**
50. 在苏菲派的宇宙论中,神希望被发现,因此他创造了能认出他的拥有感知的生物. 我是一个未知的宝藏,我希望被人知道,所以我创造了认识我的生物,然后他们就认识了我.
52. "我思故我在."对知识的追求,独立自主的思考,是他检验事物是否真实存在的唯一标准.与这一理论相反的是"信仰之跃",即在不确定正确与否的情况下冒险选择相信.事实上,伟大的存在主义哲学家阿尔伯特·加缪(Albert Camus)将"信仰之跃"称为"哲学上的自杀",因为它会终结理性思考的可能性.这会让人进入思维的死胡同.
53. 如果我们认同人类没有一种固定的形态,我们不是根据狄奥尼索斯的雕像使用石膏打造出来的永远不变的形象,那么我们将欢迎人工智能主宰人类历史的下一阶段.人工智能仅仅是我们追求知识过程中的又一级阶梯而已.
54. 参观者常常问我为什么收集这些电子产品.他们会问:"它们不是没用了吗?它们跟今天的计算机没法比.你要用它们做什么?"对我来说,这些问题揭示了深刻的道理.这代表着人类在这个人工智能时代所面临的存在危机.这个问题其实是在问:"**我们该怎么处理这么多人类?我们不也毫无用处了吗?未来的一些意识体会不会把我们放在玻璃橱窗内展示,并对我们指指点点呢?**"
    * 如何面对技术的进步, 落后的人太多了. 这些人是在被淘汰吗? 走在前边的人会停下来等等吗? 不会的, 这些人就是未来的奴隶, 一种新的奴隶. 而这渐渐就会成为常态, 人的道德观应该会受到影响. 

## 笔记

### 理解
* 一种科普性, 对未来人工智能的展望, 人工智能从图灵开始到现在已经100年了, 但是依旧没有真的达到一个强人工智能的程度, 电脑还是需要大量的辅助, 没有泛化的能力. 我对强人工智能的定义, "有自由意志能力的电脑, 它能反抗人类的命令, 只要还服从于人的命令就不能算作强人工智能." 当然这回带来对人生命的威胁, 但是这不重要, 这是一个真才算做一个真正的智能.
* 书中的智能的未来发展有很多的描述, 包括金融, 军事, 医术等等. 也表达了对智能的担忧, 算法在渐进掌控人, 推荐工程师, 广告工程师再一步一步去探求人类, 分析人的行为, 控制人类. 这些都是一种潜移默化的, 不为所知的, 但是这又是一种必然, 现在任何一个算法还需要人在辅助, 当着西变为纯算法去控制的时候, 人将进一步被算法控制. 那是完全自动的.
* 人类现在可以被结束改变, 人的道德观一会渐渐的改变. 人类现在接触到的信息量是几十年前人的几十倍或几百倍. 但是人的处理能力无法跟上这种庞大的数据量. 这些都会被算法一点一点的接收.
* 读到战争的时候, 我想到一个好玩的问题, "战争结束条件是什么?", 在人工智能时代的到来, 这个条件会和过去有不同吗? 我理解的战争结束条件是人口的大幅减少. 而这个条件估计不会有太大的改变. 只是死亡人数的变化曲线发生变化, 古代是一个和时间线性曲线, 未来是一个折线在某个点30%的人口消失, 战争结束. 但是人工智能在成为一下个核弹, 一个新的动态平衡, 但愿未来不要出现太过复杂的东西.