# 统计会犯错--如何避免数据分析中的统计陷阱

> 作者:Alex Reinhart(亚历克斯·莱因哈特), 刘乐平 (译)

> (2019/02/07-2019/03/01)

# 目录
```
第1章统计显著性简介
    p值的力量
    统计的心理暗示
    奈曼-皮尔逊检验
    构建置信区间
第2章统计功效与低功效统计
    功效曲线
    低功效困境
    低功效的原因
    遇红灯时错误转弯
    置信区间的优势
    膨胀的真理
    微小的极端
第3章伪重复：理智地选择数据
    什么是伪重复
    如何应对伪重复
    生物学批量数据
    同步现象造成的伪重复
第4章p值与基础概率谬误
    基础概率谬误
    一个小测试
    药检中的基础概率谬误
    如何用吸烟数据说谎
    如何应对基础概率谬误
    样本越多就越好吗
    大西洋鲑鱼的脑功能成像试验
    如何控制FDR
第5章统计显著性的误判
    显著性水平的微小差异
    关注显著性
第6章双重数据
    圆形统计分析
    向平均数回归
    停止准则
第7章连续性错误
    二分法？多此一举
    统计疲劳
    复杂的混杂因素
第8章模型误用
    西瓜数据的拟合
    相关与因果
    辛普森悖论
第9章自由研究还是无意识偏向
    危险的随意探索
    避免认知偏向
第10章统计显著性简介
    无法复制的基因学
    使再现变得容易
    试验，清洗，重复
第11章数据背后的真相
    被囚禁的数据
    数据分享的绊脚石
    数据衰变
    细节遗漏
    已知的未知
    偏倚的结果报告
    档案柜中的科学
    未公布的临床试验
    找出报告偏倚
    强制披露
第12章我们能做些什么
    统计教育
    科学出版
    你能做到的事
参考文献
```

# 主旨和分类
* 统计会存在大量的误区的
* p值

# 标记
1. 正如Hanlon's razor告诉我们的那样: "把一切归咎于恶意, 是对无能的充分解释", 有些出版物是在"谎言, 该死的谎言和统计"这一条目下的. 制药行业似乎尤其偏爱那些忽视了不利因素(例如那些指责他们产品没有疗效的出版物)的证据;
2. 即使是正确处理的统计资料也可能是不可信的. 统计技术和分析方法的过剩使得研究人员在分析数据时有很大的自由发挥空间, 而且很容易"不断拷问数据直到它承认存在某些关系". 不断尝试你的统计软件中提供的几种不同的方法, 直到其中某个可以产生有趣的结论, 然后假装这就是你想要做的所有分析. 
3. 通常来说, 我们观测的是由于巧合或随机变化导致的差异, 所以当观测差异大于随机产生的差异时, 统计学家称之为"统计意义上的显著区别". 
4. p值是在假设药物效果没有真实差异的情况下, 差异等于甚至大于实际观测差异的概率.  例如, 你给100个患者服药, 发现他们的平均感冒时长比对照组少一天, 这时p值就是在药物无效的假设下, "他们的感冒时间比对照组少一天"这种情况完全是出于巧合的概率. 
6. 记住, p值不是用来测度你多么正确, 或者这个差异有多重要. 反之, 它是对"意外"的测度. 如果假设药物无效, 那么也只能用运气来解释两组的区别. 然后p值越小, 试验结果是意外或因为运气的可能性越大——或者说你的假设就是错误的, 新药的确有效. 
7. 如何运用p值来解释"这些组之间是否有差异"? 通常的经验法则是: 当p<0.05时, 区别是"统计显著"的. 选择0.05不是出于特别的逻辑或统计的原因, 而是在多年的使用过程中形成的科学惯例. 
8. 记住, p值是指对意外的测度, 一个较小的p值意味着更加意外. 它不是影响大小的测度. 可以通过测量大的影响获得一个小的p值(这种药物可以使人的寿命延长4倍), 或者用较大的确定性测量一个较小的影响. 
9. 在科学研究中, 控制假设检验的两类错误是至关重要的: 
    1. 第一类错误(false positives), 就是将无效说成有效(取伪);
    2. 第二类错误(false negatives), 则是将有效判断成无效(弃真). 
    3. 在一定程度上, 第一类错误和第二类错误是一枚硬币的两面. 如果我们比较激进, 则容易犯第一类错误;如果我们过于保守, 第二类错误会主动找上门来. 
10. 关于置信区间报告很少的原因可能是因为他们区间宽的令人尴尬. 另一个原因是论文同行评审的压力太大, 最好像其他学科那样做统计, 否则评审者会拒绝你的论文. 或者可能是关于 p值的困惑掩盖了置信区间的好处. 或者是在统计课程中过度强调假设检验意味着大多数科学家不知道怎么样计算和使用置信区间. 
11. 一个置信区间包含一个点估计以及这个估计的不确定性. 
12. 置信区间可以将结论中的不确定性定量, 而且比不能说明任何效应量的 p 值提供更多的信息. 
13. 一项研究的功效指的是, 它能将某种强度的效应从纯粹的运气因素里区分并识别出来的概率. 如果一种药物治疗作用特别明显, 那么它的识别就比较容易, 而如果疗效轻微, 其识别往往比较困难. 
14. 数据越多, 我们越容易从噪声中区分出信号. 但说起来容易做起来难, 科学家没有足够的资源开展具有高功效的科学研究, 来检测他们要找的信号, 因此在开展研究之前他们就注定会失败. 
15. 以上现象被称为真理膨胀, 或者M型错误, 赢者灾难. 这种现象经常发生, 尤其在那些进行类似试验争相发表最激动人心结果的领域经常见到, 例如药理学试验, 流行病学研究, 基因关联研究, 心理学研究等. 
16. 在设计试验时, 先计算统计功效, 以此来决定所需样本的大小. 不要跳过这一步. 如果你对统计功效不甚了解, 可以阅读Cohen's的经典教材《行为科学的统计功效分析》或者向统计专家进行咨询. 如果试验样本大小不切实际, 最后结论的可靠性就会大打折扣.  如果你想精确地度量某种效应, 请不要单纯地进行显著性检验, 更好的做法是设计满足置信度的试验, 这样就能以理想的精度度量某种效应.  请铭记"统计上不显著"并非意味着"0". 即使你的结果是不显著的, 该结果也代表基于你所收集的数据所得到的估计. "不显著"与"不存在"并不等价.  持质疑态度看待那些低功效研究的结论, 这些结论可能夸大真实情况.  请使用置信区间作为最后的答案, 不要过分关注统计上的显著性.  当比较规模不同的组时, 请计算置信区间. 置信区间可以反映估计的精确程度: 规模较大的组置信区间较窄, 估计更精确. 
17. 回顾一下p值的定义: 在无效或无差异的零假设下, 检验统计量取当前值及(沿备择假设方向)更加极端值的概率. 也就是, 样本数据显示的差异等于甚至超过实际观测到的差异的概率. 
18. 所以, 当有人引用一个较低的 p 值来说明某项研究可能正确时, 请务必牢记: 实际上发生错误的概率几乎肯定比p 值高. 当大部分被检验假设错误的时候, 像早期的药物试验那样(多数药物不能通过试验), 很可能几乎全部p < 0.05水平下统计显著的结果, 事实上都是巧合. 
19. 针对引言的前半部分, 我对哈夫表示赞同, 统计显著性并不意味着将数据精确到两位小数(
20. 在BBC报道了NO.7品牌的美容精华素能有效减少皮肤皱纹的临床试验之后, 2007年该产品成为英国连锁药店Boots的销售冠军. 据《英国皮肤病学》杂志报道, 临床试验结果表明, 使用该精华素后, 43%的受试者皱纹数量有所减少, 该效果统计上显著有效, 而其对照组(不包含某活性成分的精华素)的结果是22%, 统计上并不显著. 正如其广告中宣传的那样, 这意味着科学证明该精华素是控制皱纹的最佳选择. 尽管作者在其报告中承认: 试验组和对照组之间的差异并不是统计显著的(即该产品确有减少皱纹的功能, 但该功能并不明显优于其他类似产品).  类似的统计误读不仅发生在市场营销部门, 在其他领域也比较常见. 
21. 一份对心理学家, 神经学家和药物研究员的调查显示: 其中大部分人混淆了标准误, 标准差和置信区间这几个概念, 而且他们主要通过置信区间有无重叠来判断差异是否显著(如果置信区间有重叠说明二者效果相近, 如果无重叠则二者有较大差异). 另一项针对气候科学论文的调查发现, 大多数用误差区间进行两组对比的文章都存在错误. 即使是科学家们用的入门级教科书, 例如John Taylor的《误差分析导论》, 也教学生用眼睛去对比置信区间, 却几乎从不提及正规的假设检验. 
22. 注意事项 用统计方法直接在两试验组之间做检验, 而不要将各个试验组分别与对照组比较后简单地说: "与对照组相比这个是显著的而另一个不是. " 不要单靠眼睛观察置信区间来判别试验效果之间是否有显著差异, 要用统计检验. 如果要同时对比多个组, 需要使用多重比较的方法! 
23. 第5章中我们讨论了过度使用显著性检验的弊 端——言不符实. 在探索结论显著性的过程中, 研究者们通常只会得到那些最幸运, 最夸大的结论——因为只有它们才能通过显著性检验. 然而, 其他问题也可能会造成结论是有偏, 夸大的. 本章将对其详细探讨. 
24. 当要求统计学家说出统计中一个有趣的矛盾时, 他们常常会提到辛普森悖论[2]. 当由混杂变量造成的数据有明显趋势时所出现的辛普森悖论, 都能够通过将数据分为几个自然组来消除. 这样的悖论有许多例子, 我们从最著名的开始. 
25. 统计技术的广泛传播给我们提供了有用的工具, 但是, 它们似乎被当作对数据"滥用刑罚"的武器, 折磨逼迫, 直到数据"屈打成招". 为了改善这个局面, 我们要应用预注册试验报告, 盲分析和进行试验方法的研究, 开始更人道地对待数据. 
26. 在收集数据之前确定分析方法, 确保该方法可以解释多重比较, 并且包括任何想要探究的效应.  如果情况允许, 注册临床试验协议.  如果研究偏离了协议, 务必在论文中指出这个问题, 并给出解释.  不要一味对数据"严刑逼供""屈打成招". 在开始分析之前, 头脑中要有一个清晰的统计假设. 
27. John Ioannidis的著作《为什么大多数发表的研究成果都是错的》1是基于数学理论而不是对研究结论的经验检验. 由于大多数研究的统计功效都很低, 为了得到理想中的结论, 研究人员会自由地选择任何分析方法, 但大多数被检验的假设都是错的, 而正确的假设只有很低的效用, 最终只能得到大量的假阳性结论. 
28. 在仅有的几门相关课程中, 也并不涉及统计功效, 多重比较这类重要的统计概念. 甚至在统计课堂上, 教授也建议学生不要把统计思想应用到科学问题中, 这使得学生从未理解或者早已忘记某些重要的统计方法. 
29. 误解就像蟑螂: 你不知道它从哪里来, 但它却无处不在, 你经常能在意想不到的地方发现它, 连核武器对此也束手无策. 
    * 说的有道理
30. 另外, 不合理的激励机制促使科学家们急于发表小型研究——这些研究通常很草率地使用统计方法. 
31. 当然, 你的工作不仅仅是数据分析. 科学家们也需要花很多时间来阅读其他人的文章——以从中学习更多的统计方法以及寻找统计分析中重要的细节, 例如:  如何计算研究的统计功效或者确定样本量的其他方法.  如何为数据分析选择合适的变量.  统计结果是否支持文章结论.  根据效应量估计的显著性检验和置信区间, 判断该结论是否有实际意义.  是否使用了恰当的统计检验. 如有必要, 这些检验是如何对多重比较进行修正的.  停止规则中的每一处细节. 
32. 总而言之, 你的任务可以总结为以下四步. 
    1. 学习统计教科书或者接受统计课程, 进行统计实践.  
    2. 预先仔细计划数据分析过程, 避免上文中提到的误解和错误. 在你开始收集数据之前多与统计学者沟通.  
    3. 如果在科学文献中发现常见错误, 如对p值的误读, 就用你手中的统计教科书对该作者示之以颜色.  
    4. 督促科学在教育和出版方面的改革. 这是我们的研究领域, 我们必须对此予以重视. 


## 笔记
### 基础和检视阅读需要回答的问题
1. 书的主题是什么?
    * 科学统计和真实情况的差距
2. 整体来说, 这本书到底在谈些什么
    * 统计会有大量误区
    * 整体的举例集中在医学上, 医学
4. 这本书说得有道理吗?
    * 我还是比较认同的.
    * 统计是从数据中中获得有意义的一种重要方式. 只要合理使用就好. 理性和准确的判断是重点.
5. 是全部有道理, 还是部分有道理?
6. 这本书跟你有什么关系? 
    * 作为一个程序员, 统计暂时还没有大量用到
    * 进入ai部分

### 分析阅读需要回答的问题
1. 书中关键字?
    * p值
    * 统计误区
    * 置信区间
2. 作者的论述是什么?
    * p值不是万能的, 在生活中却很有用
    * 统计方式和概率的计算会和真实永远存在大量的偏差
    * 置信区间要比p值更加可信
3. 作者已经解决了哪些问题, 还有哪些是没解决的. 再判断哪些是作者知道他没解决的问题?
4. 否定和肯定作者.


### 提出新的问题并解答.
* p值定义: 
    * wiki定义: p值是指在一个概率模型中，统计摘要（如两组样本均值差）与实际观测数据相同，或甚至更大这一事件发生的概率 。换言之，是检验假设零假设成立或表现更严重的可能性。p值若与选定显著性水平（0.05或0.01）相比更小，则零假设会被否定而不可接受。然而这并不直接表明原假设正确。通常在零假设下，p值是一个服从[0,1]区间均匀分布的随机变量，在实际使用中因样本等各种因素存在不确定性。产生的结果可能会带来争议。
    * 百度百科定义: P值是用来判定假设检验结果的一个参数，也可以根据不同的分布使用分布的拒绝域进行比较。由R·A·Fisher首先提出。P值（P value）就是当原假设为真时所得到的样本观察结果或更极端结果出现的概率。如果P值很小，说明原假设情况的发生的概率很小，而如果出现了，根据小概率原理，我们就有理由拒绝原假设，P值越小，我们拒绝原假设的理由越充分。总之，P值越小，表明结果越显著。但是检验的结果究竟是“显著的”、“中度显著的”还是“高度显著的”需要我们自己根据P值的大小和实际问题来解决。
    * 书中定义: 在无效或无差异的零假设下, 检验统计量取当前值及(沿备择假设方向)更加极端值的概率. 也就是, 样本数据显示的差异等于甚至超过实际观测到的差异的概率. 
    * 书中给的含义: p值不是用来测度你多么正确, 或者这个差异有多重要. 反之, 它是对"意外"的测度. 如果假设药物无效, 那么也只能用运气来解释两组的区别. 然后p值越小, 试验结果是意外或因为运气的可能性越大——或者说你的假设就是错误的, 新药的确有效. 
* 置信区间定义:
    * wiki定义: 是对产生这个样本的总体的参数分布（Parametric Distribution）中的某一个未知参数值，以区间形式给出的估计。相对于点估计（Point Estimation）用一个样本统计量来估计参数值，置信区间还蕴含了估计的精确度的信息。在现代机器学习中越来越常用的置信集合（Confidence Set）概念是置信区间在多维分析的推广. 置信区间在频率学派中间使用，其在贝叶斯统计中的对应概念是可信区间（Credible Interval）。两者建立在不同的概念基础上的，贝叶斯统计将分布的位置参数视为随机变量，并对给定观测到的数据之后未知参数的后验分布进行描述，故无论对随机样本还是已观测数据，构造出来的可信区间，其可信水平都是一个合法的概率；而置信区间的置信水平，只在考虑随机样本时可以被理解为一个概率。
    * 百度百科: 置信区间是指由样本统计量所构造的总体参数的估计区间。在统计学中，一个概率样本的置信区间（Confidence interval）是对这个样本的某个总体参数的区间估计。置信区间展现的是这个参数的真实值有一定概率落在测量结果的周围的程度，其给出的是被测量参数的测量值的可信程度，即前面所要求的“一个概率”。
    * 书中定义: 和p值功能相同, 置信区间的优势提供了更多的信息而且可以直接阐明. 一个置信区间包含一个点估计以及这个估计的不确定性. 置信区间可以将结论中的不确定性定量, 而且比不能说明任何效应量的p值提供更多的信息.
* 统计方式和概率的计算会和真实永远存在大量的偏差, 书中对这一点通过大量证据的论证
* 参数太多导致人无法去分析, 就会限定统计范围,导致和现实存在了偏差. 
    * 给我四个参数我可以拟合出一头大象, 再给我一个参数我可以让大象鼻子动起来
* 统计中两个重要错误
    1. 第一类错误(false positives), 就是将无效说成有效(取伪);
    2. 第二类错误(false negatives), 则是将有效判断成无效(弃真). 
    3. 在一定程度上, 第一类错误和第二类错误是一枚硬币的两面. 如果我们比较激进, 则容易犯第一类错误;如果我们过于保守, 第二类错误会主动找上门来. 
* 在统计的采样的不全面和人为的偏见,误解,利益纠葛 最终会反映在结果中, 而这个结果会作为一个准确结论会影响人的判断. 这种就产生的大量的利益. 感觉美国FDA针对药片的双盲检测就是一点一点减少各种人工统计误差.
* 不要轻易的使用简单的统计就下结论, 当进入测验和检验的学科要好好学学统计之后再开始. 
