# 信号与噪声:大数据时代预测的科学与艺术

> (2018/5/18-2018/5/29)

> 第一遍阅读,读书笔记时间: 2018/5/29

## 关键词
, #信号 #纳特 #西尔弗 #复杂 #统计 #预测 #联系 #内在联系


1. 人们一下子接触到大量的新思想, 这难免会产生诸多混淆. 信息的增长速度远远超过了人们处理信息和分辨信息的速度. 共享信息的不断增长反而加速了民族和宗教的孤立进程, 其速度之快不禁让人瞠目结舌. 面对"过量的信息"时, 我们会本能地进行筛选, 选出喜欢的, 忽略其他的, 与同道中人为友, 与意见相左之人为敌
2. 莎士比亚借西塞罗的话警示我们, "(可是)人们照着自己的意思解释一切事物的原因, 实际上却和这些事物本身的目的完全相反". 这句话对于所有正在对自己新发现的大量信息进行选择的人, 都不失为一条好的建议. 人们很难从干扰他们的噪声中分辨出有用的信号. 数据展示给我们的通常都是我们想要的结果, 而且我们通常也能确保这些数据令我们皆大欢喜.
    * 人是存在偏见, 对一个问题是有有好恶之选的
3. 科学发展比经济发展更难判定, 但科技进步有一大标志, 即专利的数量, 尤其是与研发投资相关的专利数量. 如果一项发明的成本降低了, 这就表明我们善于利用信息, 并将其转变为知识. 而如果发明的成本增加了, 那就说明我们正在噪声中寻找信号, 这无疑是在错误的方向上浪费时间.
4. 《连线》杂志的前主编克里斯·安德森曾经在 2008 年的一篇文章中说: "**数量庞大的数据会使人们不再需要理论, 甚至不再需要科学的方法.** "
    * 现在数据分析会是这样吗? 之前在solidot上看的一篇简文所说的, [机器学习是 “炼金术”](https://www.solidot.org/story?sid=56492), "创建者并没有完全理解那些额外部分有什么好处"
5. 我的成功也只是因为我在某种程度上比较幸运, 一是尽管出现了本书中提到的一些错误, 但还是取得了成功;二是选对了调查案例.
6. 如果信息的数量以每天 250 兆亿字节的速度增长, 其中有用的信息肯定接近于零. 大部分信息都只是噪声而已, 而且噪声的增长速度要比信号快得多. 有太多假设需要验证, 有太多数据需要发掘, 但客观事实的数量却是个相对恒量
    * 信息过多, 已经无法验证数据的真实性了.
7. 你们中有些人也许对我此前提到的一个前提感觉不舒服, 现在我来澄清一下这个前提: 我们永远都不可能做出完全客观的预测, 因为这些预测总会带有主观色彩.
8. 但是, 本书对"根本不存在客观真理"这一虚无缥缈的说法完全不赞同. 相反的, 本书认为要做出准确的预测, 首要的前提就是坚信客观真理的存在, 并且执着地追寻它. 而预测者的另一个承诺, 就是要认识到他无法穷尽对客观真理的认知.
9. 这种自以为是的做法会伤害整个金融体系. 道格拉斯·亚当斯在其著作《银河系漫游指南》一书中写道: "**可能会出错的事情和完全不可能出错的事情之间的主要差别在于, 一旦这件完全不可能出错的事情最终出了错, 这个错误往往无法挽回或者根本无法补救.** " 既然拥有科学, 精确的预警信息, 评级机构的预测模式为何还会错误百出, 预测水准如此低下呢?
10. **评级公司的问题在于, 它们无法区分风险和不确定性的不同, 或者它们对两者间的差别根本就不关心.**
11. 希勒对荷兰与挪威等几个国家几百年来的数据进行了研究, 结果发现, 一旦房地产行业的发展超出人们的负担能力, 房地产市场必将崩盘.
    * 必将崩盘的时间有没有一个好的预测. 大家开心一下.
12. 信息不对称将导致市场瘟疫, 商品质量会下降, 市场将充斥着非法的卖家和急切且轻信的买家.
13. 但问题是, 20000 次出行记录没有一次是像这次醉酒驾车的, 你的醉驾样本数量不是 20000 次, 而是零次. 因此, 用先前的经验预测此次驾车的风险是毫无根据的. 这个例子就解释了什么是"非样本"问题.
    * 一个很好的问题, 人在面对未知时是如何解决的, 现在程序是如何做的,考样本支持吗? 那用于会有问题.
14. 在信息时代我们面临的一个重大挑战, 就是全球的知识总量在增加, 而我们实际掌握的知识和自认为掌握的知识之间的鸿沟却越来越宽.
15. 刺猬属于 A 型性格的人, 他们相信"凭一技之长而无穷", 认为自己掌控着世间真理, 认为自己就是万物的法则, 切实保障着社会的运行. 比如马克思和阶级斗争, 弗洛伊德和潜意识, 或是马尔科姆·格拉德威尔和"引爆点"等.  而狐狸属于一种好斗的人, 他们认为"千伎百俩而有尽", 解决问题有许多方法. 他们对于琐碎, 不确定, 复杂或是有分歧的意见更加有耐心. 如果说刺猬是猎手, 总在不停地寻找大型猎物, 那么狐狸更像是一个采集者.
    * 我的性格可能是刺猬吧.
16. 如果你的预测结果每天都会出现巨大的波动, 那可能就是一个不好的预示——不是设计的模型很差劲儿, 就是你的预测对象根本不具备可预测性
17. 就像一组各持己见的人真正要做的那样——他们会客观地对待所有信息, 而绝不会把某一条信息当成金科玉律.
20. 因为缺乏这样的理论认识, 地震学家只能采取纯统计方法预测地震. 你可以像鲍曼一样, 在自己的模型中创设一个名为"压力"的数据变量. 由于无法直接对其进行测量, "压力"这一变量只能表达为过去发生的地震的一个数学函数.
23. 这种解释似乎让情况一目了然, 但很多预测者完全无视这个问题. 研究者拥有很多统计方法, 可这么多的方法却没有让他们增加一点科学态度, 减少一点幻想, 而是像充满幻想的孩子在天空中寻找动物形状的云一样. 数学家约翰·冯·诺伊曼谈到这个问题时曾说: "**我用 4 个参数就能拟合出一头大象, 用 5 个参数就可以让这头大象甩动它的鼻子.**"
24. 有这样一个被引用了无数次的笑话: 一位统计学家趟过一条平均水位不足 1 米深的河时, 竟被淹死了. 此次洪灾, 美国国家气象局的预测模型给出的水位平均值是 14.9 米, 但水位只要稍高一点, 就会淹没整个城镇.  自此以后, 美国国家气象局开始逐渐意识到向公众准确, 诚实地传达不确定性的重要性. 然而, 其他领域的预测者几乎都没有秉持这种态度, 在预测经济运行状况时尤其如此.
25. 就这一点而言, 经济学家并非特例. 这样的做法已成为预测行业的行规: 那些专家既不擅长诚实地描述预测中的不确定性, 对这种做法也不大感兴趣. 过度自信的预测体现出的这种特性在其他许多领域也显露出来, 包括医学研究, 政治科学, 金融学以及心理学. 不论是靠人的判断进行预测（如菲利普·特罗克等政治科学家的预测案例）, 还是用统计模型进行预测, 似乎都能找到过度自信的影子.
26. 大多数人都听说过这句格言: "**相关性并不是指因果关系.**"两个变量之间存在统计学关系, 并不代表两者互为因果.
    * 相关性我个人理解为大概率两个事物是有内在联系的的, 但谁是因谁是果, 或者互为因果就需要认真分析了.
27. 经济增长依靠的大多是激增的政府和消费者债务, 还有各种资产价格泡沫. 再先进的经济也没有神授的权利可以使自身按照"大缓和"时期的增长率发展: 20 世纪 80 年代, 日本经济的年增长率为 5%, 而此后的增长率仅为 1%.
28. 忽视数据通常表明预测者过于自信, 或是在对自己的模型进行过度拟合——不是为了使预测更加准确, 而是为了炫耀.
29. 抵押贷款可能造成的损失所引发的宏观经济风险要远远超出公认的水平……这种宏观经济的后果可能会相当戏剧化. 如果负债经营的投资者看到贷款的总损失达到 2 000 亿美元, 他们可能就会把借款相应地缩减 2 万亿美元. 这是一个很大的打击……显而易见, 这样的打击会引发严重的经济衰退, 或是长期的经济萎靡.
31. 当他们试图利用实验再现医学期刊中的阳性结果时, 却发现约 2/3 的结果都无法复制. 检查一项研究发现是否真实的另一条途径是, 看其在真实世界中能否做出准确的预测, 正如本书所示, 大多数情况下, 这些发现都无法做出准确的预测. 各个领域, 从地震学到政治科学, 预测的失败率实际上相当高.
32. 这也是为什么我们的预测在大数据时代更容易失败. 拥有的信息量呈指数增长, 需要验证的假设也正在以同样的速度增长.
33. 实际上, 贝叶斯定理有一个特性, 即随着时间推移, 证据越来越多, 我们的观念也应该彼此交合
34. 从理论上来讲, 科学就应该这样产生作用. 达成共识的科学概念难以琢磨, 但真理越辩越明, 新证据不断出现, 科学观点总能汇聚到一起并且向真理逼近, 一如股市的曲折反复
35. 香农觉得计算机下棋赢了人类并非必然. 相反, 他认为计算机有以下 4 个优点:  1. 计算速度快.  2. 不会犯错, 除非编程时就编入错误.  3. 不会偷懒, 在分析招数, 分析可能位置时不会半途而废.  4. 不带感情色彩, 不会赢了一步就过度自信以致失去胜势, 或是遇到困局就沮丧, 劣势其实是可以逆转的.  香农认为, 计算机的这些优点可以与人类具备的 4 大优势相抗衡:  1. 思维灵活, 解决问题知道变通, 不会按部就班.  2. 拥有想象力.  3. 懂推理.  4. 会学习.
36. 这种情况并不是一句"完美是优秀的敌人"就能概括的
    * 出自伏尔泰
37. 通过调整这些参数并观察调整后的变化, 坎贝尔对"深蓝"进行过多次试验. 但有时"深蓝"还是会犯错, 会出现一些奇怪的, 出人意料的走法. 在这种情况下, 坎贝尔只得询问老程序员: 新出现的走法究竟是程序的特征——是一个预示着其技巧正在提升的顿悟时刻, 还是程序中的漏洞?
38. 这次失败让乌尔加利斯沮丧万分, 从此彻底停用了这个棒球程序.
    * 人的失误是可以原谅的, 但是机器为什么不可以原谅?
39. 在这个不确定的世界上, 我们仍是不完美的生物. 即使作了糟糕的预测, 我们也永远不会知道这是自己的错误还是预测模型的缺陷, 或者只是因为我们不够走运. 最接近的近似解, 就是达到一种噪声与信号的和谐状态, 两者缺一不可, 我们要学会欣赏它们.
40. 非理性交易者和娴熟交易者之间存在共生关系, 正如在扑克牌游戏中, 牌桌上需要一些新手, 这样出色的玩家才有利可图. 在金融著作中, 非理性交易者被称为"噪声交易者".
41. 噪声交易者让金融市场交易的存在变成可能, 这样我们才能观察金融资产的价格. 但是, 噪声交易者们也导致市场无效运转……总体来看, 噪声会使那些金融或经济市场运转方式的实用理论或学术理论难以检测. 大多数时候, 我们都在摸着石头过河.
43. 复杂性, 不确定性和一致意见的重要性是本书的核心主题, 每一点都值得认真倾听.
44. 有些事是已知的已知, 即我们清楚自己知道它. 有些事是已知的未知, 即我们清楚自己不知道它. 有些事是未知的未知, 即我们并不清楚自己不知道它.  唐纳德·拉姆斯菲尔德
45. 弗拉基米尔·列宁曾经说过: "恐怖主义的目的是为了使人恐惧. "这个观点看似普通, 其实内涵深刻: 恐怖主义并不是单纯地想让死亡人数最大化;相反, 恐怖分子是想使某个群体的恐惧情绪最大化, 从而让该群体转变行为方式. 死亡和破坏都是达到这一目标的手段. 拉姆斯菲尔德也曾对我说过: "恐怖分子可能会通过杀人达到目的, 但杀人并不是最终目的. "
46. 我们的初始观点从何而来呢? 从理论上讲, 我们希望将初始观点建立在过去的经验——最好是社会经验——的集合之上. 这是市场可以扮演的有用的角色之一. 市场当然不是完美无瑕的, 但绝大多数时间内群体判断都要优于个体判断. 市场在权衡新迹象的时候形成了一个好的起点, 在你还没有在某个问题上花费太多时间的情况下, 尤其如此.
48. 不断犯错, 不断尝试, 这或许是贝叶斯定理应用起来最容易的一个原则了: 进行大量的预测. 你可能不会将自己的公司或是生活赌在预测上, 尤其是刚起步的时候, 但这是唯一能够让自己取得进步的方式.
49. 验证想法的频率越高, 就能越早地避开这些问题. 眺望大海, 等待着灵感迸发, 想法就出现了, 这是电影里才会有的情节. 在真实世界中, 即使已经准备就绪, 想法也很少会出现, "大"想法就更不用说了. 更加常见的情况是, 我们只能凭借微小的, 渐进式的, 有时甚至是偶然出现的想法取得进步.
50. 预测之所以难做与其之所以重要的原因是一样的: 预测是主观事实与客观事实交汇的产物. 从噪声中区分信号既需要科学知识, 也需要自知之明, 比如, 平静地承认我们无法预测的事物, 勇敢地说出我们能够预测的事物, 还有就是明智地区分二者的不同.


-------

* 信号和噪声是一样的, 对不同人来说可能信号和噪声就会互换. 在上大学的时候, CDMA/CDMA2000的时候, 说在传输过程中信号接近白噪声, 只有知道解码秘钥的人才可以知道信号中的数据是什么. 而在超大量的数据面前, 对同一事物的描述有着大量的描述, 导致所有数据杂合再一起成为白噪声, 没有人知道啥事有用的了.
* 书中阐述了很多预测, 在面对已有数据, 要做预测需要知道哪些是有用的数据(信号), 哪些是干扰或无用的数据(噪声). 而关于数据判断需要的是大量的个人知识和经验去判断, 而这个作为会存在个人偏见, 最终又引入了新的噪声.
* 曾经有人问过一个问题"在做数据处理的时候, 数据量是减少了还是增多了". 我的答案是: 不确定, 取决于做出就处理的人, 他是否可以基于数据进行分析可以把自己的知识和经验填充进去, 如果知识和经验够丰富数据量就会增多, 不够丰富就会减少. 总体数据是在减少的, 在数据分析和处理的过程中, 对数据的合并和抽象会导致信息的丢失和无用数据的增加, 这需要人靠经验去矫正.
* 随之科技的发展每天产生的数据量已经庞大至极, 但是是否所有数据都有用, 在不同人的眼中就会有不同的判断, 知乎上有个人做金融的, 靠着公司的财报可以在美股上捞一笔. 而对大多数人是做不到的, 这个需要大量的专业背景和行业经验. 但是随之时间各种数据越来越多, 有用的数据并没有增加. 而人的能力是有限的(各个方面, 记忆力, 思考力, 逻辑深度, 判读力等), 但是在无限的数据面前人可能已经感到了恐惧, 如何有效的面对这些数据和分析数据成为一个人的未来的基本技能. 现在大量的推荐算法感觉就是一个筛选工具, 一方面在减少一个人要面对的数据量但是同时也使个体更加偏执了.
* 发现有用数据是否可以成为未来文本或数据分析的一个重要组成部分. 现在包括学术论文也有大量无意义的内容, 很多还是无法验证的. 如何从海量数据中找到真实是数据是否存在通用的模型去处理. 研究研究知识图谱看看可以快速过滤数据吗?
* 在之前看机器学习有关的书(简单了解, 已经忘干净了),  想到一个问题, 为什么现在的机器学都是大数据的, 为啥没有小数据的. 但是人(动物)的学习是小数据的, 只要有很少的数据就可以学会某件事, 但是机器做不到. 我给出了一个答案是人(动物)不是小数据学习的, 人(动物)是一个超庞大的数据集训练出来的, 他不是靠着单一个体的生命进行的是靠着整个地球上所有生命体用了几亿年的时间, 靠着最慢的一个方式--生命演化实现了, 在高等生物可以靠着极小的数据集合实现高效的学习. 但是得到整个学习的算法用了记忆年和无数的生命才成功演化出来. 当前的算法太过简单和计算能力有限无法实现这种事情.
* 我有两个问题之后尝试去尝试解答:
    * 人的失误是可以原谅的, 但是机器为什么不可以原谅? (是不是)
    * 人类在面对未知是如何处理的? (未知是完全没有经验可以阐述的, 经验不是指个人经验是指全人类集合体经验)
* 2021年回答这两个问题
    * 人的失误是可以原谅的, 但是机器为什么不可以原谅?
        * 是
        * 潜意识中机器是确定的论的一种体现, 它没有思想和灵活, 一切都是已经确定的了的程序, 所以对问题容忍度就会小于人类. 人是可以承担责任和接受惩罚的, 而机器是无法承担责任也无法接受惩罚. 人的失误是可以改进的, 而机器不可以.
    * 人类在面对未知是如何处理的?
        * 不处理, 优先考虑解决眼前的问题. 更大问题交给未来更聪明的人来想办法.
