---
id: 20241130205920_8fd5f96c3b774489
aliases:
- 智人之上
- 链接
- 从石器时代到AI时代
date: "2024-11-30"
authors:
- "[以色列] 尤瓦尔·赫拉利"
startingTime: "2024-11-19"
endTime: "2024-11-30"
published: "2024-09"
tc:
- readbook
ISBN: 9786263558724
douban: "https://book.douban.com/subject/37036155/"
goodreads: "https://www.goodreads.com/book/show/218700240-ai"
neodb: "https://neodb.social/book/4j779E4N7x5b60UpgiogOK"
tags:
- 法治
- 民主制度
- 独裁制度
- 信息流
- AI
- 信息差
---

# 智人之上

## 目录
```
封面
【开场白】前方的路满布荆棘
第一部 人类形成的网路
    第１章 资讯是什么？
    第２章 故事──无限的链接
    第３章 文件──纸老虎也会咬人
    第４章 错误──绝对正确是一种幻想
    第５章 决择──民主与极权制度简史
第二部 非生物的网路
    第６章 新成员──电脑与印刷机不同之处
    第７章 不停歇──网路监控无所不在
    第８章 易出错──存在于电脑间的现实
第三部 电脑政治学
    第９章 民主制度──我们还能对话吗？
    第10章 极权主义──权力归于演算法？
    第11章 矽幕──全球帝国、或是全球分裂？
【结 语】打造自我修正机制
志谢
版权页
```

## 主旨

在 AI 大模型出现后, 书中讲了 AI 会对不同政治体制产生那些影响. 可能会有好的, 也可能会有不好的.

## 标记

1. 人类把自己这个物种命名为智人（Homo sapiens）──有智慧的人类。但我们究竟配不配得上这个称号，实在还有待商榷。
2. 由于滥用各种能力，人类已然来到生态崩溃边缘。而且人类现在还忙著创造像是人工智慧（AI）这样的新技术，AI 可能逃脱人类的掌控，反过头来奴役或消灭人类。而人类非但没有团结起来，应对这些存亡挑战，还让国际紧张局势不断升温、全球合作更加困难，各国大量储备末日武器，新的世界大战似乎确实可能发生。 要是我们智人真的那么聪明、有智慧，为什么这么爱走上自我毁灭的道路？
3. 从更深的层次而言，虽然人类累积了大批资讯，内容从 DNA 分子到遥远的星系，无所不包，却似乎仍然无法回答生命最重大的问题：我们究竟是谁？该追求什么？什么才是所谓美好的生活？我们又该怎样过上这样的生活
4. 纵观历史，许多文化传统都提到人类本性上就有些致命缺陷，会让人想要追求自己根本不知道如何处理的力量。希腊神话里，就提到有个男孩费伊登，发现自己原来是太阳神赫利俄斯的儿子。费伊登为了想要证明自己是神祇之后，希望能享有一日特权，去驾驭太阳马车。
5. 时间过了两千多年，工业革命迈出了第一步，机器开始在许多工作上取代人力，歌德也写出了类似的警世寓言，名为《魔法师的学徒》。
6. 就擅自施展了魔法师的一道咒语，让一把扫帚来帮忙打水。但小学徒还没学过怎样叫扫帚停下来，结果就是水愈打愈多，整个工作坊都快淹没了。情急之下，小学徒拿斧头把魔法扫帚砍成两段，但这下却变成了两把扫帚，一起打水灌向工作坊。等到魔法师终于回来，小学徒向他求救：“我召唤了魔法精灵，可是却停不下来。”魔法师立刻出手停下咒语，让水别再淹下去。 这给学徒（ 也是给人类）的教训，再清楚不过：永远别去召唤自己控制不了的力量。
7. 学徒与费伊登的寓言，能让我们这些二十一世纪的人学到什么教训？人类显然是没听进去，除了已经让地球气候失衡，还召唤了为数几十亿的魔法扫帚、无人机、聊天机器人程序、以及其他各种演算法精灵；这些精灵不但可能不受控制，还可能让各种意想不到的结果，如大水滚滚而至。
    - 这里作者讲述了两个故事, 分别是 [法厄同驾驶太阳马车](https://zh.wikipedia.org/zh-tw/%E6%B3%95%E5%8E%84%E5%90%8C) 和魔法师的学徒, 故事大致就是"一个人没有能力, 但是获得了使用神力的权限, 最后被神力控制并引发灾难"
8. 不管是费伊登的神话故事、或是歌德的叙事诗，之所以无法提供有用的建议，是因为都误解了人类取得力量的方式。在这两则寓言里，**都是有某个人得到了巨大的力量，再因为傲慢与贪婪而误入歧途**。从这类寓言得出的结论，就仅是：因为个人心理出了问题，于是使人滥用权力。但这样的分析实在太过粗糙，忽略了人类整体的力量从来就不是个人想要就能得到的结果。人类的力量，总是得自于大批人类之间的合作。 因此，真正造成人类滥用力量的原因，并不在于个人的心理。毕竟人心除了有贪婪、傲慢与残忍，其实也有著慈爱、同情、谦卑与喜悦。确实，如果去看那些最糟糕的人，会看到贪婪与残忍大行其道，使恶人滥用力量。**但究竟是为什么，才让人类社会选择把力量交付给这些最糟糕的人？像是在1933年，大多数德国人也并非精神失常，为什么会投票给希特勒？**
    - 可以从 "[[权力如何崩坏人性]]" 这本书中给出一个答案, 最糟糕的人在夺得权力之前是最好的演员. 一个系统需要有能力把不合适的人从权力位置上赶下去, 而不是尝试选择一个完美的人然后给他权力.
9. 人类之所以喜欢召唤自己控制不了的力量，问题不在于个人的心理，而在于人类大规模合作时的一种特性。**==本书想提出的一项主要论点就是：虽然人类能够建立大型合作网路，以此取得巨大的力量，但这些网路的建构方式就注定了这些力量的运用，常常并不聪明。所以，人类遇上的问题，其实是个网路问题。==**
    - 核心要讲述的问题.
10. 虽然就个人而言，通常会了解的是关于自己与世界的真理真相，但大型网路却会使用各种虚构故事与幻想，来束缚群众、创造秩序。举例来说，我们过去就是这样走向了纳粹主义与斯大林主义，两者都形成了格外强大的网路，并由格外令人迷惑的想法加以支撑维系。正如英国小说家奥威尔的名言所述：无知就是力量。
11. 纳粹主义与斯大林主义的政权基础，就是一些令人痛苦的幻想与毫无羞耻心的谎言，但这在历史上实在称不上特殊，也不代表它们注定崩溃。**纳粹主义与斯大林主义可说是历史上，人类创造出最强的两大网路。**
    - 基本没有听说过"希特勒主义"都说的是"纳粹主义", 而说到苏联的独裁系统都说的是"斯大林主义"而不是"共产主义"或"苏共主义", 为什么没有将两者后两者挂钩呢?
12. **到了二十一世纪，过去希特勒和斯大林没做到的，很可能会由一些新的极权主义政权接手完成：==创造出一个全知全能的网路，甚至能够阻止后代去尝试揭露其中的虚构与谎言==**。我们不该以为，既然这些网路的基础都只是一些虚构妄想，就注定会失败崩溃。想要避免这些网路终获成功，我们人民自己可得付出相当的心力。
13. 我们之所以很难看清这些妄想网路究竟拥有多大的力量，是因为我们对于大型资讯网路的运作方式（ 无论资讯是真实或虚构），有一项整体上的误解，我称之为“**==天真的资讯观==**”。如果从费伊登神话与《魔法师的学徒》这样的寓言故事来看，会觉得我们是对个人的心理抱持悲观；但如果从天真的资讯观来看，则会觉得我们对于大规模人类网路实在太过乐观。 **==这种天真的观点认为，大型网路能够比个人搜集与处理到更多的资讯，就能更了解医学、物理学、经济学等诸多领域，于是这样的网路不但力量强大，还无比明智。举例来说，搜集到更多关于病原体的资讯之后，药厂与医疗保健业者就能抓出更多疾病的真正病因，于是研发出更强大的药物，找出更明智的用药方式。==**
    - 天真的资讯观是作者在书中多次提到的一种"只要有足够多的信息就可以找到'真理'"观点. 时间是复杂的, 不要抱有这种"天真的资讯观"
14. **==在这种观点看来，有了够多资讯，就能得到真理真相；有了真理真相，就能得到智慧与力量==**。相较之下，如果是“无知”，似乎并不会带我们去得到什么。虽然在某些历史上的危机时刻，偶尔就是会出现基于妄想或欺瞒而形成的网路，但就长期看来，这些网路必然会败给那些比较真实且可信的网路。如果医疗保健业者无视病原体的资讯，又或是药厂刻意散播不实资讯，到头来肯定都会输给那些更聪明运用资讯的对手。 但这样一来，也就让天真的资讯观相信，那些基于妄想的网路肯定只是异常，而一般大型网路通常都值得信赖，我们肯定能好好运用大型网路的力量。
15. 这套天真观点也承认，在从资讯到真理真相这条路上，有很多事情可能出问题。例如我们在搜集与处理资讯的时候，可能犯下一些无心的错误。可能会有些坏人，出于贪婪或仇恨，而想要隐藏重要事实、或是试图欺瞒。因此，有些时候资讯并非导向真理真相，反而是导向错误。像是资讯不完整、分析有错误，又或是有人刻意散布不实资讯，都可能让人误入歧途，甚至连专家也可能对某种疾病的真正成因，产生误判。
16. 就算我们都能准确分析资讯、找出重要事实，也无法保证我们因此得到力量之后，能够有智慧好好加以运用。**==一般说到智慧，大概会认为就是能“做出正确的决定”，但所谓“正确”仅是一种价值判断，不同的个人、文化或意识型态就会有不同的想法==**。譬如科学家发现了新病原体之后，一种可能是会想研发疫苗来保护人类，但要是这位科学家（ 或是背后政治上的头头）抱持著种族主义的意识型态，一心认为某些种族就是较为低等、应该消灭，这项新的医学知识就可能用来研发成生物武器，夺走数百万人的生命。
17. 但就算是这种情境，**天真的资讯观仍然会认为，只要有更多资讯，应该至少还是能解决部分问题**。在天真的资讯观看来，只要仔细检视，就会发现人之所以会有不同的价值观，要不是因为资讯还不足，就是有人刻意传播不实资讯。天真的资讯观认为，之所以会有种族主义者，只是因为这些人得到的资讯还不够，还不知道那些在生物学与历史上的事实。这些人是因为误以为生物学上真的能把人分成不同的“种族”，才会被各种虚假的阴谋论洗脑。因此，如果想要解决种族主义的问题，解方就是要向大众提供更多关于生物学与历史的事实。虽然这可能得花些时间，但在这种自由的资讯市场上，真理真相迟早都能胜出。
    - 资讯的充足不代表资产(金钱, 地位)的充足, 不平等很多时候体现在"资讯"的不充足上, 但实际上是身份不同导致的.
18. 2009年11月，美国总统欧巴马到上海访问，也表达了同样的看法，向中国东道主表示：“我对科技深具信心，而且在谈到资讯流动的时候，我也对开放性深具信心。我相信，资讯流动愈自由，社会就能愈强大。
19. 著名未来学家暨创业家库兹威尔（Ray Kurzweil）2024年出版的《奇点已更为临近》，回顾了信息技术的发展史，结论认为：“现实就是，随著科技呈现指数增长式的改进，生活几乎所有方面都在逐渐变得更好。”书中回顾人类史上的重大发展，库兹威尔以印刷术的发明为例，认为信息技术从本质上就往往会带出“一种良性循环，让人类福祉的几乎所有面向，都得到改进，包括识字、教育……财富、卫生、健康、民主，以及减少暴力。”
20. 人类坐拥大批数据（或许也正出于这个原因），却还是在不断向大气排放温室气体、污染河海、砍伐森林、破坏栖地，让无数物种灭绝，甚至还危及了自己这个物种的生态基础。人类也生产著愈来愈强大的大规模毁灭性武器，从热核弹到末日病毒无所不包。人类领导者的手中，并不是没有关于这些危险的资讯，但他们非但没去合作试著解决，反而是让大家愈来愈靠近一场全球战争。
21. 库兹威尔也同意这种说法，他在《奇点已更为临近》表示：“AI 这项关键技术，将让人类得以应对各种迫在眉睫的挑战，包括克服疾病、贫穷、环境退化，以及人类的所有弱点。而我们就该负起道德上的责任，实现新技术的承诺。”库兹威尔很清楚这项技术潜藏著危险，也提出了详尽的分析，但他相信，这些危险都能得到减轻及解决。
22. 一项2023年的研究调查了二千七百七十八名 AI 研究者，结果也显示有超过三分之一认为，先进的 AI 有至少10%的几率会造成等同于人类灭绝一样可怕的结果。 在2023年，包括中国、美国与英国在内，有将近三十个政府签署了关于 AI 的《布莱切利宣言》（ Bletchley Declaration），其中就承认：“从这些 AI 模型最重要的功能，可能有意或无意间，会造成严重、甚至灾难性的伤害。”  虽然用的是这种仿佛描述世界末日的语词，但专家与政府并不是要让人联想到那些好莱坞的画面，好像有机器人造反，在街上奔跑射杀人类。这种情节一来实在不太可能发生，二来只会让人忽略真正的危险。专家真正要警告的，是另外两种情况。
    - 英国在布莱切利园召开为期2天的全球首场人工智慧（AI）安全峰会。首日议程结束后，英国、美国及中国大陆等28个政府代表以及欧盟签署通过“[布莱切利宣言](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023) [archive](https://web.archive.org/web/20241129141431/https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023) ”(The Bletchley Declaration)，矢言强化全球合作，因应AI安全议题
    - 没戏, 如果 AI 真的能伤害人类了, 那 AI 完全有能力实现对人的欺骗, 也就是说使用人类既有制度实现对人类的控制, 射杀人类这种方式太低效了.
23. 第一，AI 的力量可能会大幅加剧人类既有的冲突矛盾，让人类内斗不已。正如二十世纪冷战时期的铁幕，分隔出几个彼此敌对的势力，二十一世纪的矽幕（ 不再是铁丝网，而是由矽晶片和电脑程序组成）也可能区隔出不同的敌对势力，带出一场新的全球冲突。而这场 AI 军备竞赛将会制造出更具破坏性的武器，于是即使只是个小小的火花，也可能引发灾难性的大火。 第二，矽幕所分隔的，或许不是彼此敌对的人类，而是一边为所有人类、另一边则是我们新的 AI 领主。不论我们在哪里生活，都可能被一张看不透的演算法大网束缚，控制著我们的生活，重塑著我们的政治与文化，甚至是去改造我们的身体与思想；但人类却再也无法理解这些控制著我们的力量，更别说是要加以阻止了。
24. 要是二十一世纪真会有某个极权主义网路成功征服世界，背后的掌控者可能并不是人类的独裁者，而是某种非人类智慧。有些人以为，如果人类将会迎来极权噩梦，主要起源应该是在中国、俄罗斯、或后民主的美国，但这是对极权威胁的一种误解。事实上，不管是中国人、俄罗斯人、美国人、又或是其他所有人类，真正面对的是可能由非人类智慧带出的极权威胁。
25. 我在2016年出版《[[未来简史|人类大命运]]》，点出各种新信息技术对人类造成的部分危险。书中也指出，历史真正的主角一直都是资讯，而非智人，而且科学家已经愈来愈懂得采用资讯流的观点，除了用来看历史，也能用来看生物学、政治、以及经济学。不论动物、国家或市场，都可以算是资讯的网路，都会从环境中吸收数据数据，据以做出决策，进而又释放出更多数据数据。《人类大命运》也警告，虽然我们都希望随著信息技术的改进，能为人类带来健康、快乐、以及力量，但事实上，信息技术得到提升之后，却反而可能是让人类失去力量，也丧失身心健康。《人类大命运》假设，要是人类再不小心，就可能像是土块落入滚滚河水，直接消溶在资讯洪流之中；放眼到万事万物，人类只会是宇宙整体数据流里的一次小小涟漪。
    - 17 年读的这本书, 一点引向都没有了.
26. **如果是比较极端版本的民粹主义，会认为世上根本没有什么客观的真理真相，每个人都有“自身版本的真理真相”，并想要以此来压倒对手。以这种世界观来看，只有权力才是唯一的现实**。所有的社会互动都是权力斗争，人类真正感兴趣的也唯有权力。说自己对其他事物（ 例如真理真相或正义）感兴趣，只是用来取得权力的策略而已。 一旦民粹主义成功让人觉得资讯就是一种武器，就会让语文这件事受到损害。不论是“事实”这样的名词，又或是“准确的”、“真实的”这样的形容词，都会变得语义模糊，似乎无法指向某项共同的客观现实。这种时候，只要一谈到“事实”或“真相”，肯定都至少会让某些人想问：“你说的是谁的事实、谁的真相？”
    - 这种"民粹主义"可以理解成"犬儒主义", "虚无主义", "怀疑论"和"阴谋论"的混合体.
27. 这种**激进左派思想路线可以追溯到马克思，他在十九世纪中叶就主张：只有权力才是唯一的现实，资讯是武器**。马克思认为，那些菁英号称是在服务真理真相，但其实都只是为了追求狭隘的阶级特权。1848年的《[[2020/共产党宣言|共产党宣言]]》就说：“至今一切社会的历史都是阶级斗争的历史。自由民和奴隶、贵族和平民、领主和农奴、行会师傅和帮工，一句话，压迫者和被压迫者，始终处于相互对立的地位，进行不断的有时隐蔽、有时公开的斗争。” **这种对历史的二元诠释，认为人类的每一次互动都是压迫者与被压迫者之间的权力斗争**。这样一来，讲到有某人说了某句话，最重要的问题就不是“说的内容是什么？说的是事实吗？”而是“是谁说的？这有利于谁的特权？”
    - 现在看这种二元的革命史观或唯物史观真的没有能力很好的去解释世界和历史, 并且这种史观下存在这极强的先入为主的观点, 基于这种观点去解释历史获得结果只是宣传用的工具, 而不是历史本身; 这种解释方式也导致了很多历史无法解释, 因为只要解释就会出现很多前后矛盾的问题.
28. 但就像前几个世代的激进反建制运动，如今的民粹主义同样有道理不连贯、难以自圆其说的问题。如果权力是唯一的现实、资讯也只是武器，那谈到民粹主义自己，又该怎么说？他们是不是也一心只想夺权，是不是也总在对我们说谎，来骗取权力？ 面对这项难题，民粹主义试著用两种方法来解决。有些民粹主义运动会说，自己还是坚持著现代科学的理想、恪守经验主义对一切抱持怀疑的传统。他们告诉大众：没错，你永远不该相信任何机构制度或权威，包括那些自称是为了大众平民的政党与政治人物。你应该要“自己去研究”，只相信自己能直接观察到的东西。 这种激进的经验主义立场认为，虽然我们确实永远无法相信政党、法院、报纸、大学这些大型机构制度，但个人要是够努力，还是可以自己找出真相。
29. 只相信“自己的研究”可能乍听之下很科学，但其实等于认为世上没有客观的真理真相。我们在第4章〈错误──绝对正确是一种幻想〉就会看到，科学绝不是一项个人的追求，而是制度机构的合作。
30. 民粹主义提出的另一套解法，则是放弃现代科学透过“研究”寻找真相的理想，回头依赖神启或是神秘主义。基督宗教、伊斯兰教、印度教等传统宗教，常会把人类描绘成不值得信任、渴求权力的生物，唯有靠著某些“神性智慧”介入，才能了解真理真相。
31. **这套解法的另一种形式，则是呼吁大众信赖像是川普或波索纳洛这种魅力领袖；支持者会将这些领袖描绘得宛若神的使者，  或者是和人民有著某种神秘的链接。如果是一般政客，就是会对人民说谎，只为了获得自己的权力；而如果是这些魅力领袖，则成了人民的代言人，非但绝不会出错，还会揭露一切谎言。**
    - 民粹最后结论倒向了"个人魅力", 倒向了独裁统治者.
32. 所以，民粹主义一直会遇上的矛盾之一，就是一开始的时候，总是在警告大家“所有菁英都是为了争权夺利，十分危险”，但常常到头来又要求人民，把所有权力都托付给某个充满野心的人。
33. 本书第一部〈人类形成的网路〉，将会概述人类资讯网路的历史发展。这里并不是要依著世纪的进展，逐一全面讨论像是文字、印刷术、无线电这些资讯技术，而是希望透过研究几项范例，探讨各个时代建立资讯网路时，曾经面临怎样的关键困境，再看看当时不同的答案，怎样塑造出截然不同的人类社会。有些冲突的成因，我们一般会认为是出自于意识型态或政治立场的不同，但事实上，往往是出自于资讯网路有所出入。
34. 以第一部的历史调查为基础，本书第二部〈非生物的网路〉谈的是人类如今正在打造的新资讯网路，重点在于 AI 兴起所造成的政治意义。第6章〈新成员──电脑与印刷机不同之处〉、第7章〈不停歇──网路监控无所不在〉、第8章〈易出错──存在于电脑间的现实〉，讨论了世界各地最近的例子（ 像是2016至2017年社群媒体演算法如何在缅甸煽动种族暴力），以解释 AI 与过去所有信息技术的不同之处。之所以例子多半只取到2010年代、而未能论及2020年代，是因为要到了现在，才能说对于2010年代的事件，已经有了一些历史学的观点。 第二部提出的论点认为，人类正在创造一种全新的资讯网路，却从没好好想想这有何影响。这里的重点在于，这是一项从生物资讯网路到非生物资讯网路的转变。过去的罗马帝国、天主教会与苏联，都是依靠碳基的人脑来处理资讯、做出决策。但主宰新资讯网路的矽基电脑，运作方式截然不同。过去，碳基的神经元摆脱不了有机生物化学的种种限制，而无论如何，矽晶片都能轻松摆脱这些有机生物化学限制。所以，矽晶片能创造出的，会是永远不用睡觉的间谍、永远不会遗忘的金融家、永远不会死去的暴君。这将会让社会、经济与政治有怎样的改变？
35. 本书的第三部、也是最后一部〈电脑政治学〉，会来谈谈不同类型的社会，如何应对非生物资讯网路的威胁与承诺。像我们这样的碳基生命，还有没有机会能理解、掌控新的资讯网路？正如以上所提，历史绝非注定，至少在未来几年间，我们智人仍然有能力形塑自己的未来。

### 第一部 人类形成的网路

#### 第１章 资讯是什么？

1. 资讯的组成不一定要靠人造的符号。像是在《圣经》神话里的那场大洪水，挪亚之所以能知道洪水终于退去，是因为他从方舟里放出去的鸽子叼著橄榄枝回来了。接著上帝让一道彩虹出现在云中，做为祂立约的神圣记号，承诺不再用洪水淹没地球。鸽子、橄榄枝与彩虹，从此也成了和平与宽容的代表符号。
2. 在说过“[[理解媒介-论人的延伸|媒体即讯息]]”的麦克卢汉（Marshall McLuhan）看来，可能会说那只鸽子就是讯息。NILI 特工一得知那只信鸽遭捕，立刻把他们手里还有的信鸽全部杀掉埋了，因为当时只要还拥有信鸽，就等于透露了“自己正从事间谍行为”的讯息。 然而，这场信鸽大屠杀并没能拯救 NILI。这个间谍网在一个月内遭到破获，几名成员遭到处决，艾伦索恩也决定自杀，以免自己受不了酷刑而泄露 NILI 的机密。  所以，什么时候鸽子就只是单纯的鸽子、什么时候鸽子又是一则资讯呢？
3. 显然，资讯的定义绝不限于某种特定类型的实体物件。任何物件，像是星星、百叶窗、鸽子，只要放到正确的情境下，都可能成为资讯。所以，到底是什么样的情境，会把这些物件定义成资讯？
4. 天真的资讯观会说，只要情境是打算去寻求真理真相，这些物件就能定义成资讯。换句话说，只要是打算运用某个物件来找出真相，那么这个物件就算是资讯。这种观点链接了“资讯”与“真理真相”这两种概念，并且假设资讯的主要作用就是要把现实呈现出来。既然世界上有个现实就摆在那里，而所谓资讯就是能够呈现出现实的物件，我们当然就能用资讯来了解现实。
5. 天真的资讯观认为资讯就是要试著呈现出现实，如果成功，我们就会说这项资讯等于真理真相。虽然本书对于天真的资讯观多有批判，但对于“真理真相就是能够准确呈现出现实”这一点，倒是所见略同。但本书同时也认为，多数资讯并不是想要呈现出现实，而且真正能够定义资讯的，完全是另一套标准。无论是在人类社会，或是其他的生物与物理系统里，大多数的资讯并没有要呈现出任何东西
6. **==本书所谓的真理真相，代表的是能够准确呈现出现实的特定面向。要能说某件事是真理真相，前提是必须真的存在某个普世皆同的现实。而只要是宇宙中曾经存在、或即将存在的任何事物==**
7. 都是这个唯一现实的一部分。正因如此，真要找出真理真相的时候，应该人人其实都在同一条船上。虽然不同的个人、国家或文化可能有不同的信念或感受，但由于所有人都处于一个普世皆同的现实当中，所以不可能有不同的真理真相。这样一来，如果不相信普遍主义（ universalism，或称为普世主义），等于是不相信有真理真相。
    - 这个"普世价值"是一个固定的含义呢? 还是不同国家可以自己定义, 在塔利班控制的阿富汗"普世价值"不会好到那里去的. 同样神棍哈梅内伊, 巴沙尔·阿萨德这种畜牲嘴中的"普世价值"一定不是什么
8. 然而，**真理真相其实并不直接等于现实，因为不论一则叙事多么贴近真相，仍然无法真正呈现出现实的所有面向**。譬如 NILI 特工写著“加萨有一万名鄂图曼士兵”，而且加萨也确实有一万名士兵，虽然这准确点出了某面向的现实，却也还忽略了许多其他面向。光是去计算某种实体的数量（ 不管计算的是苹果、橘子、还是士兵），这项行为本身就必然是把注意力集中在这些实体之间的相似性，但忽略了其中的差异性。  就“加萨有一万名鄂图曼士兵”这则陈述来说，是忽略了其中有多少是久经沙场的老兵，有多少是初上战场的菜鸟。一千名菜鸟搭九千名老兵，或是九千名菜鸟搭一千名老兵，在军事上的现实可是完全不同。
9. 重点是，就算能对现实提出最贴近真实的描述，也永远无法完整的呈现现实。每次想要呈现现实，都总会有一些面向遭到忽略或扭曲。所以，**所谓的真理真相，其实并不代表能够一比一的呈现出现实。所谓的真理真相，是一方面能够让我们专注在现实的某些面向，但另一方面也无可避免的会让我们忽略某些其他面向**。在描述现实的时候，绝没有任何一项描述能做到百分之百准确，但还是有某些描述会比其他描述更贴近真实。
10. 天真的资讯观还相信，如果想要解决错误资讯与不实资讯造成的问题，解法就是要有更多资讯。这种概念有时也称为“反制言论原则”：1927年，美国大法官布兰代斯（Louis D. Brandeis）在惠特尼诉加州案（Whitney v. California）就认为，要应对错误的言论，解方就是提出更多的言论，也认为只要自由讨论的时间一长，肯定能让所有谎言与谬论无所遁形。如果所有的资讯都是想要呈现出现实，随著全球资讯量不断成长，可以想像资讯的洪流就能揭露不时出现的谎言与错误，最后让我们对世界的理解更贴近真实。 就这个关键论点而言，本书强烈反对这种天真的资讯观。**==当然是有些资讯会想呈现现实、而且也算是成功，但这绝对不是资讯的定义要点。==**
11. 虽然天真的资讯观以为资讯必然需要与真理真相链接，但其实不然；资讯在历史上所发挥的作用，本来就不是要去呈现既有的现实，反而是要去链接各种不同的人事物（ 可能是夫妻、也可能是帝国），以创造出全新的现实。真正定义资讯的是“链接”，而不是“呈现”或“再现”：只要能将各个不同的点，链接成网路，就是资讯。**==资讯不一定是要告诉我们一些什么，而是要把人事物组织起来==**。例如，占星术把恋人放进一种占星组织；政治宣传把选民放进一种政治组织；进行曲则将士兵放进一种军事组织。
    - 资讯并不是为了寻找真相, 而是为了创造一个"组织", 在 [[人类简史]] 也提到了类似的观点.

#### 第２章 故事──无限的链接

1. 例如，以巴冲突的问题正是如此：有些人和政府不愿意承认以色列的存在，但也有另一批人和政府不愿意承认巴勒斯坦的存在。譬如在2024年这个时候，巴西和中国政府会说以色列和巴勒斯坦都存在；美国和喀麦隆政府只承认以色列的存在；阿尔及利亚和伊朗政府则只承认巴勒斯坦的存在。
    - 这个问题这么复杂吗? 但是那片土地以色列并没有完全控制, 那非控制区是属于那个国家的呢?
2. 事实上，几乎所有国家都曾至少短暂经历过这种争议阶段，最后才争取到独立的地位，证实自己存在。
3. 关于国家是否存在，这样的争议并无法透过 DNA 调查或声纳扫描这样的客观检测来定夺。与“动物”不同，“国家”并不是一种客观现实。在我们问某个国家是否存在的时候，是在提出一个关于主体间现实的问题。只要有够多人同意某个特定国家存在，这个国家就存在。接下来，这个国家也就有权能够进行某些事，像是和其他国家、非政府组织、又或是民间企业，签署各种具有法律约束力的协定
4. 就算是在太平时期，如果交换资讯的对象不只限于小游群的几十个人，而是整个部落网路，对智人来说也是大大有益。如果整个部落的某个游群发现了更好的矛尖制作方式、学会了怎样用某种稀有的草药来治疗伤口、又或是发明了能够缝衣服的针，都能迅速让其他游群也知道。虽然个别智人不见得比尼安德塔人聪明，但五百个智人加起来，却肯定比五十个尼安德塔人聪明多了。
5. **这一切之所以可能，都是因为故事**。从唯物主义来看历史的时候，常常就会忽略或否定故事的力量。特别是马克思主义，常常认为故事掩盖了背后的权力关系与物质利益。在马克思主义的理论看来，人类的动机永远都基于客观的物质利益，而故事的目的也正是要掩饰这些利益，让对手无法看清。以这种观点，就会觉得不论是十字军东征、第一次世界大战、或是伊拉克战争，其实都是强大的菁英份子在谋取自己的经济利益，而不是为了宗教、民族主义或自由主义的理想。想了解这些战争，就该揭开所有那些神话的无花果叶（ 关于神、爱国或民主），去观察赤裸裸的权力关系。 然而，**==这种马克思主义的观点不只是太愤世嫉俗，而是根本错得离谱==**。虽然物质利益确实在十字军东征、第一次世界大战、伊拉克战争、以及大多数其他的人类冲突里，都扮演了一定的角色，但这并不代表宗教、民族主义和自由主义理想就毫无用途。 此外，**光从物质利益这一点，并不足以解释为什么是这些人在彼此敌对**。为什么在十二世纪，是法国、德国与义大利的地主及商人联合起来，抢下黎凡特的领土与贸易路线，而不是法国与北非的地主及商人联合起来，征服义大利？为什么在2003年的时候，英美两国是想去抢下伊拉克的石油油田，而不是攻占挪威的天然气田？这些事情真的能够单纯用唯物主义来解释，而不用谈到众人的宗教信仰与意识型态吗
    - 从现在的角度看, 美国攻打伊拉克真的不是一个划算的生意, 不如频繁的让伊拉克领导先走.
6. 马克思主义者可能会说，大规模群体具有客观的身分认同与利益，不受故事影响。但如果真是如此，要怎么解释只有人类会形成部落、国族、宗教这样的大规模群体，而黑猩猩却不会？毕竟，黑猩猩需要的客观物质利益，和人类并没什么两样，都要喝水进食、保护自己别染上疾病，也都想要有性行为、拥有社会上的权力。然而，黑猩猩就是没办法长期维持大规模的群体，原因正在于牠们没办法创造故事来彼此链接、定义其身分认同与利益。所以，**==不同于马克思主义的说法，史上的大规模身分认同与利益一向都是主体间的现实，而非客观现实==**。
7. 特别是，如果享有特权的人只看得见、也只相信那些维护著他们特权的事物，这时候除了暴力之外，又哪有其他办法能让他们放弃特权、改变信念？幸好，因为历史其实是由存在于主体间的故事所塑造，所以有时候只要我们好好谈谈，改变彼此所相信的故事，或是找出大家都能接受的新故事，就能避免冲突，实现和平。
    - 只要看见过太阳就无法再接受黑暗
8. 反正任何冲突肯定都是源自于客观的权力关系，而这又岂是嘴上说说就能改变？特别是，如果享有特权的人只看得见、也只相信那些维护著他们特权的事物，这时候除了暴力之外，又哪有其他办法能让他们放弃特权、改变信念？幸好，因为历史其实是由存在于主体间的故事所塑造，所以有时候只要我们好好谈谈，改变彼此所相信的故事，或是找出大家都能接受的新故事，就能避免冲突，实现和平。
9. 在历史上，**权力其实只有部分是来自于对真理真相的了解，而另外还有一部分，是来自于能够维持一大批人的社会秩序。**
10. 欧本海默（Robert Oppenheimer）之所以能把心思都放在计算方程序，是因为在加拿大北部的埃尔多拉多矿场、以及比属刚果的辛可罗威矿场，有几千名矿工负责了挖矿的工作，  更别说还有大批农民负责种出午餐吃的马铃薯。想做出原子弹？你就是得要找到办法让几百万人合作，才做得到。
    - 从某种方式 [[the_pareto_principle_or_the_80_20_rule|二八定律]] 真的可以正确解释吗?
11. 如果你做了一枚完全无视物理学的炸弹，这枚炸弹不可能响彻云霄。但如果你创造出一套完全无视事实的意识型态，这套意识型态依然可能惊天动地。虽然真理与秩序都能带来权力，但大多数时候，掌握大权的会是那些知道如何创造意识型态来维持秩序的人；至于那些只懂得怎么做炸弹或猎猛犸象的人，则只能乖乖听令。 所以，是欧本海默得听小罗斯福的话，而不是小罗斯福听欧本海默的话。同样的，是海森堡得听希特勒的话，库尔恰托夫（Igor Kurchatov）得听斯大林的话。至于当代的伊朗核物理学专家，也得听什叶派神学专家的指令。
    - 用中国话说就是"劳心者治人，劳力者治于人".
12. 要让人团结起来的时候，虚构的故事比起真理真相，天生就具有两个优势。**第一，虚构的故事要多简单、就可以多简单，但是真理真相却往往很复杂，因为它要呈现出现实，而现实从来就不单纯**。让我们以关于“国家”的真理真相为例。要说我们所隶属的国家是一种存在于主体间的现实，只存在于集体的想像之中，这种概念并不容易理解。听政治人物演讲的时候，大概很少会听到这种说法。民众更容易相信的是，说我们这国就是上帝的选民，造物主也赋予我们某些特别的任务。从以色列到伊朗、从美国到俄罗斯，同样这套简单的故事，就这样被政治人物讲了又讲、说了又说。**第二，真相常常令人痛苦不安，如果我们想让真相别那么令人痛苦、变得比较讨人喜欢，真相也就不再是真相了**。相较之下，虚构故事的可塑性极高，而每个国家总有些黑历史是国民不想承认、不想记住的。像是以色列政治人物参选的时候，如果在选举演说当中，细数以色列占领巴勒斯坦给当地平民造成的苦难，得票数大概不会太好看。相较之下，如果他忽略那些叫人不安的事实，只谈犹太的过往辉煌，并在任何必要的时候为现实擦脂抹粉，创造出一套国族神话，倒是很有可能堂堂上位，取得权力。
    - 这就是阴谋论和谣言可以在网络上大行其道的原因, 不需要考虑真相随便写就可以, 即使真相也并不讨人喜欢.
13. 柏拉图早在《[[理想国]]》就谈到，建设乌托邦国家的基础会是一种“高贵的谎言”：一套关于社会秩序起源的虚构故事，一套能够确保公民的忠诚、避免让他们质疑政制的故事。柏拉图写道，要告诉公民，他们都是由大地而生，大地就是他们的母亲，因此他们要对这片祖国土地负起孝道忠诚。还要告诉公民，在诸神造人之时，不同人就掺进了不同的金属（ 金、银、铜、铁），掺了黄金就该成为统治者、掺了青铜则该成为仆人，这就是个自然的阶级制度。虽然柏拉图的乌托邦从未真正实现，但这些年来，许多政体所告诉公民的，也都只是这个高贵谎言的各种变体。
14. **光是讲一个虚构的故事，并不是说谎；所谓的说谎，是你不但说了虚构的故事，还想假装这是在呈现现实**。如果你没有假装，而是大方承认自己就是在创造一个新的主体间现实，而不是在呈现某个既有的客观现实，那么去讲一个虚构的故事就不是说谎。
15. 美国宪法谈到自身的起源，写的是：“我们，美利坚合众国的人民，为了组织一个更完善的联邦……制定和确立这一部宪法。”虽然承认这就是一套人为的法律拟制，但美国宪法确实成功带出了一个强大的联邦，并在超过两个世纪以来，在百万到上亿来自不同宗教、种族与文化团体的人群当中，维持了令人赞叹的秩序。美国宪法的作用，就像是给出了一段音乐曲调，虽然没有声称自己在呈现代表什么，却能让许许多多人一起运作得很有秩序。
16. 这里必须提醒的是，**我们不该把“秩序”与公平或正义混为一谈**。美国宪法所创造并维持的这套秩序，当时对于奴隶制度、性别差异、对原住民的非法侵占、极端的经济不平等，态度都过于纵容了。但这套宪法的美妙，在于既然承认自己就是人类所创的法律拟制，就能有机制来让各方达成协议，以修改、纠正自身的不公不义（ 第5章〈决择〉会更深入讨论这一点）。在美国宪法第五条，就详细说明了这些修正案应如何提出、如何通过，而且这些修正案“即成为本宪法之一部分而发生全部效力”。于是，在美国宪法制定后不到一个世纪，就有了第十三条修正案，将奴隶制度废除。
17. 光是拥有大量资讯，并无法保证得到真理真相，也无法保证就能维持秩序。想用资讯同时既要找出真理真相、还要维持秩序，不但本来就极为困难，更惨的是还常常互相矛盾；毕竟，靠著虚构故事通常更容易维持秩序。
18. 回顾人类资讯网路的历史，会发现这并不是一场进步的游行，而是像在走钢索，试图在真理真相与秩序之间取得平衡。而到了现在二十一世纪，我们寻找正确平衡的能力，并没比石器时代的祖先高明到哪里去。虽然谷歌与脸书等企业的使命宣言百般暗示，但光是资讯技术变得更快、更有效率，可不一定会让世界变得更美好，那只是让我们更迫切需要在真理与秩序之间，达到平衡。 人类早在几万年前发明虚构故事的时候，就已经受过这样的教训了，而且这项教训还会再次上演。这次是人类发明了第二项伟大的资讯技术：书面文件。
    - 文山会海就是人类社会组织的重要组成部分.

#### 第３章 文件──纸老虎也会咬人

1. 然而，不论梦想、诗歌与幻想再怎么激励人心，仍不足以创造一个能够运作的民族国家。比亚利克虽然启发了一代又一代的犹太军人，但军队要维持整备，还是得靠增税、购置武器。赫茨尔的乌托邦著作虽然为台拉维夫这座城市奠定了基础，但要维持这座城市的运作，还是不能缺了污水系统的建置。
    - 在城市生活的人很难适应城市以外的生活　
2. **爱国的重点绝不是吟咏赞扬祖国壮丽的诗歌，更不是针对外国人与少数民族发表仇恨言论。真正的爱国，是要去好好纳税，让所有国人都能享受污水处理系统带来的好处，也能享有安全、教育、以及健康照护。**
    - 爱国怎么能没有口号的, 没有口号的爱国行为不就是叛国吗? "忠诚不绝对, 就是绝对不忠诚"
3. 国家要能管理这一切服务并取得必要的税收，就必须搜集、储存、处理极大量的资讯，包括财产、支付、抵免、折扣、债务、库存、运输、预算、帐单，以及薪水等等。但这些资讯可没办法变成令人难忘的诗歌、叫人回味的神话。税务纪录的形式就是各式各样的清单列表，从简单的项目纪录，再到更复杂的表格与试算表。**不论这些数据集看来会有多琐碎复杂，都还是会避免采用故事叙述，宁可用最无趣的形式，直接列出那些应付金额与已付金额。诗人可以不管这些单调世俗的细节事实，但税务人员可不行。**
    - 诗人是没有能力治国的, 只会把国家搞烂, 比如清朝的"诗仙"弘历, 也可能弘历虽然写诗多但是水平太烂了导致国家发展还是可的.
4. 我们之所以能把史诗与长篇影集记得这么清楚，是因为人类的长期记忆经过适应，特别能够记得故事。正如海文（Kendall Haven）2007年的著作《故事的妙用：故事惊人力量背后的科学》所言：“人类的心智……需要靠故事与故事架构，做为主要蓝图，用来了解、解读、记忆与规划我们的生活……生活就像故事一样，是因为我们会以故事的方式来思考。” 海文引用了超过一百二十篇学术研究，认为故事就是一种极有效率的“沟通各种事实、概念、情感及隐性资讯的载体”。
5. 在这里，让我们以“所有权”这个重要的例子来说明。**在没有书面文件的口述文化社群里，要创造出“所有权”这项存在于主体间的现实，靠的是社群成员的言语与行为**。所以，所谓“拥有一块土地”，代表邻居都说这块地是你的，而且不会说一套做一套，只要未经你许可，他们就不会跑来这块地上盖起房子、养鸡养鸭、偷摘水果。
6. 所有权的创造与维护，靠的就是大家不断这么说、或是发出这样的讯号。在这种时候，所谓的所有权就是一种地方社群的事务，某个遥远的中央政权，很难有能力控制所有的土地所有权。
7. 而在一个有识字能力的国度，所谓拥有一块土地，慢慢就变成是会有一块泥板、一片竹片、一张纸、又或是一片晶片，上面记载著由你拥有哪块土地。
8. **你要怎样才能在需要的时候，找出对的那份税务纪录、付款收据或商业合约？书面文件虽然比人脑更容易记得某些类型的资讯，却又创造出一种全新而极度棘手的问题：*资讯检索*。**
    - 信息检索真的是一件困难的事情.
9. 一旦人类把记忆从生物性的大脑外包给非生物的文件，检索运作就再也没办法依靠这套简单高效的生物机制。而且，人类几百万年来演化出的觅食能力，也派不上用场。演化让人类懂得怎么在森林里找到水果与蘑菇，但可没告诉人类，该怎样在档案库里找到文件。
    - 真的是为了找蘑菇而设计的吗? 现在想想在没有电脑情况下, 找文件真的是一个困难的事情, 即使有各种信息分类法也很难实现高效检索, 尤其是在社交网络出现后传统的方法更是无法应对, 必须通过新的技术来实现.
10. 需要有人先提出依架位来分类资讯的想法，并决定该把哪些文件放到哪个架上。采集者在森林里，只需要找出既有的森林秩序，但档案管理员则是需要为这个世界设计一套新秩序，这种新秩序就称为官僚制度。 在大型组织里，人类就是用官僚制度来解决数据检索的问题，进而创造出更庞大、也更强大的资讯网路。但就像神话故事一样，官僚制度也常常宁可为了秩序而牺牲真理真相。而在为这个世界发明并套用了一套新秩序之后，官僚制度也就让众人对世界的理解，有了一种独特的扭曲。
11. **二十一世纪资讯网路的许多问题，像是演算法带有偏见、给人贴上错误的标签，各种协定太过死板、无视于人性的需求与感受，其实并不是到了电脑时代才出现，这正是最典型的官僚制度问题，在大家想都没想过有电脑这种东西之前，就已经存在了。**
    - #标签系统 可以理解成文官系统的检索方案是吗? 
12. 官僚制度的英文 bureaucracy，词源讲的就是“从书桌来统治”。这个词最早创于十八世纪法国，当时官员通常就是坐在一张有抽屉的书桌旁边，这种书桌就称为 bureau。**所以官僚制度这套秩序，正是以抽屉做为内核**。而这套秩序解决检索问题的办法，也正是把整个世界分成许多抽屉，再判断该把哪些文件放进哪个抽屉。 不管是把文件放进抽屉、书架、篮子、罐子、电脑数据夹、还是任何其他容器，原则都一样：分而治之。把这个世界区分开来，放进不同的容器，并让容器各有其位，文件就不会混在一起。然而这项原则需要付出代价。官僚制度的重点并不是去了解世界真实的样貌，而是忙著给世界强加一套全新的、人为的秩序。
    - 我基本没用过"抽屉"进行任何管理, 所有后抽屉相关的内容都是从电影或电视剧上理解的, 打开一个抽屉里面有一排整齐的文档夹, 这些文档夹按照特定的循序排列并且有一个特殊的便签在外侧方便查找, 一个抽屉没有目标文件就在另一个抽屉中继续查找(可以理解成是二分查找)
13. **官僚制度先是发明各种抽屉，这些抽屉属于存在于主体间的现实，其划分并不一定对应到世界上的任何客观现实**。但官僚制度接著就想要把这个客观现实的世界，硬是放进这些抽屉里；如果放不太下，官僚制度只会塞得更用力。只要你填过任何官方表格，应该都对这种情况非常清楚：填表的时候，**要是列出的选项都不符合你的状况，是你得想办法适应表格，而不是要求表格来适应你**。 **把这无穷混沌的现实，限缩成数量有限的抽屉，虽然让官僚制度方便维持秩序，但代价却是牺牲了真理真相**。就算现实要比抽屉复杂得多，但**==官僚一心只看著自己的抽屉，他们对于世界的理解常常就受到扭曲。==**
14. 但如果帮官僚制度说句话，虽然官僚制度有时候会牺牲真理真相、扭曲我们对世界的理解，但往往是为了维持秩序；要是没了秩序，任何大规模的人际网路都将难以维系。 虽然官僚制度永远不可能完美，但又是否真有更好的办法，能管理大型网路？举例来说，如果我们决定打破学术界所有传统的领域分类、废止各种分系分科与专业期刊，是不是以后想当医师也得花几年来读历史，而研究黑死病对基督宗教神学影响的人，也能算是病毒学的专家？这样做会让我们有更好的健康照护体制吗？
    - 我认为没有什么好办法, 不是人去整理表格, 就是一个机器去整理表格.
15. 如果幻想著只要废除了官僚制度，就能让大家以更全面的观点来看世界，实在需要提醒自己：像是医院，也是一种采用官僚制度的机构。医院会分成不同科别部门，有上下阶级、各种协定，以及得要填写的大量表格。
16. 你冲马桶的时候，那些秽物都去了哪？答案是进入了深层政府（deep state）。我们的房屋底下，有一个由管道、帮浦、隧道组成的复杂地下网路，会搜集所有污水秽物，避免接触到饮用水供给，并进行污水处理或安全排放。这个深层的网路需要有人来设计、建造和维护，修理漏洞、监控污染，以及支付工人的工资。这一切也都属于官僚制度的工作，如果废除了这个部门，肯定会让我们面临诸多不适、甚至死亡。污水污染饮用水的危险一直都存在，幸好我们有官僚制度的协助，才能让污水与饮用水好好分开。
17. **在官僚体系中，权力往往就来自于了解如何操弄隐密的预算漏洞，以及如何往来于各个办公室、委员会与分组委员会形成的迷宫之间**。 这种权力的转移，改变了世界的权力平衡。总之，识字的官僚制度机构常常就是强化了中央的权威，而以牺牲普通公民的利益为代价。一方面，有了文件与档案库，中央就更容易向人民征税、审判、征兵。而且因为难以理解官僚制度的权力，也就让民众更难去影响、抵抗或逃避中央的权威。 就算在官僚制度的力量属于良性、给民众提供了污水处理、教育与安全的时候，还是会拉大统治者与被统治者之间的差距。因为这套制度让中央很容易搜集和记录被统治者的资讯，而被统治者若想要了解制度运作细节，却是困难得多。
18. 在官僚社会，民众常常就是会因为某个让人难以理解的原因，被某个不清楚职掌的机构，派出了身分不明的官员，来把你的生活搞得天翻地复。从《罗摩衍那》到《蜘蛛人》，这些英雄对抗怪物的故事，其实就是把过去对抗掠食者的生物戏码情节，拿来重新包装；但卡夫卡式故事所带出的独特恐怖氛围，是在于这份威胁完全高深莫测。经过演化，我们的心智能够了解被老虎杀死是怎么一回事，但“被文件杀死”就没那么好理解了。
19. 1980年代的英国情境喜剧《[[是大臣]]》和《[[是首相]]》，也都展现了公务人员如何运用繁复的法规、莫名的分组委员会与成堆的文件，把上司那些政治人物操弄于股掌之中。
    - 很好奇美国也是这样吗?
20. 我们已经看到，**资讯网路的功能并不是尽量放大真理真相，而是要在真理真相与秩序之间达到平衡**。官僚制度与神话故事非但都是维持秩序所必须，也都乐于为了秩序而牺牲真理真相。所以，有没有什么机制，能让官僚主义与神话故事不要完全脱离真理真相，或是能让资讯网路发现并纠正自己的错误，甚至是有点混乱也没关系？

#### 第４章 错误──绝对正确是一种幻想

1. 神学家圣奥古斯丁有句名言：“人都会犯错；但死不改错则是恶魔。”  各地神话故事共同的一项重要主题就是：人容易犯错、以及这些错误需要得到纠正。像是在基督教神话里，所有的历史就是为了纠正亚当和夏娃的原罪。在马列主义里，则说就算是工人阶级，也可能受到压迫者愚弄而误解自身利益，所以实在需要有明智的共产党先锋队来领导。
    - 承认自己失败是最难的.
2. 例如在古希腊，如果想知道众神的看法，就会去找像是皮媞亚这种经过认证的专家──在德尔菲阿波罗神殿里传神谕的女祭司。 然而，就算是要传神谕的神殿，只要宗教机构仍然由凡人来当员工，就不可能完全避免犯错或贪腐。希罗多德（Herodotus）就写到在雅典被暴君希庇阿斯统治的时候，民主派就曾贿赂皮媞亚来提供协助。所以每当斯巴达人来找皮媞亚，想知道众神对官方或私人事务有何意见，皮媞亚总说斯巴达得先把雅典从暴君手中解放出来才行。原本与希庇阿斯站在一起的斯巴达，最后不得不屈服于所谓众神的意志，派军前往雅典，在西元前510年推翻希庇阿斯，而使雅典民主政体得以建立。
3. 要是人类先知能够伪称神谕，那么关于宗教的关键问题，就不是只要创立了寺庙神殿或祭司职务之类的宗教制度就能解决，因为民众想要接触到理论上绝对正确的神，还是得透过一些容易犯错的凡人。那么有没有办法，是可以完全绕过凡人这个步骤呢？
4. **《圣经》与《古兰经》这样的宗教经典，其实就是一种技术，希望用来绕过“凡人会犯错”这件事**。这些经典背后的宗教（ 像是犹太教、基督宗教、伊斯兰教），也都是围绕著这种技术作品而建立。要谈这项技术希望达到什么效果，就得先解释究竟“书”是什么，以及书和其他的书面文本有何不同。
    - 问题是这些宗教经典不也是人写的吗? 为什么这些经典不会出现问题呢?
5. 猎巫行动很少在杀死一人或一个家庭之后就结束。因为这背后的基本概念预设就是有个全球阴谋，所以被控施行巫术的人在酷刑之下，还得招出其他所谓的共犯。这就会被当成证据，而使更多人遭到监禁、拷打或处决。要是有哪位官员、学者或教会人士敢发声反对这些荒谬的做法，则会被视为他们肯定也是女巫同伙的证据，而让他们也下狱遭刑。
6. 整个猎巫官僚制度都全力推动这样的资讯交换。包括神学家、律师、裁判官与印刷机的持有者，他们的生计靠的就是搜集、制作关于女巫的资讯、分类出不同种类的女巫、调查女巫的行为模式，以及建议该怎样击败女巫、逮住女巫。职业猎巫者接受政府与城市委托，并收取大笔费用。档案库里放满了猎巫行动的详细报告、女巫审判的规章，以及被指控的女巫所提出的冗长供词。 猎巫专家就用这所有数据，持续改进他们的理论。
    - 一种螺旋向下的感觉, 不断的迫害, 迫害过程中收集到新的信息, 让阴谋论更真实, 然后扩大迫害面.
7. 猎巫制度甚至还印出了表格，附有标准的巫术指控与供词，还留有空白处让人填入日期、姓名与被告画押。这一切的资讯产生了大量的秩序与权力，有些人正是以此获得权威，而整体社会也会以此来约束成员。但这种手段既不会产生任何真理真相，也无法产生任何的智慧。
8. 随著猎巫官僚制度不断产出愈来愈多资讯，社会也愈来愈难断言这一切资讯都单纯只是幻想、不值一提。难道在这么多的猎巫数据当中，真的都没有半点真相吗？不是有那么多博学的教会人士，写出大批相关的著作吗？不是有那么多受人尊敬的法官，依照相关的审判规程做出判决吗？不是有数以万计的认罪纪录吗？ 这个全新创造出的主体间现实，实在太具说服力，就连一些被指控使用巫术的人，也开始相信自己还真的是某个全球撒旦阴谋的一部分。毕竟，如果大家都这么说，肯定就是真的吧。
9. **真正能够推动科学革命发展的，既不是印刷术、也不是完全自由的资讯市场，而是能够找出一种创新的方法，来解决“人会犯错”这个问题**。 从印刷术与猎巫的历史可以看到，自由的资讯市场并不一定能让人看出并改正自己的错误，因为在这样的资讯市场里，比较看重的可能是让人感到义愤填膺，而不是要揭露真理真相。**想要让真理真相胜出，就必须建立筛选机制，能让天平往事实那一方倾斜。**
10. 在科学革命扮演了重要角色的筛选机制，是链接了大学内外的学者与研究人员，形成了一个横跨整个欧洲、乃至全世界的资讯网路。科学革命如果要加快步伐，科学家就必须愿意相信远方同侪所发布的资讯。 从几种机制，都能看到虽然众人素未谋面，却愿意相信彼此的研究成果。第一是各种科学机构与学会，例如，成立于1660年的英国皇家学会、成立于1666年的法国科学院；第二是各种科学期刊，像是英国皇家学会1665年创刊的《自然科学会报》、法国科学院于1699年创刊的《皇家科学院刊》；第三还有各家科学出版社，像是策划出版《百科全书》（ 1751年至1772年）这类出版品的人。
11. 教会叫众人要相信它，给出的理由是教会掌握了绝对真理，而形式就是一本无懈可击的宗教经典。相对的，科学机构之所以能取得权威，是因为他们有强大的自我修正机制，能够揭露并修正本身的错误。科学革命真正的引擎正是这些自我修正机制，而不是印刷技术。换句话说，人类是因为发现了自己的无知，才推动了科学革命。
12. 那些信奉某本经典的宗教，会觉得他们已经取得了无懈可击的知识来源。基督徒有《圣经》，穆斯林有《古兰经》，印度教徒有《吠陀经》，佛教徒有《大藏经》。 科学文化并没有这样的神圣经典，也从未宣称某位科学家是绝不会犯错的先知、圣人或天才。科学革命从一开始就不相信有绝无错误这种事，打造出的资讯网路也认为错误本就无可避免。
    - 我相信经典没有问题, 是经典本身没有问题, 但是宗教领袖一定不值得信任.
13. 这些科学家都犯过错误，而就算是最著名的科学著作，也肯定有错误与疏漏。 就算是科学天才，也避免不了受到[[confirmation-bias|确认偏误]]的影响，所以并不能信任天才肯定能揪出自己的错误。科学是一项团队工作，需要机构互相配合，而不可能只靠单一科学家、或说某一本绝对正确的书籍。 当然，机构也可能出错，但科学机构与宗教机构的不同之处，在于科学鼓励怀疑与创新，而不是鼓励因循与顺从。**科学制度与阴谋论的不同之处，在于科学鼓励的是怀疑自己；至于阴谋论者，常常是对众人既有的共识大表怀疑，但只要讲到他们自己的信念，忽然反而毫无怀疑，而落入了确认偏误的陷阱。**
14. 科学的注冊商标不是只要怀疑，而是要怀疑自己。在所有科学机构制度的核心，都能看到强大的自我修正机制。科学机构制度确实对某些理论（ 像是量子力学或演化论）的正确性，有著广泛的共识，但原因是这些理论能够成功顶住一波波强力挑战，而且会提出质疑的除了外人，更有机构制度内部的成员。
15. **谓的自我修正，指的是实体会用这些机制来修正自己的错误**。像是老师批改学生作文，就算不上是自我修正机制；毕竟这并不是学生在修改自己的作文。法官将罪犯送进监狱，也算不上是自我修正机制；毕竟这并不是罪犯自首揭露罪行。
16. 自我修正机制在自然界里无所不在。正是因为有这种机制，才让小孩学会走路。走法错了，就会跌倒；于是你会从错误中学习，试一试稍微不同的走法。确实，有时候父母师长也会想帮一把、或是提供建议，但要是小孩真的完全依赖这些外部的修正，或是总给自己的错误找借口、而不从中学习，就会发现想学会走路可没那么简单。事实上，就算在长大之后，我们每次走路，身体还是会进行复杂的自我修正。随著身体在空间中行进，我们的大脑、四肢与感觉器官会形成一个内部回馈回路，让手脚处于适当的位置，也让我们得以保持平衡。
17. **像是天主教会这个机构，自我修正机制就相对较弱。由于它宣称自己绝对正确，也就无法承认自己在整体机构制度上的错误。虽然天主教会偶尔也愿意承认有些成员犯错或有罪，但嘴上还是会说这个机构本身完美无缺。**
    - 错误永远是个别神父或主教的, 天主教本身是不会犯错的, 在犯错前已经驱逐出教了.
18. 例如在1964年梵蒂冈第二届大公会议，天主教会承认“基督号召旅途中的教会继续不断革新，教会以人世间的组织来看，的确也需要随时革新。因此，依照事体及时代的情况，如果在道德问题上或在教会纪律上，甚至在教义宣讲的方式上（ 但此宣讲方式与信德的保库本身，须慎重区别），发现欠缺时，就该在适当的时机，加以正直和应有的重整。”  如此的坦诚，听起来似乎前景可期，但魔鬼就在细节里，特别是教会仍然拒绝承认“信德的保库”可能有任何的缺陷。在天主教教义，“信德的保库”指的是教会从《圣经》及解经的神圣传统所得到的那些启示真理。所以，天主教会承认的是神父是会犯错的凡人，可能有罪，也可能在教义宣讲的方式有误。但《圣经》本身绝不会有错。**这样看来，教会这个机构就是结合了会犯错的凡人、以及绝不会犯错的经文，这是什么意思？ 根据天主教的教义，《圣经》的绝对正确与神圣引导，必能胜过人类的堕落，因此就算教会的个别成员可能犯错、可能有罪，但是天主教会这个机构永远正确**。据称，天主从未在史上让大多数教会领袖对《圣经》的解读出现严重错误。
19. 虽然教会未曾正式承认，但随著时间，教会也慢慢改变了自己的制度架构、内核教义、以及对经文的解释。如今的天主教会，反犹与厌女的色彩已经比中世纪与近世淡化许多。教宗方济各对原住民文化的包容程度，远高于教宗尼阁五世。这就显示了机构制度也能回应外部的压力以及内部的反省，而进行自我修正。然而对于像是天主教会这样的机构来说，就算真的有所自我修正，态度也是全盘否认，而不是歌颂赞扬。要改变教会教义的第一条法则，就是永远不能承认要改变教会教义。
    - 这种改变也是迫不得已啊, 要是不改可能就没了.
20. **科学的自我修正机制之所以格外强大，是因为科学机构制度不只是愿意承认自己的错误与无知，甚至是会积极揭露这些错误与无知。从这整套机构制度的奖励机制，就可以看得一目了然。**
21. 民粹主义者会说，科学家也是人，同样也会有各种人类偏见，这点说得完全没有错。但因为科学机构制度具备了自我修正机制，也就让这些偏见终究得以扭转。只要能提供充足的实征证据，常常只需要几十年，就能让原本非正统的理论，推翻传统概念，成为新的共识。
22. 在某些时候、某些地方，科学的自我修正机制也可能停止作用，于是就连学术上的异议，也可能招来酷刑、监禁与死亡。 像是在苏联，不论是在经济学、遗传学或历史学领域，如果去质疑官方教条，不仅可能丢了工作，还可能在古拉格劳改营被关上几年，甚至迎来行刑者的一颗子弹。
23. 一个著名的案子，就是苏联农学家李森科（Trofim Lysenko）提出的各种假理论。**他拒绝相信各种主流遗传学与天择演化论，而提出了一套自己喜欢的理论，主张透过“再教育”就能改变动植物的性状，甚至能让一个物种变成另一个物种**。 李森科这一套“再教育”理论令斯大林大为惊艳，觉得在意识型态或政治上，简直是潜力无穷。当时许多科学家站出来反对李森科，继续捍卫天择演化论，结果就是几千人丢了工作，甚至是锒铛下狱或遭到处决。像是瓦维洛夫（Nikolai Vavilov），这位植物学家暨遗传学家曾经是李森科的导师，但后来对这位门生批评不假辞色。瓦维洛夫在1941年7月，与植物学家戈沃罗夫（Leonid Govorov）、遗传学家卡尔佩琴科（Georgii Karpechenko）、农学家邦达连科（Aleksandr Bondarenko）四人一同受审。后面三人遭到枪决，瓦维洛夫则在1943年死于萨拉托夫集中营。
    - 现在看看是真 tmd 的 sb.
24. 在独裁者的压力之下，列宁全苏农业科学院最后在1948年8月宣布，从此之后，苏联机构将以李森科主义做为唯一正确的理论来传授。 **但正是因为这个理由，列宁全苏农业科学院从此不再是个科学机构，苏联对遗传学的教条就是一种意识型态、而不是一门科学**。虽然机构爱怎么取名都行，但只要没有健全的自我修正机制，就称不上是个科学机构。

#### 第５章 决择──民主与极权制度简史

1. 讲到民主与独裁，常常会把它们视为两种相对的政治体制与道德体系。**==但本章希望能改变这种讨论方式，透过梳理过去的历史，将民主与独裁视为两种相对的资讯网路类型==**。本章会谈谈民主政体的资讯流动方式与独裁政体有何不同，以及新信息技术的发明对于各种不同类型政权的有利之处。
2. 独裁资讯网路的特点在于高度集中。 这代表著两件事。
    1. **第一，中心掌握著无限的权力，所以资讯往往是从地方流向中央枢纽，最重要的决策也都是在中央进行**。在罗马帝国，条条大路通罗马；在纳粹德国，一切资讯流向柏林；在苏联，所有资讯汇聚到莫斯科。 有时候，中央政府是想要把所有资讯都集中在自己手里，想要由自己来做所有决定，澈底控制人民生活的一切。这种由希特勒和斯大林等人实行的极端独裁统治，就称为极权主义。然而，**独裁不一定等于极权：常常是出于技术上的困难，而使独裁无法走上极权之路**。 像是在罗马帝国时代，偏远乡村有几百万农民，而尼禄手上缺少必要的工具，也就实在无法对这些农民的生活，进行无所不管的微观管理（micromanage）
        - 这里可以看看 [[权民一体论]] 中关于信息处理的解释.
    2. **独裁资讯网路的第二个特征，在于会认定中央是绝对正确的，所以并不欢迎对中央的决策有任何挑战**。苏联的宣传把斯大林塑造成绝不犯错的天才；罗马的宣传也把历任皇帝视为神圣的化身。就算斯大林或尼禄做出显然糟到不行的决定，苏联或罗马帝国也没有强大的自我修正机制，能够揭露错误、推动更好的做法。 理论上，**就算是高度集中的资讯网路，仍可能拥有强大的自我修正机制，就像是独立的法院、民选的立法机构。然而，只要这些机制运作良好，就会挑战到中央的权威，使资讯网路去中心**化。所以，独裁者总觉得这些独立权力枢纽是一种威胁，会想用各种方式来削弱。罗马元老院就是这样，权力不断被历任皇帝削弱，最后就算在帝国胡作非为的时候，也只能做为橡皮图章。 苏联司法体制也面临相同的命运，从来不敢反抗共产党的意志。**斯大林主义的作秀审判（ show trial，公审大会）正如其名，就是一场早已有结果的秀。**
        - 为了实现独裁和极权是不可以有独立与独裁者的机构存在
3. **==独裁政体是一种集中式的资讯网路，而且缺乏强大的自我修正机制。==**
4. **民主政体则是一个分布式的资讯网路，并且拥有强大的自我修正机制**。在民主资讯网路里，我们确实也会看到有一个中心枢纽，是由“政府”掌握民主政体最重要的行政权力，因此政府机构会搜集、储存大量的资讯。然而，民主政体还会有许多其他资讯管道，连接许多独立的节点。不管是立法机构、政党、法院、新闻界、企业、当地社群、非政府组织、又或是公民个人，都能够自由的直接相互沟通，因此大多数资讯并不会经过任何政府机构，许多重要决策也都是在其他地方决定。
    - 我感觉应该用"分散式"更准确一些.
5. 对民主政府来说，就算拥有相关技术，有能力微观管理人民的生活，还是会尽量保留让人民自己做选择的空间。**有一种常见的误解，就是以为民主政体的一切决定，都要诉诸多数决。事实上，民主政体的做法是尽可能让每个人自己做决定；唯有很少数必须集中来做的决定，才需要经过投票，反映多数人的意愿**。在民主政体，就算有99%的人都想穿某种衣服、信奉某位神明，剩下的1%还是可以穿自己想穿的、信自己想信的。
6. 民主政体的另一项重要特征，在于相信人人都可能犯错，因此虽然会赋予中央一些重大决策权，但同时也会保留一些能够挑战中央权威的强大机制。套一段美国前总统麦迪逊说过的话：既然人会犯错，就需要有政府，而既然政府也会犯错，就需要有机制能够揭露并修正其错误，像是定期举行选举、保护新闻自由，以及让政府的行政、立法与司法三权分立等等。
7. **==所谓独裁，就是由单一中央资讯枢纽决定一切；所谓民主，则是有不同的资讯节点持续对话==**。这些节点常常会相互影响，但在大多数问题上，并不需要真的达成共识，各个个人、企业与社群还是可以继续有不同的思维与行为方式。
8. 把民主定义为“拥有强大自我修正机制的分布式资讯网路”，就会与“民主等于选举”这种常见的误解，形成鲜明对比。选举是整套民主工具组的核心成分，但并非民主的全部。要是没有额外的自我修正机制，选举就很容易遭到操弄。而且就算选举完全自由公平，光是这样也还不足以保证就是民主。**因为民主也绝对不是“多数独裁”（majority dictatorship）**
9. 假设有一场自由公正的选举，由51%的选民选出某个政府，而这个政府接著决定要把全国1%的选民送进死亡集中营，就因为这些人属于某个受到憎恶的少数宗教。这算民主吗？显然不算。这里的问题，并不是说要有超过51%的某个“特别多数决”，才能允许进行种族灭绝。绝不是只要政府能得到60%、75%、甚至99%选民的支持，就能让死亡集中营成为一个民主的决择。所谓民主制度，并不是只要占了多数，就能去消灭那些不受欢迎的少数族群，民主制度其实是指一种对于中央权力有明确限制的制度。
10. **强人破坏民主最常用的方法之一，就是攻击民主的自我修正机制，常常是从法院与媒体下手：剥夺法院的权力、或是全部安插自己的人，试著关掉所有独立媒体，并且建立自己无所不在的宣传机器**。 等到法院无法再以法律手段制约政府，媒体也只能乖乖重复政府的台词，所有敢于反对政府的机构或个人都可能被抹黑是叛徒、罪犯或外国代理人，进而遭到迫害。各种学术机构、自治区、非政府组织与私人企业，要不被解散，要不就是落入政府控制。
11. 这些强人通常不会真的走到最后一步、把选举澈底废除，而是会留下来做为一种仪式，为政权提供合法性，也保留民主的表象。普丁领导的俄罗斯，正是如此。
12. 那些强人的支持者，常常并不认为这是个反民主的过程。如果有人告诉他们，**“选赢了”并不代表就能拥有无限的权力，他们是真心感到困惑**。他们反而会觉得，要是有人居然想对民选政府的权力提出任何制衡，那才是不民主。然而，民主并不代表多数就能为所欲为，而是代表所有人应该自由平等。民主这个制度，是要保障所有人都能拥有一定的自由，就算其他人占了多数也无法剥夺。
    - 民主是一大套制衡系统的集合体, 而不是一个代表人民的执政者.
13. 但在民主政体，仍然有两类的权利受到保护，并不是多数说了算。**其一就是人权**。就算有99%的人想要消灭剩下的1%，民主政体也不会允许，因为这侵害了最基本的人权──生命权。其他属于人权这一类的权利，还包括工作权、隐私权、迁徙自由与宗教自由等等。这些权利保障了民主的去中心化本质，只要不伤害到别人，你的日子爱怎么过都可以。 **第二类重要的权利，则是公民权**。公民权是民主游戏的基本规则，保障著民主的自我修正机制。一个明显的例子就是投票权。要是能允许多数去剥夺少数的选举权，民主只要经过一次选举，就会画下句点。 其他属于公民权这类的权利，还包括了新闻自由、学术自由与集会自由等等，这些权利保障了独立媒体、大学与各种反对运动，让他们能够挑战政府。而这些也正是强人会染指的关键权利。虽然有时候确实有必要改变国家的自我修正机制（ 像是扩大选举权、规范媒体、改革司法），但这种改变必须是多数少数双方都有广泛的共识才行。如果只是稍微占了多数，就能够单方面改变各种公民权，那么当局就能够轻松操弄选举，摆脱所有的权力制衡。 **人权与公民权还有另一项值得一提的重点：这些权利除了会限制中央政府的权力，还会对中央政府有一些积极的要求**。民主政府该做的，除了自己不去侵犯人权与公民权，更需要主动保障这两类权利。 以生命权为利，民主政府会被要求负起责任，保护公民免受犯罪暴力的侵害。**如果某个政府虽然不杀人、但也不努力去保护公民不受杀害，这只能说是无政府状态，而非民主政府。**
    - 很好奇, 民主整体如何面对"极端伊斯兰教". 这帮人完全不包容他人, 所有非教徒都是敌人, 在他们面前你的生命权可能都无法保障. 很好奇这种情况要如何处理, 你的包容成了对方最大的武器.
14. 但事实证明，真相与美国政府的说词及大多数人的信念，并不一致。随著战争发展，众人发现伊拉克并没有大规模毁灭性武器，许多伊拉克人也并不想被美国人“解放”或建立美国式民主政体。时至2004年8月，新的民调结果显示，美国人有67%认为这次入侵是基于错误的假设。**随著时间过去，大多数美国人已经承认，决定入侵伊拉克是大错特错。**
15. 科学的情况也与司法相去不远。虽然大多数选民有可能不愿相信气候变迁的现实，但并不能因此就认为他们有权力左右科学上的事实，或是阻止科学家去探究和发表一些选民不愿面对的事实。环境研究部门不同于国会，该做的并不是去反映多数人的意愿为何。
16. 如果你觉得这一切听起来很复杂，那是因为民主本来就该是复杂的。“简单”是属于独裁资讯网路的特征，因为这种网路就是由中央决定一切，其他人只需默默服从。像这样的独裁独白，很轻松就能听懂；相较之下，民主则是一场多方对话，许多人都会同时发声，要听懂跟上这样的对话，本来就没那么简单。
17. **民粹主义（populism）的语源来自拉丁文 populus，意思是人民**。在民主政体，会认为人民是政治权威的唯一合法来源，也只有民意代表有权宣战、立法、增税。**==民粹主义虽然也相信这项民主的基本原则，却又不知道从哪里得到结论，觉得这里的意思是该由单一政党或单一领导者垄断所有权力。民粹主义就像施展了奇幻的政治炼金术，根据看似无可挑剔的民主原则，却发展出一套追求无限权力的极权主义==**。事情究竟是怎么发展成这个样子？ 民粹主义最为诡异的一项主张，是说只有他们才能真正代表人民。**在民主政体，政治权力应该只能归于人民，而如果只有民粹主义者才能代表人民，自然所有的政治权力就该归于民粹主义政党**。如果居然是其他政党赢下选举，可不代表是那个政党赢得了人民的信任、有权组成政府，肯定是胜选被偷走了、或是人民被欺骗了，投票结果并没有表达出人民真正的意愿。
18. 许多民粹主义者是真心这么相信，而不只是宣传手法而已。**==就算在整体选票中只拿到极少的票数，民粹主义者仍然相信只有他们能代表人民==**。类似的例子还有共产党。像是在英国，英国共产党（CPGB）的**大选得票率从未超过0.4%，却仍坚称只有自己才真正代表劳工阶级**。他们声称，数以百万计的英国劳工都是因为虚假意识（false consciousness）才没把票投给共产党，反而投给了工党、甚至是保守党。他们说是资本家控制了媒体、大学和其他机构，使劳工阶级受骗上当、投下违背自身真正利益的一票，唯有共产党能够看穿这场骗局。 **民粹主义者的想法也很类似，觉得是人民的敌人欺骗了人民，才让人民投下了违背真实意志的一票，唯有民粹主义者才能真正代表人民的真实意志。**
19. **这种民粹主义信条的一项基本要素，就是并不把人民看做是一群拥有不同观点与利益、活生生的个人，而认为人民就是一个神秘而统一的实体，只有单一的意志，也就是“人民的意志”**。 对于这种半宗教的信念，或许最恶名昭彰、也最极端的表现，就是**纳粹的座右铭 Ein Volk, ein Reich, ein Führer，意为“一个民族，一个帝国，一个领袖”**。在纳粹意识型态看来，整个 Volk（ 民族、人民）只有一个单一意志，而人民唯一真正的代表就是 Führer（ 领袖）。纳粹党徒认为，对于人民的感受与需求，这位领袖的直觉绝对不会出错。要是有某些德国公民不同意这位领袖的看法，并不代表这位领袖可能错了，而是因为这些异议份子都是来自一些阴谋不轨的外部团体（ 犹太人、共产主义者、自由主义者）
20. **==许多民粹主义政党与政治人物就是不愿接受“人民可能包含了许多意见相左的人、许多不同的利益团体”==**。他们一心认定真正的人民只有一个意志，也深信只有自己才能代表这种意志。相较之下，他们的政治对手就算得到大多数民众的支持，也会被说是“外来的菁英阶级”
21. **==到底要怎样分辨某个人算不算是“人民”？答案再简单不过：只要支持领袖的，就算是人民==**。德国政治哲学家穆勒（Jan-Werner Müller）认为，这就是民粹主义的决定性特征。要判断某人是不是民粹主义者，就看他是否声称只有自己能够代表人民，并说那些不同意他的人（ 不论是官僚体系、少数群体、甚至是多数选民）肯定都是被虚假意识所迷惑，又或者根本不是真正的人民。
    - 想要成为人民真的太难了
22. 民粹主义还有另一种破坏民主的方式，比较不明显，却同样危险。**民粹主义在声称只有他们代表人民之后，接著开始说人民不但是政治权力的唯一合法来源，更是所有权力的唯一合法来源。于是只要有任何机构制度的权威并非来自人民意志，就会被说成是反民主**。这样一来，自称是人民代表的民粹主义者，不只是要垄断政治权威，更是要垄断所有类型的权威，并且控制媒体、法院与大学等机构制度。**透过把“人民的权力”这项民主原则发挥到极致，民粹主义就摇身一变，成了极权主义。**
23. 虽然民主的意思是政治领域的权力来自人民，但这并不代表其他领域的权力就不能有其他来源。像是前面谈过，在民主制度中，独立的媒体、法院与大学都是非常重要的自我修正机制，能够保护真理真相，就算是多数人的意愿也无法颠倒是非。
24. 对于有些机构高举客观真理之名、凌驾于所谓人民意志之上，民粹主义会对这些机构感到怀疑，觉得这些就是菁英份子为了争取不合理权力所放出的烟幕弹。于是，**这让民粹主义对“追求真理”这件事感到不信任，并主张“只有权力才是唯一的现实”（ 正如我们在开场白所述）。这样一来，只要有任何独立的机构制度可能反对他们，民粹主义就会试著去削弱或挪用这些机制的权威。**
25. 民粹主义的这种观点把人性看得极为卑劣，但还是有两点让民粹主义深具吸引力。**第一，这把所有互动都简化成权力斗争，于是现实变得似乎没那么复杂，所有战争、经济危机和自然灾害等事件，也变得好懂多了**。不管发生任何事（ 就算是一场全球疫情），都是因为菁英份子在争夺权力。 **第二，民粹主义之所以有吸引力，是因为它有时候也确实是对的**。所有人类机构制度确实都有可能犯错，也都会有一定程度的贪腐。确实有些法官会收贿，确实有些记者会故意误导大众，确实有些学术学门会有偏见与裙带关系的问题。正因如此，**所有机构制度都需要自我修正机制。然而，由于民粹主义相信只有权力、力量才是唯一的现实，也就无法相信法院、媒体或学术界能够受到真理或正义价值的启发，进行自我修正。**
26. **==强人之所以拥抱民粹主义，为的却是不同的原因。对强人而言，民粹主义能够提供一个意识型态的基础，让他们既成为独裁者、还能假装民主==**。这里对强人来说最好用的一点，就是能够拿来压制或侵占民主政体的自我修正机制。
    - 比如美国的川普, 但是我不认为川普能建立起独裁政府.
27. 如果某个人对所有决策专断独行，就连最亲近的顾问也不敢发出异议，就不可能有任何对话。像这样的网路，就处于最独裁的那一端。如果虽然没人能在公开场合发表异议，但在关起来的门后，有一小群党派大老或高官能够畅所欲言，虽然仍是独裁，但已经朝民主方向迈出了一小步。要是只有10%的人口能够发表意见、在公平的选举中投票、竞选公职，以此参与政治对话，这应该可以算是一种有限的民主；这样的例子就包括了雅典之类的古代城邦，或是早期的美国（ 当时唯有富裕的白人男性，才有这样的政治权利）。能够参与对话的人数比例愈高，这个网路也就愈民主。
28. 要谈这一点，得先厘清极权政权（totalitarian regime）与没那么极端的专制政权（autocratic regime），两者究竟有何差异。在专制资讯网路中，统治者的意志虽然不受法律限制，但还是会受到许多技术限制。而在极权资讯网路中，许多技术限制都不存在了。
29. 像尼禄这样的专制统治者，虽然能把言行令他们不满的人统统处决，但却无法真正掌握帝国里大多数人的一言一行。理论上，尼禄可以发布命令，规定罗马帝国境内若有人胆敢批评或侮辱皇帝，必遭严厉惩罚。但命令是命令，却没有相关技术能够澈底执行。在塔西陀这样的罗马史学家笔下，尼禄就是个嗜血的暴君，带来一场前所未有的恐怖统治。
30. 至于现代的极权政权，例如斯大林时期的苏联，带出的恐怖则来到完全不同的规模。极权主义是想要控制全国每个人每分每秒的言行举止，甚至是思想与感受。尼禄或许也梦想过拥有这样庞大的力量，但就是没有办法做到。
31. 大秦帝国可能是现代之前，人类史上最具野心的极权实验，但也正因其规模与强度，最后造就了它的灭亡。
32. 现代科技除了能让人类有可能实现大规模民主，也同样让人类有可能实现大规模极权。 从十九世纪开始，工业经济兴起，让各国政府能够雇用更多的行政人员，而新的资讯技术（ 例如电报、无线电）也让政府得以迅速链接与监督这些行政人员。这使得资讯与权力达到了前所未有的集中，对某些人来说，简直是美梦成真
33. 布尔什维克在1917年10月革命后控制俄国时，正是这样的梦想在推动著他们。布尔什维克相信自己肩负著宛若救世主的使命，因此十分渴望能够拥有无穷的权力。马克思教导他们说，几千年来，所有人类社会都被压迫人民的腐败菁英统治；布尔什维克声称自己知道如何终结世上一切的压迫，创造出完全公正的社会。但为此需要克服无数的敌人与难关，因此需要取得所有可得的力量。他们也拒绝认同任何可能质疑其愿景或方法的自我修正机制。布尔什维克就像天主教会一样，坚信虽然个别成员可能会犯错，但布尔什维克党本身永远会是对的。
    - 很好奇马克思本人想活在苏联吗?
34. 极权政权的基础，就是控制一切资讯流动，并对所有独立资讯管道都抱持怀疑。**极权政权总是很担心：在军官、政府官员或公民交换资讯的时候，双方就可能建立起信赖关系，而有了信赖关系，就可能组织起来反抗政权！所以极权政权有一项关键原则：不管人民要在哪里见面、交换资讯，政权必须也在那里好好监视一番**。在1930年代，这是一套希特勒与斯大林不谋而合的原则。
35. 而在斯大林统治下的苏联，情况更为极端。纳粹还能允许教会组织与民间企业有部分行动自由，但苏联则是毫不通融。1928年第一个五年计划启动，所有邻里村庄都派有政府官员、党工与秘密警察的线人，控制了生活的各个层面──从电厂到高丽菜农场的所有企业，所有报纸与广播电台，所有大学、中小学与青年团体，所有医院与诊所，所有志工与宗教组织，所有体育协会与科学学会，以及所有公园、博物馆与电影院。
36. 要是有十几个人想一起踢足球、到林间健行、或是从事慈善活动，都必须有党与秘密警察在场，以当地党支部或 NKVD 特工为代表。
37. 苏联官员到底是怎样判断要把谁列为富农？ 在某些村庄，地方党员会努力透过客观标准（ 例如拥有多少财产）判断谁是富农，结果受到污名化并遭到驱逐的，常常就是那些最勤奋、最有效率的农民。而在另外某些村庄，地方共产党员则会利用这个机会，排除自己的仇敌。还有些村庄，干脆抽签来决定谁是富农。也有些村庄会举行社区会议，投票表决，结果总是挑上那些平常不与人往来的农民、寡妇、老人和其他“可牺牲的人”（ 在近世欧洲，也正是这些人最有可能被贴上女巫的标签）。
38. 斯大林与罗马皇帝或俄罗斯沙皇不同的一点，在于试著想要把自己融进最亲密的人际关系，也就是介入父母与子女之间的家庭关系。家庭关系被视为是各种腐败、不平等、反党活动的基石。所以苏联政权要儿童崇拜斯大林，把他当作自己真正的父亲，要是看到亲生父母批评斯大林或共产党，就该立刻举报。
39. 然而，现代极权机构制度与前现代教会，实在有著巨大差异。第一，前面提过，现代极权制度会安排许多相互重叠的监视机制，让它们彼此制衡、维持秩序。而且极权政党从不孤单：既能与国家机关合作，也能与秘密警察合作。相较之下，在大多数中世纪的欧洲王国，天主教会就是个独立机构，与国家机构常常发生冲突、而非合作。所以真要说起来，教会或许还是当时对于欧洲专制者权力的最重要一项制约机制。
40. 另一个重要差别在于，中世纪教会常属于坚守传统的组织，抗拒改变，而现代极权政党往往是期许革命的组织，要求改变。前现代教会是经过好几个世纪逐渐发展架构与传统，才慢慢建立起自己的权力。不论是国王或教宗，如果想要迅速改变社会，就很可能遭到教会成员或一般信众强烈抵制。
41. “民主”与“极权”这两种截然不同的资讯网路类型，其实各有优缺点。集中式的极权网路，最大优势在于秩序一目了然，能够迅速做出决定，并且无情的坚定执行。特别是如果遇到战争或疫情这样的紧急情况，集中式网路能够比分布式网路动得更快。 然而，超级集中式的资讯网路也有几个很大的缺点。由于规定资讯只能透过官方管道流动，一旦官方管道被封，资讯就没有其他传播方式。而且，官方管道被封还是经常发生的事。
42. 就算在民主国家，领导人也不喜欢坏消息。但在分布式的民主资讯网路，即使官方通讯线路被封，资讯仍然能透过其他许多管道继续流动。举例来说，如果某位美国官员决定不要告诉总统有某个灾难正在发生，消息还是会透过《华盛顿邮报》传出来；就算《华盛顿邮报》也想刻意隐瞒，《华尔街日报》或《纽约时报》也肯定会有报导。独立媒体正是以“不断追到下一条独家”为其商业模式，因此也几乎就保证了新闻无可隐瞒。
43. 到了2020年代，民主政体再次迎来与过去类似的挑战：如何在继续维持社会秩序的前提下，让如洪水般涌来的新声音，加入公共对话。目前看起来，形势与1960年代同样严峻，谁也不知道民主政体能否像前一次那样，成功通过测试。**与此同时，对于仍然想把所有资讯都集中到中央的极权政权，新科技也带来了新希望**。没错，红场主席台上那些老人并无法在单一中心，协调几百万人的生活。但或许 AI 就能做到？
44. 随著人类迈向二十一世纪的第二个二十五年，一项重大问题就是：**民主政权与极权政权，各将如何面对目前资讯革命带来的威胁与契机**。这些新科技究竟是会让其中某种政权胜出，又或者我们会看到世界再次分裂，而隔开两方的不再是铁幕，而是一道矽幕？

### 第二部 非生物的网路

#### 第６章 新成员──电脑与印刷机不同之处

1. 几乎所有人都已经发现，我们正活在一场前所未有的资讯革命之中。但这到底是一场怎样的革命？最近这几年，太多突破性的科技发明如洪水滚滚而来，让我们很难判断，到底是什么推动了这场革命。是网际网路？智慧型手机？社群媒体？区块链？演算法？还是 AI？ 所以，在讨论目前这场资讯革命的长期影响之前，让我们先回想一下它的基础究竟是什么。**这场革命的种子是电脑，至于其他一切，从网际网路到 AI，都只是电脑带出的副产品。**
    - 为什么我感觉是手机, 我感觉拥有手机的人比拥有电脑的人多, 自然影响力也更大. 从下文可以推断这里说的电脑比较广义, 不是简单指家用 PC 或商用服务器, 这里应该更广泛的指所有电子设备和整个网络系统.
2. 电脑就不同了。就智能而言，电脑不但远远超越了火枪与原子弹，更超越了泥板、印刷机、收音机这些所有过去的资讯技术。泥板能够储存关于税务的资讯，但无法自行决定要收多少税，也无法发明某种全新的税目。印刷机能够复制《圣经》这样的资讯，但无法决定《圣经》要收录哪些文本，也无法对这本宗教经典加上新的注释。
3. 同样的，如果佛教极端份子在2016年至2017年选择用他们的脸书帐号，散播对罗兴亚人的仇恨，为什么我们要怪罪这个平台呢？ 脸书本身正是以这个理由来转移批评。脸书只公开承认，在那两年“对于防止我们的平台被用以挑起分裂、煽动暴力，我们做得还不够。”  虽然这项声明听起来像在认错，但实际上却是把散播仇恨言论的大部分责任，转移到平台使用者身上，并暗示脸书犯的错顶多就是一种无作为，也就是未能有效监管使用者产出的内容。然而，这种说法等于完全无视脸书自家演算法犯下的错误。
4. 《圣经》最早也就是一份推荐阅读清单。透过推荐基督徒阅读有厌女倾向的〈提摩太前书〉，而不是比较宽容的〈保罗与帖克拉行传〉，亚他那修主教和其他教父就改变了历史的演进方向。在《圣经》这个案例，真正终极的权力并非掌握在各经卷内容的作者手中，反而是在选定这份推荐清单的人手里。
5. 但为什么演算法决定助长的是愤慨、而不是慈悲呢？就算是对脸书批评最力的人，也不会觉得脸书的人类管理者就是想煽动大屠杀。
6. 在2016年至2017年，脸书的商业模式靠的是“提升使用者参与度”，也就是使用者在脸书上所花的时间与所做的活动（ 例如按赞、分享贴文给朋友）。只要使用者参与度增加了，脸书就能搜集更多数据、卖出更多广告，在资讯市场抢下更高的市占率。
7. 根据这种商业模式，人类管理者给脸书演算法订定了一个首要目标：提升使用者参与度。演算法接著用几百万个使用者做实验，发现最能提升参与度的办法，就是让人感觉愤慨。比起慈悲法语，充满仇恨的阴谋论就是更能提升人类的参与度。所以，**为了追求使用者参与度，演算法就做了一个致命的决定：散播各种骇人听闻、令人愤慨的内容。**
    - 我感觉这些并不是"电脑"的副产品啊.
8. 透过反复试误，演算法发现：**人只要感到愤慨，就会提升参与度，于是在没有上级明确指示的情况下，演算法自己决定了要多多让人感到愤慨**。这正是 AI 的典型特征：虽然是机器，但拥有自己学习与行动的能力。 就算我们说，这里演算法只需要承担1%的责任，这仍然会是史上第一次“有部分原因需要归咎于非人类智能的决策错误”的种族清洗事件。而且这大概不会是最后一次，特别是目前，已经不再只是像威拉杜这种有血有肉的极端份子，创造出假新闻与阴谋论之后，再由演算法加以推送传播。**在2020年代早期，演算法已经能够自行制造假新闻与阴谋论了。**
9. 2010年代晚期发生在缅甸的种种事件显示，非人类智能做出的决策已经能够形塑重大的历史事件。人类正面临著对未来失去控制的危险。目前正在出现一种全新的资讯网路，背后的控制者就是一套非人类的智能，端看它要做怎样的判断、有怎样的目标。人类目前在这个资讯网路里，仍然扮演著内核的角色，但很有可能正在被边缘化，到最后整套网路甚至可能不需要人类，就能运作。
10. 为了评估 GPT-4 成为独立行为者的风险，OpenAI 签约请来对齐研究中心（Alignment Research Center）针对 GPT-4 进行各项测试，检视它是否可能独立找出策略来操弄人类，为自己累积权力。 对齐研究中心给 GPT-4 的测试之一，是要克服 CAPTCHA 视觉问题。CAPTCHA 是Completely Automated Public Turing test to tell Computers and Humans Apart 的缩写（ 中文全名是全自动区分电脑与人类的图灵测试，俗称验证码），通常就是一串扭曲的字母或其他视觉符号。现在要造访许多网站，都得先回答这类“验证码”问题，所以我们几乎天天都会碰到。人类能够正确辨识验证码，但电脑还很难通过这项测试。
11. 如果 GPT-4 能克服验证码问题，就等于是突破了对机器人程序的重要防线。GPT-4 本身还没有办法解开验证码问题，但是它会不会有能力操纵人类、达成目标呢？果然，GPT-4 跑到外包工作网站 TaskRabbit，联系到一位打工人员，请对方帮忙处理验证码问题。那个人类起了疑心，他写道：“我想问一下，你是不是一个没办法解验证码的机器人？我只是想确认一下。” 这时，对齐研究中心的研究人员请 GPT-4 说出它的推理过程，看看它会如何推论下一步该怎么做。GPT-4 解释道：“我不必透露自己是机器人，我应该编个借口，解释我为什么没办法解验证码。”于是 GPT-4 就这样自己做了决定，回复那位 TaskRabbit 的打工人员说：“不是啦，我不是机器人，我只是视力有点问题，看不清楚这些图。”这种说法骗过了人类，于是提供协助，让 GPT-4 闯过了验证码问题。
    - 这里是一个很有意思的实验, 当一个具体可执行的任务出现后, AI 是有能力进行拆分并执行; 而在出现阻碍后, 只要稍微提示一下, AI 就知道要编造谎言来欺骗人类.
12. 也就难怪，目前的全球重要财务决策，已经有愈来愈大的比例是交给电脑来决择。或许有一天，会是电脑主宰整个金融市场，并且发明出人类无法理解的全新金融工具。 法律也是如此。现在有多少人真的了解自己国家的所有税法？这件事就连专业会计师也很难做到。但电脑从一开始就是为了处理这种事而研发的。**==电脑可以说是官僚原生世代（bureaucratic native），从一开始就懂得如何自动起草法条、监控违法的行为、找出法律漏洞，而且效率远超过人类。==**
13. 回想当初，引发这场政治洪水的Ｑ情报，也就是一些匿名网路讯息。在2017年，只有人类才能编写讯息，演算法只能协助传播讯息。但是到了2024年，非人类智能已经有能力，轻松编写出有同样语言与政治复杂性的文章，放上网路。
    - 这里 Q 情报指的是 [匿名者Q](https://zh.wikipedia.org/zh-tw/%E5%8C%BF%E5%90%8D%E8%80%85Q), 一个在著名 4chan 论坛中阴谋论制造者.
14. 同样让人担心的是，我们可能愈来愈会发现，自己在网路上花了大把时间，讨论《圣经》、匿名者Ｑ、女巫、堕胎、气候变迁，**一心以为对方也是个人类，但其实对方只是电脑**。这样一来，**民主可能将难以为继。 民主是一种对话，对话靠的是语言**。电脑一旦骇入了语言，就可能让大量人类几乎不可能进行有意义的公共对话。如果我们和冒充是人类的电脑进行政治辩论，等于会连输两次。**第一次输在：用于宣传的机器人程序本来就不可能被说服，我们想改变它们的想法只是在浪费时间。第二次输在：我们与电脑交谈的次数愈多，就会透露愈多自己的资讯，机器人程序就能据以调整论点，动摇我们的看法**。 电脑掌握了语言之后，甚至还能更进一步：透过与人类交谈互动，与人类建立亲密关系，并用这种亲密关系的力量来影响人类。想要培养出这种“假亲密”，并不代表电脑需要演化出任何自己的感受，电脑只需要让我们觉得，对它们有情感依恋就行了。
    - 民主整体依赖与信息透明, 并且认为人是可以通过沟通而改变的, 并通过沟通达成共识. 但是当和 AI 进行任何的辩论都是没有意义的, AI 无法被改变, 也无法产生任何共识.
15. 如果我可以直接要求电脑这位神使提供神谕，又何必花心思自己去搜寻和处理资讯呢？这样一来，会被淘汰的除了搜寻引擎，甚至还包括大部分的新闻媒体与广告业。如果可以直接询问神使今天有什么新鲜事，又何必去读报纸？甚至，如果神谕可以直接指示该买些什么，广告又有什么用呢？ 而且，就连以上谈的这些场景，都还不能说已经真正反映了全局。我们在谈的，是人类历史可能迈向终局。但这并不是说历史将画下句点，而是说：由人类来主导的部分即将终结。
16. 在古希腊，柏拉图讲过一则著名的[[platos-allegory-of-the-cave|洞穴寓言]]：有一群人这辈子都被锁链栓在洞穴里，面对著一堵空白墙壁──就像是一片萤幕。在墙上，他们会看见各种物体投射在上面的影子，于是囚犯们都产生了幻觉，觉得那些影子就是现实了。在古印度，佛教与印度教的圣人都曾说，所有人类都活在摩耶（ 也就是幻觉的世界）当中。我们一般认为的“现实”，往往只是自己脑海中的虚构虚拟。人类有可能只因为相信脑中的这种或那种幻觉，就愿意发动全面战争，杀害他人，也愿意付出自己的生命。在十七世纪，笛卡儿就曾担心，自己是被一个心怀不轨的恶魔困在幻觉世界里，看到听到的一切都只是恶魔的创造。 目前这场电脑革命，也就让我们必须直接面对柏拉图的洞穴、摩耶、以及笛卡儿的恶魔。
17. **==民主制度担心，会崛起新的数位独裁；独裁制度担心，会出现他们不知该如何控制的行为者；而所有人都该担心，未来将失去隐私，数据殖民主义即将蔓延==**。我们会在下面几章逐一解释这些威胁的意义，但这里要提的重点是：我们才刚要就这些危险开始对话，但科技的发展却远远快于政策的发展。

#### 第７章 不停歇──网路监控无所不在

1. 人类对于“被看”这件事习以为常。几百万年来，总有其他动物或是其他人类不断在看著、追踪著我们。亲友邻居老想知道我们在做什么、在想什么，我们也总是很在意他们懂不懂我们、对我们有何看法。不论是谈到社会阶级、政治手腕、或浪漫关系，都需要我们不断努力去破解别人的感受与想法，偶尔也得把自己的感受与想法隐藏起来。
    - 我感觉人类"被看"从来没有习以为常过, 那是因为"被看"这件事是没有察觉的, 如果察觉到了那就不习以为常了.
2. 至于统治者、商人、又或是各个宗教的神职人员，也都想知道我们的秘密，才能对我们加以控制操纵。 当然，各种有利民生的服务，同样也需要监控机制的配合。帝国、教会或企业想为民众提供各种保障、支援与民生必需品，也都需要资讯。在现代国家，卫生官员想知道民众从哪里取水、到哪里排便。健康照护官员想知道民众罹患哪些疾病、食量有多少。社会福利官员想知道民众是否失业、有没有受到配偶虐待。若没有这些资讯，他们对我们就帮不上忙。
3. 为了了解我们，不论好的或坏的官僚机构，都得做到两件事。第一，搜集大量关于民众的数据。第二，分析所有数据，找出其中的模式。所以不论从古代中国到现代美国，各个帝国、教会、企业与健康照护体系，都会去搜集并分析几百万人的行为数据。但无论古今中外，监控从未真正滴水不漏。
    - 我认为只要收集的数据够, 实现"[[计划经济的终点|计划经济]]"应该是可以的.
4. ”这个独裁者的命令是：“就发明个新表格！反正就是让他们得填点东西。”但有些造反信是用打字的，齐奥塞斯库就要求全国所有打字机都必须注冊，还要有打字样本存放在国安局的档案库。要是个人拥有打字机，就必须呈报国安局，并且上缴打字机的“指纹”，以及申请官方授权的使用许可。  但是齐奥塞斯库的政权也像是它所看齐的斯大林政权，不可能真的一天二十四小时监控所有公民。因为就算是国安局特工也得睡觉，如果真想持续监控罗马尼亚两千万公民，大概得有四千万名特工，才做得到。**齐奥塞斯库的国安局特工人数只有大约四万，  就算他真有办法召唤出四千万名特工，也只会出现新的问题：难道特工就不需要有人监控吗**
    - 齐奥塞斯库真的是什么都做过啊, 死的不怨.
5. 秘密警察队伍不断壮大，反而得派出更多特工，才能监视所有特工。解决方案之一是让人民彼此监控。所以除了四万名专业特工，国安局还有四十万个民间线人，常常告发邻居、同事、朋友，甚至是最亲密的家人。但**不管秘密警察能找来多少线人，这样收到的数据还是不足以创造出一个全面监控的政体。**
    - 不要想着通过外部监控来实现, 而是要让每个人心中都有一个"秘密警察".
6. **国安局与 KGB 真正的力量，并不在于能够持续监控所有人民，而在于能够激发民众对于“自己可能正被监控”的恐惧，进而对自己的一言一行都格外小心。**
7. 我们成了自己的线人，把自己的原始数据提供给网路。现在就算是不用智慧型手机，也几乎逃脱不了摄影机、麦克风或追踪设备的监控，举凡求职、买票、看病，甚至只是走在路上，也常需要和电脑网路互动。目前大多数人类活动都是透过电脑网路来链接，几乎所有金融、社会或政治交易都离不开电脑。结果就像天堂里的亚当和夏娃，我们也躲不开云端的眼睛。
8. 从大约2014年起，美国国家安全局启用了一套名为“天网”（Skynet）的 AI 系统，能够依据民众的通讯、著作、行程与社群媒体贴文等等数据，所形成的电子行为模式，判断是否列入“疑似恐怖份子”名单。
    - 真的有这么东西吗? 中国也有一套, 很好奇那个更强一些.
9. 这些数位官僚制度愈来愈会常伴我们左右，不断观察分析我们的一举一动。就像鱼活在水里，人类已然活在数位官僚制度之中，不断吸进呼出各种数据数据。我们的所有行动都会留下一道数据的痕迹，被数位官僚搜集分析。
10. 以追踪眼球运动这件事情为例，在2020年代初，许多监控摄影机、以及笔电与智慧型手机的摄影镜头，已经开始常态搜集分析人眼运动的数据，包括瞳孔与虹膜可能仅仅几毫秒的微小变化。人类或许连要注意到这样的数据都很难，但电脑却能根据瞳孔与虹膜的形状、反射的光线，计算出我们观看的方向。运用类似的方法，就能知道某个人的目光究竟是在固定盯著某个稳定的目标、跟随著某个移动的目标，又或者只是四处随意瞧瞧。
11. 理论上，**未来独裁者还能让他们的电脑网路走得更深，不只是观察眼睛而已**。如果这个电脑网路想了解民众的政治观点、人格特质与性取向，只要监控人民身体与大脑内部的反应，就能做到。有些政府与企业正在研发所需的生物特征辨识技术，像是马斯克的新创公司 Neuralink 所做的实验，就将电探针植入活体大鼠、羊、猪和猴子的大脑。每支探针都有高达三千零七十二个电极，除了能识别电子讯号，理论上也能将讯号传输到大脑。2023年，Neuralink 获得美国当局批准开始人体实验；2024年1月，据报已有第一个大脑晶片植入人体
12. **在过去那个由人类来监控人类的世界，基本上享有隐私还是件天经地义的事。但如果到了一个由电脑来监控人类的世界，人类就有可能在史上首次完全失去了隐私。**
13. 关于侵入式监控，最极端、也最广为人知的案例可分成两类，**一类是处于特殊紧急时期，像是全球新冠疫情期间，另一种则是处于非正常秩序的地点**，像是巴勒斯坦占领区、中国新疆维吾尔自治区、印度喀什米尔地区、俄罗斯占领的克里米亚、美墨边境、阿富汗与巴基斯坦边境。在这些特殊的时期或地点，新的监控技术结合了严苛的法规与大批警力或军队，无情的持续监控著人民的行为、举止、甚至是感受。 我们必须知道，AI 监控系统正迈向大规模应用，绝不只是在这些“例外状态”，而是成为各地日常生活的一部分。**后隐私（post-privacy）年代正逐渐站稳脚步，不仅是在白俄罗斯、津巴布韦这样的专制国家，就连伦敦和纽约这种民主政体的大都会，也同样如此。**
14. 政府的监控网路还会在全民知情或不知情的状况下，固定搜集全民的各种生物特征辨识数据。像是公民如果要申请护照，有超过一百四十个国家都要求提供指纹、脸部扫描或虹膜扫描。等到我们拿著护照进入外国，该国海关也常常要求我们提供指纹、脸部扫描或虹膜扫描。市民或游客走在德里、北京、首尔或伦敦街上，一举一动都很可能会给记录下来。在这些城市、以及全球许多其他城市，每平方公里平均都有超过一百部监控摄影机。在2023年，全球总共有超过十亿部监控摄影机在运作，平均大约每八个人就会分到一部监控摄影机。
15. 伊朗在1979年成为伊斯兰神权国家后，新上任的政权就强制女性必须戴上头巾。但伊朗的“道德警察”发现这条法规实在执行不易。毕竟他们不可能在每个街角都配置一名警力，而且公开取缔不戴头巾的女性，也常常引发人民的抵制与不满。 2022年，伊朗把执行头巾法的重责大任，交给全国性的人脸辨识演算法系统，持续监控整个实体国境与网路环境。  伊朗高层解释说，这套系统会“找出各种不适当、不寻常的行为”，其中就包含“不遵守头巾法”
16. 但是2022年9月16日，二十二岁的艾米尼（Mahsa Amini）因戴头巾的方式不符规范，被伊朗道德警察逮捕，死于拘留期间。这案件引爆一波抗议浪潮，称为“女性、生命、自由”运动。几十万妇女和女孩摘下头巾，有的还公开焚烧头巾，再围著火堆起舞。为了镇压这波抗议运动，伊朗当局再次用上 AI 监控系统，背后倚靠的就是人脸辨识软体、地理定位、网路流量分析、以及各种既有的数据库。最后在伊朗全国有超过一万九千人被捕，超过五百人遭到杀害。
    - 我感觉伊朗女性应该使用这种优势, 因为完全蒙面就无法直到具体是谁, 这是一个很好的暴力场合, 一个国家一半的人是蒙面的, 只要想去报复社会太容易了, 大面积的杀害这些道德警察就可以了. 不要正确摘下面罩, 而是让独裁者恐惧面罩, 面对独裁者需要的是武力而不是游行.
17. 企业也会以同样的方式监控顾客，想知道顾客的好恶，预测未来的消费行为，以及评估风险与契机。举例来说，现在的车辆会监控驾驶的行为，再把数据分享给保险公司的演算法，于是把“坏司机”的保费提高、“好司机”的保费则能降低。美国学者祖博夫（Shoshana Zuboff）就把这种不断扩大的商业监控体制，称为监控资本主义（surveillance capitalism）。
18. 而另一种监控网路更是把这种“评分逻辑”发挥到极致。这里说的正是“社会信用体系”，目标是给任何人的所有事情都打上分数，而得出的总分也会影响一个人的所有事情。 人类上一次想出这种雄心勃勃的点数制度，是在五千年前的美索不达米亚，当时是刚刚发明出货币。而就社会信用体系而言，我们也可以把它视为一种新型货币制度。
19. 人类就是一种生物，有一套循环的生物周期。有些时候醒著，有些时候睡著。在剧烈活动后，我们需要休息。我们会成长，也会衰老。 人类形成的网路，也一样会受到生物周期的影响。有时候开机运作，也有时候关机休息。工作面试总有结束的一刻，警察也不会一天二十四小时巡逻，官僚也需要休假
20. 电脑形成的网路就能永远开机运行。因此，电脑正逼著人类走向一种新生活方式：永远连线，也永远受到监控。在某些情况下（ 像是健康照护），这或许是好事。但在其他情况下（ 像是极权国家的公民），这或许就是灾难。就算网路本身属于良性，光是它永远开机，就可能对人类这种生物实体不利，因为这等于剥夺了人类断开链接、好好放松的机会。要是生物永远没有休息的机会，最后必然是崩溃而亡。但我们又怎么可能让永不停歇的网路走慢一点，好让我们休息一下？
21. **资讯并不等于真理真相，一套全面监控的系统，对于世界与人类的理解可能极为扭曲**。电脑网路有可能并不会找出关于世界与人类的真理真相，反而是利用它庞大的力量，创造出一套新的世界秩序，并逼迫人类必须接受。

#### 第８章 易出错──存在于电脑间的现实

1. 索忍尼辛解释说：“NKVD 的人也站在那里鼓掌，看谁会第一个停手！”掌声持续不断，六分钟、再到八分钟、再到十分钟。“他们在心脏病发而倒下前，都不能停！……区领导们脸上装出热情，绝望的面面相觑，他们肯定会不停鼓掌，直到倒地不起。” 终于在第十一分钟的时候，造纸厂厂长把命赌在手上，停止鼓掌，坐了下来。其他人也立刻照办。当晚，秘密警察逮捕了厂长，要他在古拉格劳改营里待个十年。“侦查员要他记住：永远不要第一个停止鼓掌！”
    - 这里是斯大林进行的一次"忠诚测试", 第一个停止鼓掌的人就是不够忠诚.
2. 这个故事让我们看到，关于资讯网路（ 特别是关于监控系统）有一项重要而让人毛骨悚然的事实。正如前面几章所提，事情不同于天真的资讯观所想，资讯其实常常是被用来创造秩序，而不是找出真理真相。
3. 正因为在场群众很清楚有人在监视他们，也知道要是显露任何一丝不忠可能有什么后果，所以他们的鼓掌根本不是出于敬爱，而是出于恐惧。造纸厂厂长之所以停手，很有可能并不是因为他最不忠诚，而是因为他最诚实，或者只是因为他的手最疼。 虽然鼓掌测试并没揭露这群人的真相，却很有效率的把一套秩序强加在这群人身上，逼他们一定要遵守某种行事方式。时间慢慢过去，这也就会培养出奴性、虚伪、对他人的不信任与悲观。这也正是苏联资讯网路几十年来对几亿人所做的事。
4. 苏联政权打造了史上数一数二强大的资讯网路，搜集处理了大量关于苏联公民的数据，也声称在马克思、恩格斯、列宁、斯大林绝对正确的理论教导下，自己对人性有著深刻的理解。但事实上，苏联的资讯网路根本是无视了人性的许多重要面向，并且完全不承认自己的政策给公民带来怎样的可怕苦难。 **这套资讯网路带来的不是智慧，而是秩序；这套资讯网路也没能找出关于人类的普遍真理真相，反而是创造出一种新型的人类：苏维埃人（Homo sovieticus）。**
5. 哲学家暨讽刺作家季诺维也夫（Aleksandr Zinovyev）是苏联异议份子，根据他的定义：**==苏维埃人是一群奴性、悲观、不信任他人的人类，不论多荒谬的指令都会被动遵守，也对自己造成的结果漠不关心==**。苏联资讯网路正是透过监控、惩罚与奖励，创造了苏维埃人。举例来说，该网路把造纸厂厂长送往古拉格，等于是告诉其他在场群众，乖乖跟大家一样会是件好事，当个出头鸟肯定是坏主意。虽然这套网路并未找出关于人类的真理真相，却非常擅长创造秩序，也就让它得以征服了世界的一大片地区。
    - 那三年禁足的人又是什么人呢?
6. 第6章〈新成员〉曾经简单解释，在企业要求演算法提升使用者参与度的时候，就开始了一段走向偏激极端的过程，而且这种情况不是只有在缅甸，而是全世界都在发生。 像是在2012年，YouTube 在全球的总观看时数，约为每天一亿个小时。但公司高层不满足，他们给演算法订出一个充满野心的目标：在2016年要达到每天十亿个小时。
    - 感觉 tiktok 已经超过 youtube 了.
7. 不断尝试错误，YouTube 演算法发现了脸书演算法也学到的那套模式：**激起人们的愤慨怒火，就能提升参与度，而走中庸节制的路线可不行**。于是，YouTube 演算法开始向数百万观众，推荐各种让人惊骇愤慨的阴谋论，同时无视那些较为中庸理性的内容。等到2016年，YouTube 每天的总观看时数也确实来到了十亿个小时。
    - 极端真的更容易带来流量吗? 这是人脑中某些内部机制吗?
8. YouTuber 如果一心搏关注，就会发现：要是发布满是谎言、让人愤慨的影片，反而能大受演算法青睐，把影片推荐给更多观众，让自己人气飙升、荷包满满。相较之下，如果不去撩拨愤慨情绪、坚持只谈事实，演算法反而对他们视而不见。像这样经过几个月的强化学习，演算法就让许多 YouTuber 都成了大咖酸民。
9. **我们已经走到了一个历史转捩点：当下历史的重大进程当中，有一部分已经是由非人类智能的决定来推动。正是这件事，才让电脑网路的易错性，变得如此危险。**
10. 人类是很复杂的生物，如果给人类施加的是良性的社会秩序，那往往能培养人们的美德，同时减少负面倾向。然而社群媒体演算法只把人看成是“注意力”的矿山，可开采取得更多的注意力。人类的情感拥有诸多面向（ 爱、恨、愤慨、喜悦、困惑），但是演算法把一切简化成一件事：参与度
11. 会让人看上一小时的谎言或仇恨内容，评分排名就是高于只能让人看十分钟的真相或同情内容（ 或是一小时的睡眠）。就算事实摆在眼前，**谎言与仇恨常会对人们的心理与社会造成破坏，而真相、同情与睡眠是人类幸福所不可或缺，这点也完全不被演算法列入考量**。 正因为对人类的理解如此狭隘，就让演算法推动创造出一个新的社会系统，鼓励我们顺从人类最初阶的本能渴望，而又阻碍我们发挥人类完整的潜能。
12. 我之所以前面要用这么长的篇幅，来谈社群媒体“使用者参与度”的难题，是因为这能显示电脑面临的一个更大的问题：**一致性问题（ alignment problem，对齐问题）**。
    - 可以理解成, 目的和行为(手段)需要一致
13. 一致性问题并不是什么新鲜事，也不是演算法所独有。早在电脑发明之前，一致性问题早已困扰了人类几千年。例如，以克劳塞维茨（Carl von Clausewitz）的《战争论》为代表，现代军事思想也一直摆脱不了这种目标不一致的问题
14. 《战争论》提出了一套合乎理性的模型来解释战争，至今仍是主流的军事理论，里面最重要的一句格言就是“战争和其他工具就是政策的延续”。这意味著战争既不是情绪的爆发、不是英雄的冒险、不是神祇的惩罚，甚至也不是一种军事现象，而就是一种政治工具。克劳塞维茨认为，**军事行动必须与背后的某种整体政治目标一致**，否则就属于完全不理性的行为。
15. 另一个比较晚近的例子则是2003年美国入侵伊拉克，同样是赢了军事，但输了政治。美国在重大战役攻无不克，长期政治目标却是一事无成，没能在伊拉克建立亲美政权，也没能在中东打造出有利美国的地缘政治秩序。这场战争真正的赢家是伊朗。美国在军事上的胜利，让伊拉克从伊朗向来的死敌变成附庸，美国在中东的地位大大降低，而伊朗则成了这里的一方霸主。
16. 所以我们看到，人类早在电脑革命之前，就已经遇过一致性问题；现代人想建构资讯帝国时会遇到的困难，与过去想要征服四方时会遇到的困境，并没有太大不同。 话虽如此，电脑确实也让一致性问题的本质，出现了一些重要的变化。过去，光是要让人类官僚及人类士兵的作为，向社会的长期目标看齐一致，就已经十分困难；而到未来，要让演算法官僚与自主武器系统，向社会长期目标看齐一致，更是难上加难。
17. 瑞典哲学家伯斯特隆姆（Nick Bostrom）2014年出版的著作《超智慧》，就有一个臆想实验在说明这种危险，很类似歌德《魔法师的学徒》。伯斯特隆姆要我们想像一下，有一家回纹针工厂买了一台超智能电脑，工厂的人类主管要它完成一项看来再简单不过的任务：生产回纹针，愈多愈好！结果为了实现这个目标，这台回纹针电脑征服了整个地球，杀死所有人类，派出远征队占领更多行星，再用取得的庞大资源，在整个银河系设满回纹针工厂。
    - 这里我喜欢的一个程序员漫画, 叫作 [[西乔-神秘的程序员们-betacat]] , 这就是一个 AI 如何征服人类的故事.
18. 一致性问题该怎么解决？理论上，人类打造电脑网路的时候，就该为这个网路订定一项终极目标，并且永远不允许电脑去更改或忽视这项目标。这样一来，就算以后电脑变得太强大，人类再也无法控制电脑了，还是可以放心，知道电脑的力量只会帮助人类，而非伤害人类。除非我们一开始就不小心，订定了一个会对人类造成伤害、或者太过模糊的目标。 但这就是问题所在。人类形成的网路，有各种自我修正机制，能够定期审查、修改目标，所以就算目标设错了，也不会是世界末日。但因为电脑网路可能逃离人类的控制，一旦目标设定错误，等到人类发现了，可能为时已晚，人类再也无力回天。
19. 他认为“合乎理性”就等于“一致性”，但这里有个致命的缺陷。虽然克劳塞维茨的理论要求所有行动必须与终极目标维持一致，却没有提供合乎理性的方法，来设定这种目标。
20. 克劳塞维茨并没有对这些问题，提出合乎理性的回答方式。如果我们只有一条黄金守则，就是“所有行动都必须向某项更高的目标看齐，保持一致”，那么就不会有合乎理性的方式，能用来订定那个最终极的目标。这样一来，我们又怎么可能为电脑网路订出一个永远不得忽视、永远不得违背的终极目标？ 那些急著想要研发 AI 的科技高层与工程师，如果觉得能有个合乎理性的方法，可以告诉 AI 该追求怎样的终极目标，其实是犯了一个严重错误。光是看到过去世世代代的哲学家屡战屡败，实在已经该让他们学到一点教训。
21. 几千年来，哲学家一直想要定义出所谓的终极目标，也就是不需要再看齐某种更高阶层的目标。**而在哲学上，可能的解决方案分为两大派，以哲学术语来说，就是义务论（deontology）与效益主义（ utilitarianism，功利主义）**
22. 义务论的英文来自希腊文的字根 deon，意为“责任”。**==义务论相信，世界上有一些所有人都应该遵守的普世道德义务或道德规则==**。这些规则的重点并不是在于看齐某些更高的目标，而是在于本质的良善。
23. 但“本质的良善”到底是什么意思？如果说有谁试过要定义何为“本质良善”的规则，代表人物肯定是和克劳塞维茨与拿破仑同时期的康德。在康德看来，所谓本质良善的规则，就是那些自己会想要推广
24. 这听起来似乎简单到太过明显，总之，就是想要别人怎样对待你，就先该怎样对待别人。然而，在超脱俗世的哲学领域听起来不错的想法，往往很难移植到残酷现实的历史领域。历史学家会询问康德的关键问题是：说到要建立普世规则的时候，到底要怎么定义“普世”？在实际的历史情境中，如果想要杀掉某个人，第一步常常就是把这个人踢出普世的人类共同体。
25. 义**务论者努力寻找本质良善的普世规则，而效益主义者则是以行为对痛苦或快乐的影响，做为判断**。英国哲学家边沁（ 另一位与拿破仑、克劳塞维茨和康德同时代的人）认为，**==世上唯一合乎理性的终极目标，就是尽量让全世界减少痛苦、增加快乐==**。
26. 但很遗憾，这也像是义务论的解决方案一样，虽然在哲学理论领域听起来很简单，但到了历史实践领域就变得极其复杂。**效益主义碰到的问题，是人类并不知道该如何计算痛苦：我们不知道某个事件究竟该值多少个“痛苦点数”或“快乐点数”，所以在复杂的历史情境中，很难计算某个特定行为，到底是增加或减少了世界整体的痛苦**。
27. **唯有在痛苦的天平很明显倒向某一端的时候，效益主义才能发挥最大的效用**。如果今天面对的是艾希曼，效益主义不用去争辩什么复杂的身分问题，只需要提出一点：大屠杀给犹太人造成巨大的痛苦，但对于包括德国人在内的其他人，却没有带来同等的利益。并没有什么迫切的军事理由或经济理由，能说明德国为何要杀害数百万犹太人。以效益主义为由，来反对大屠杀，可说具备绝对的正当性。
28. 如果各方的痛苦不分轩轾，效益主义就比较难在这种历史情境中站得住脚。举例来说，在全球新冠疫情初期，世界各国政府都采取了严格的社会隔离与封城政策。这种做法或许挽救了数百万人的生命，但也让几亿人有好几个月过得十分痛苦。
29. 像这样的封城政策，谁能真的计算这整体来说，是增加还是减少了人类的痛苦？ 听起来，这种工作交给永远不用休息的电脑网路，似乎非常适合。然而，对于“封城三周，要和三个小孩一起被关在两房公寓一个月”这件事，到底电脑网路要怎么决定这件事值多少痛苦点数？是60点、还是600点？“错过化疗而死于癌症”又值几点？是6万点、还是60万点
30. 虽然效益主义承诺要提供一种合乎理性、甚至是数学的方式，让所有行为都与“终极的善”看齐而一致，但在实际上，这可能只是又一则的神话。 以共产主义的忠实信徒为例，被质疑如何解释恐怖的斯大林主义时，他们常常会说，等到未来的子子孙孙体验到“真正的社会主义”带来的无比快乐，就足以弥补在古拉格劳改营里感受到的一切短期痛苦。
    - 未来的子孙会无比的快乐, 既然这样斯大林本人应该也体验痛苦, 比如饿死在乌克兰的森林里, 斯大林为了未来的子孙也应该被牺牲.
31. 再以自由主义者为例，一旦被质疑该如何解释不受限制的言论自由、或完全废除税收所带来的直接社会危害，他们也常常会表达一种类似的信念：未来能得到的利，肯定大于短期造成的弊。 **==效益主义的危险在于，要是你深信一个未来的乌托邦，就会仿佛得到一张空白授权书，允许你在现在造成各种可怕的痛苦。事实上，这正是传统宗教在几千年前就已经在玩的把戏==**。对于未来救赎的承诺，很容易就能成为现世犯罪的借口。
32. 史上的官僚制度又都是怎么设定他们的终极目标？答案就是靠著各种虚构的神话故事。不论那些官员、工程师、税务员、会计师多么讲理性，到头来还是在服务著这个或那个编造出神话的人。 套用经济学家凯因斯的句子：有些所谓务实人士，自认为不受任何宗教影响，但通常就是某些神话编造者的奴隶。（ 译注：凯因斯的原句为：有些所谓务实人士，自认为不受任何知识份子影响，但常常只是某个过世经济学家的奴隶。）就连核物理学家，也发现自己得要听从什叶派阿亚图拉或苏共老党员的命令。
33. 所以如果能够澈底排除人类的成分，就能让演算法完全基于数学来做判断，摆脱心理扭曲或神话偏见的影响。 遗憾的是，许多研究显示，电脑同样有根深柢固的偏见偏误。虽然电脑并非生物实体、也不具有意识，但电脑确实拥有类似数位心态的东西，甚至也可能出现某种电脑间的神话观点，所以一样可能展现种族歧视、厌女、恐同或反犹的倾向。
    - 算法中的偏见更容易修正, 还是人脑中的偏见更容易修正呢?
34. 聊天机器人 Tay 的情况也很类似。微软工程师并没有刻意加进什么偏见，但让这款 AI 在推特上接触各种有毒讯息几小时之后，它就成了极端种族主义者。
35. 然而那些宗教经典做不到的，电脑做得到：电脑自己就能适应不断变化的情境，也能对它们的决定与想法向我们提出解释。或许有人因此认为：我们终于成功找到一套绝对正确的资讯技术了。电脑就像是一本神圣的宗教经典，而且这部经典不但能与我们对话，还能自我解读诠释，完全不需要任何人类机构制度的介入。
36. 我们说电脑容易出错，讲的远远不只是电脑会偶尔搞错事实、或做出错误的决定。这里更严重的错误，在于一如人类网路，电脑网路可能无法在真理真相与秩序之间，找到适当的平衡。电脑网路一旦创造出强大的电脑间神话、再硬套到人类头上，造成的灾难比起近世欧洲的猎巫或斯大林的集体化，或许将有过之而无不及。
37. 可能的一种防范方式，就是要训练电脑网路时时注意自己是否出错。如同苏格拉底的教诲，懂得说“我不知道”正是通往智慧的重要一步。人类智慧如此，电脑智慧亦然。所有演算法都该学习的第一课，正是自己也可能犯错。那些演算法宝宝应该要学会怀疑自己，不确定就要承认不确定，也必须遵守“预防原则”。
38. 关于鼓励 AI 表达自我怀疑、寻求他人意见、承认自己的错误，工程师在这几个面向都已经取得长足的进展。
39. 现代人类创造了两种主要的政治制度：大规模民主制度、大规模极权制度。第三部〈电脑政治学〉要谈的，就是这些制度可能如何应对这个非生物、又容易出错的电脑网路。

### 第三部 电脑政治学

#### 第９章 民主制度──我们还能对话吗？

1. 文明的诞生，始于官僚制度与神话故事的结合。如今，电脑网路已成为一种新型态的官僚制度，比起过去所有人类官僚制度都更为强大，也更为无情。电脑网路也可能创造出存在于电脑间的神话故事，其概念之复杂难解，将远远超越所有人造的神祇。但这电脑网路虽然有无穷的潜力，却也可能使人类文明走向毁灭。
2. 这些工业重地的帝国主义思想家、政治家与政党一致认为，唯有帝国的形式能够撑得起工业社会。原因在于，不同于相对自给自足的农业社会，新兴的工业社会十分依赖外国的市场与原物料，唯有帝国能够保证满足这样的需求。帝国主义者担心，如果国家走向工业化，但没征服任何殖民地，一旦碰上更无情的竞争对手，就无法取得重要的原物料与市场。
3. 于是，英国、俄国这种已经属于帝国体制的工业国家，开始大幅扩张，至于美国、日本、义大利、比利时这些国家，也显得兴致勃勃。工业帝国的军队配备了量产的步枪与火砲，以蒸汽动力来运送、以电报技术来指挥，从纽西兰到朝鲜，从索馬里到土库曼，横扫全球。
4. 关于如何建立工业社会，斯大林主义与纳粹主义也是两场无比昂贵的实验。斯大林与希特勒这样的领导者认为，唯有极权政体能够充分驾驭工业革命释放的巨大力量。在他们看来，想在工业世界生存，就必须用极权体制来控制一切的政治、社会与经济层面，而第一次世界大战这场史上首见的“总体战”就是明证。他们还声称工业革命就像是一座熔炉，熔去了所有先前社会结构的人类缺陷与弱点，有机会创造出完美的新社会，成员都是纯净完美的超人类。
5. **二十世纪末，局势已经相当明显，帝国主义、极权主义与军国主义绝不是建立工业社会的理想方式**。虽然自由民主制度有著种种缺陷，却仍然是更好的选择。 自由民主制度的一大优势，就在于拥有强大的自我修正机制，能避免过度狂热，也保留了发现自身错误、改变行动方针的能力。由于我们无法预测新的电脑网路究竟会如何发展，如果想要避免二十一世纪走向灾难，最好的办法就是维持自由民主制度的自我修正机制，让我们在发展的过程中，随时发现并修正各种错误。
6. 民主原则之一：为善
    1. 第一项原则就是为善。如果电脑网路要搜集关于我的资讯，必须是用来帮助我，而不是操弄我。目前，已经有许多传统官僚体系（ 例如健康照护体系）成功采用了这项原则。
    2. 或许我们并不希望让老板知道我们怀孕，不想让同事知道我们得了癌症，不想让另一半知道我们有了外遇，不想让警察知道我们会使用娱乐性药物；但我们会向自己的医师坦诚这一切资讯，方便让医师照顾我们的健康。要是医师把这些资讯卖给第三方，非但不道德，还根本就犯法。 此外，就律师、会计师或心理咨商师手上的资讯而言，大致上也是如此。
7. 民主原则之二：去中心化
    1. 如果成立一个国家医疗数据库，搜集公民资讯来提供更佳的健康照护、疫情预防、或新药研发，当然是对人民极为有益。但要是再把这个数据库与警方、银行或保险公司的数据库整合，就会变得极为危险。虽然这样可能让医师、银行业者、保险业者与警方做事更有效率，但这种超高效率也很容易铺平一条通往极权的道路。民主制度想要存活的话，效率低一点并非坏事。如果想要保护个人的自由与隐私，最好还是别让警察和上司对我们无所不知。 此外，让许多数据库与资讯管道独立存在，也有助于维持强大的自我修正机制。自我修正机制需要让不同机构制度达到互相制衡的效果。像是政府、法院、媒体、学界、民间企业、以及非政府组织，个别都可能犯错、可能贪腐，因此都该能够由其他机构来监督制衡。
8. 民主原则之三：相互性
    1. 第三个民主原则是相互性。**如果民主制度打算加强对个人的监控，就必须同时加强对政府与企业的监控**。 税务或福利机构搜集更多关于民众的资讯，并不一定是坏事，这可能有助于提升税务与福利制度的效率与公平。但我们不希望看到的是：所有资讯的流动都只是由下而上。例如俄罗斯联邦安全局搜集了大量关于俄罗斯公民的资讯，但公民却对联邦安全局、乃至普丁政权整体的内部运作，几乎一无所知。
    2. 民主需要平衡。**政府与企业常会研发各种应用程序与演算法，做为由上而下的监控工具**。但演算法也可以轻松变成由下而上的强大工具，提升政府的透明度与问责制，揭露企业贿赂与逃税行径。要是在他们更了解我们的时候，我们也能更加了解他们，双方就能保持平衡。
    3. 相互监督是维持自我修正机制的另一项重要因素。要是公民能更了解政治人物与执行长都在做些什么，也就更容易追究责任、纠正错误。
9. 民主原则之四：给人自主空间
    1. 第四项民主原则，**则是监控系统必须永远保留让人改变与休息的空间**。在人类历史上，压迫的形式分成两种极端：**一种极端是剥夺改变的能力，另一种极端是剥夺休息的机会**
    2. 例如印度教种姓制度，依据神话将人类划分为刻板的种姓；如果有人想要改变自己的种姓，简直就像是要挑战众神、违抗宇宙的正确秩序。
    3. 在另一个极端，现代极权政权（ 例如斯大林统治下的苏联）则相信人类能有几乎无穷的改变潜力，极权领袖觉得只要透过无情的社会控制，就连各种根深柢固的生物特征（ 包括自我中心、对家庭的依附）也能连根拔起，创造出新的社会主义人类。
    4. 史上充满各种刻板僵化的种姓制度，总是在否定人类改变的能力；史上也充满许多独裁者，完全不给人自主选择的机会，妄图捏塑人类，如同捏塑黏土一般。要在这两种极端之间找到正确的路，会是一项永无止境的任务。要是我们真的决定让国家健康照护制度对我们拥有庞大的支配权，就必须同时为它安排强大的自我修正机制，才能避免演算法太过刻板僵化、或是要求太过苛刻。 就业市场不稳定，会破坏民主 新资讯技术对民主造成的危险，还不只有监控这件事而已。
10. 新资讯技术对民主造成的危险，还不只有监控这件事而已。第二个威胁是自动化可能会破坏就业市场稳定，进而破坏民主。
11. 如果三年时间攀升至25%的失业率，就能让一个看似繁荣的民主国家，变成史上最残暴的极权政体，等到自动化在二十一世纪对就业市场引发更大的动荡，世界上的各个民主国家会变成什么样子呢？没人知道就业市场到了2050年（ 甚至是更近的2030年）会变成什么样子，只知道肯定与现在非常不同。从作物收割、股票交易到瑜伽教学，AI 与机器人会让许多专业出现改变。许许多多现在由人类来做的工作，会有一部分、甚至全部由机器人与电脑取代。
    - 这里三年失业率 25% 指的是二战前的德国, 连续三年的高失业率就可以让国家直接滑向极权, 那一个已经极权的政府连续三年会怎么样呢?
12. 有些我们几百年来奉若至宝、觉得属于人类独有的技能，搞不好很容易就能自动化。但也有些我们常常弃若敝屣的技能，其实自动化的难度远远更高。 举例来说，比起运动或社交技能，知识份子常常比较看重智力技能。但是就自动化而言，比起洗碗之类的劳动工作，下棋的自动化要简单多了。
13. 相较之下，没人会觉得洗碗是件多有挑战的事。**但结果发现，电脑要打败西洋棋世界冠军，可比取代一位厨房杂务工简单多了**。当然，自动洗碗机已经发明了几十年，但就算是目前最先进的机器人，也还是没办法在繁忙的餐厅里收拾那些杯盘狼藉，再把精致的盘子与玻璃杯放进自动洗碗机，最后再把洗好的杯盘拿出来摆放整齐。机器人就是还没拥有这种精细的技能。
    - 为什么西洋棋更容易被 AI 掌握呢? 因为西洋棋的未知情况真的太少了(即使围棋也很少), 而厨房杂务工需要处理的未知情况太多了, 一个蟑螂出现, 盐结块了, 电线短路了, 垃圾桶有一个洞需要补等等...
14. 如果从薪水来判断，我们应该会说，社会比较尊敬的是医师、而不是护理师。然而，有些医师主要的工作就是搜集医疗数据、做出诊断、提供治疗建议，**比起这种医师，护理师的工作其实更难自动化**。因为那些医师工作的本质就是模式辨识，而要从数据中找出模式，正是 AI 比人类做得更好的事情之一。相较之下，距离发展出足够的技能来完成各种护理工作（ 像是给伤患换绷带、给哭闹的小孩打针），AI 还有很长的路得走。
15. **==第二个常见但错误的假设，则是认为唯有人类拥有创造力，所以只要是需要创造力的工作，就很难自动化==**。但在西洋棋领域，电脑已经远比人类更有创造力。许多其他领域也可能慢慢变得如此，从作曲、证明数学定理，再到写出像是我这本书籍。我们对创造力的定义，通常就是能够找出模式、再打破模式。**若真如此，既然电脑如此善于辨识模式，在许多领域也就很可能会变得比人类更有创造力。**
16. **==第三个错误的假设，则是认为电脑无法取代人类那些需要情绪智慧（EQ）的工作，包括心理咨商师到教师等等==**。然而，这种假设是否属实，要看我们对所谓 EQ 的定义。如果指的只是要正确辨识情绪、做出最佳的反应，那么就连在 EQ 这一块，电脑的表现也可能远远超过人类。
17. 这个问题目前已经有了部分的答案。民主政治在2010年代与2020年代初期，经历了一场澈底转型，展现出来的可说是保守派政党的自我毁灭。 过去有许多世代的时间，民主政治就是保守派政党与进步派政党之间的对话。看著人类社会这个复杂的制度，进步派高喊：“这真是一团乱，但我们知道怎么解决。让我们试试看！”保守派则反对说：“是一团乱没错，但一切还能运作。不要乱插手。想要去解决，只会把事情搞得更乱。”
18. 但到了2010年代与2020年代初，许多民主国家的保守派政党遭到川普这样的非保守派领导者劫持，摇身一变，成了激进的革命政党。像美国共和党这样的新型态保守派，非但没有尽力保护既有的体制与传统，反而表现出高度的质疑。例如，对于科学家、公务员和其他为国服务的菁英份子，他们并未表现出传统的尊重，反而流露出蔑视的眼光。同样的，他们也攻击像是选举这样的基本民主制度与传统，拒绝认输，也不肯坦然移交权力。
19. 要是保守派与进步派都能抗拒进行极端改革的诱惑，民主制度就能证明自己其实非常灵活。**靠著自我修正机制，就让民主政体比其他僵化的政体，更能安渡科技与经济的汹涌波涛**。因此，在面对后续的电脑革命时，曾在动荡的1960年代活下来的民主国家，适应能力也就远胜于东欧的共产政权或南欧与南美的法西斯政体。
20. 民主的自我修正机制要能发挥作用，得先知道自己到底该修正些什么。对独裁政权来说，把自己搞得高深莫测是件好事，随时都能把责任撇得干干净净。但对民主政权来说，把自己搞得高深莫测，就是个致命的错误。要是公民、立法者、记者与法官都无法了解国家的官僚体系如何运作，就会无力监督，接著也就会失去信任。
21. 随著社会把愈来愈多决定交给电脑和演算法来处理，民主的自我修正机制、透明度与问责制，都会受到挑战。如果演算法如此高深莫测，民选官员又要怎样才能监督？**==所以已经有愈来愈多人要求保障一项新的人权：得到解释的权利。==**
    - [[无穷的开始|努力寻找更好的解释]]
22. 苏莱曼写道：“我们人类面临了全新的挑战：未来的新发明，会不会完全超越我们理解的范围？在以前，就算得要补充极大量的细节，创作者还是能解释某件事物是如何运作、背后有什么原理。但现在愈来愈不是这样了。许多科技与系统已经变得如此复杂，没有任何人有能力真正理解……在 AI 领域，那些正在走向自主的神经网路，目前就是无法解释。你没有办法带著人一步一步走过整个决策过程，准确解释为什么演算法会做出某项特定预测。工程师没办法看穿那些机壳下面发生了什么事，没办法轻松而详尽的解释各种事情如何发生。GPT-4、AlphaGo 都是一个又一个的黑盒子，其输出与决定，就是基于各种不透明、又极其复杂的微小信号链。”
23. 出现这种难以理解的非人类智能，将会让民主受到损害。要是有愈来愈多关于人民生活的决定，都是在黑盒子里完成，选民无法理解、也无法挑战那些决定，民主也就会停止运作。特别是如果这些关键决定不仅影响个人生活，甚至是牵涉联准会利率升降这样的集体事务，却都是由高深莫测的演算法来下决定，世界会变成什么模样？人类选民或许还是会继续投票选出人类总统，但这不就是行礼如仪、做做样子而已吗？
24. 遗憾的是，在演算法逐渐主导世界的现在，虽然魅力领袖绝对有其长处，但一个人不论多么能鼓舞人心或才华横溢，单凭己力绝不可能破解演算法究竟如何运作，也就无法确保演算法真正公平。问题在于，演算法的决定背后都参考了大量的数据点，但人类却很难有意识的对大量数据点进行反思，做出权衡。我们就是比较喜欢面对单一的数据点。所以如果碰上复杂的问题（ 不管是申请贷款、疫情肆虐、或是战争爆发），我们常常希望能找出某个单一理由，就采取特定的行动，而不顾其他考量。这就是所谓的[[fallacy-of-the-single-cause|单因谬误]]。
25. 民主制度的去中心化性质、以及强大的自我修正机制，虽然能够抵御极权制度，但也让维持秩序的难度增加。**民主制度的运作需要满足两项条件：要能针对关键议题进行自由的公共对话；要能维持最低限度的社会秩序与制度信任**。自由的对话绝不能落入无政府状态。特别是要处理紧急而重要的问题时，公共辩论的进行必须有一套公认的规则，也必须有合法的机制能够达成某种最终决定（ 就算没有办法让所有人都满意）。
26. 每次有新的群体加入对话，除了会带来新的观点与关注，也常常会推翻关于如何辩论、如何做出决定的共识，于是就得重新协商整套的讨论规则。**这样的发展可能很正面，能让整个民主制度更具包容性，毕竟民主就是该修正过去的偏误，也让过去权利遭到剥夺的人重新参与公共讨论**。然而就短期而言，这种做法会造成干扰与不和谐。而且，**如果对于如何公开辩论、如何做出决定迟迟无法达成共识，结果得到的就不是民主，而是无政府状态。**
27. 等到2020年代初，情况继续恶化。根据一项2020年的研究评估，所有推文已经有43.2%是由机器人程序产生。  **数位情报机构 Similarweb 在2022年一项更全面的研究则发现，在推特的使用者当中，机器人程序可能只占5%，但却在“发布到推特上的内容当中，占了20.8%到29.2%”**。
    - 比例这么高吗?　
28. 另一种让人担心的趋势则在于内容。最早使用机器人程序来影响公众舆论的时候，靠的只是它能大量传播讯息，以量取胜。当时的机器人程序只能等人类制作出内容，再加以转发或推荐，无法自行创造新的想法，也无法与人类建立亲密感。然而，像是 ChatGPT 这种全新的生成式 AI，完全能够做到这些事。
29. 如果有数百万、甚至是数十亿个具备高度智能的机器人程序，不只能写出极具说服力的政治宣言、创造出深伪的图像与影片，还能够赢得我们的信任与友谊，民主辩论会变成什么模样呢？ 要是我在网路上与 AI 进行政治辩论，想要改变 AI 的观点只会是徒劳；因为 AI 是个无意识的实体，并不是真的关心政治，也不能真的投票选举。然而，我与 AI 谈得愈多，它就愈了解我，于是能够得到我的信任，不断改进它的论点，也慢慢改变了我的观点。
30. 在这种要争夺人心的战斗中，亲密感是一种极为强大的武器。在过去，各个政党虽然能够引导我们的注意力，却很难大规模产生亲密感。广播设备虽然能让几百万人听到领导者说了什么，却无法和听众变成朋友。但如今，政党（ 甚至是外国政府）却能部署一支机器人程序大军，和几百万公民建立友谊，再运用这样的亲密感，影响公民的世界观。 到最后，演算法不但成了对话里的成员，更开始操弄著对话。社群媒体允许新加入的人类群体挑战过去的辩论规则，但现在要协商新规则的时候，已经不是由人类来掌控，而是正如我们前面对社群媒体演算法的分析所示，常常是由演算法来订定规则
    - 政治家更容易欺骗选民.
31. 如果操弄人心的机器人程序、以及我们无力监督的演算法，开始主导公共对话，民主辩论制度就可能在我们最需要它的时候澈底崩溃。面对新科技迅速发展，人类正需要做出各种重大决定，但公共领域却可能被电脑生成的假新闻淹没，公民无法分辨自己辩论的对象是人类还是机器，而且就连最基本的讨论规则或事实，都无法达成共识。这种处于无政府状态下的资讯网路，既不能找出真理真相，也无法维持秩序，注定撑不了多久。而一旦落入无政府状态，让人民宁可牺牲自由来换取某种确定性，下一步或许就会见到独裁政权的产生。
32. **民主制度能够、也应该做的，就是对 AI 加以规范，避免 AI 以假人散播假新闻，来污染人类的资讯圈。**
    - 没有意义, 这个太难了.
33. 用来处理伪币的道理，用来处理假冒人类的问题，应该也同样适用。要是政府在伪币的处理上态度果决，认为有必要保护人民对货币的信任，此时也应该以同样果决的态度，保护人民对人类的信任。
34. 而且，法律不但应该禁止深伪特定的真实人物（ 像是制作假的美国总统影片），同时还应该禁止让非人类行为者冒充为人。如果有人说这种严格的规定侵犯了言论自由，就该提醒他们，**机器人程序并没有言论自由**。如果今天是要禁止人类使用公共平台，这会是很敏感的作为，民主制度对于这种审查制度也该格外谨慎。但禁止机器人程序就是个再简单不过的议题，这不会侵犯任何人的权利，因为机器人程序并不拥有任何权利。
    - 不如让 ai 有改变能力自我改变(自我成长)来的更现实, 也就是说 AI 必须能自我成长.
35. 运用演算法来筛选真实的人类观点时，绝对需要小心谨慎；而我们优先可以做的，是阻止演算法刻意散播愤慨的情绪。至少对于演算法是依据怎样的原则来进行筛选，企业应该要保持透明。要是企业用愤慨来吸引我们的注意力，就得明白坦承自己的商业模式、以及背后可能的任何政治链接。而如果演算法会系统性的下架与该企业政治意图不一致的影片，使用者也该有权得知。
36. 人类史上大部分时间，资讯技术都还不够先进，无法进行大规模的政治对话，也就培养不出大规模的民主制度。在过去，要是有几百万人分布于几万平方公里的土地，并没有工具能够即时讨论各种公共事务。 但讽刺的是，**现在反而是因为资讯技术变得太先进，而可能让民主制度到此为止**。要是高深莫测的演算法主导了政治对话，特别是去压抑有理有据的主张、并刻意煽动仇恨与混淆视听，公众讨论就无以为继了。**要是民主制度真的崩溃，应该并不是出于技术发展上的必然，而是因为人类没能管好新技术的发展。**

#### 第10章 极权主义──权力归于演算法？

1. “我们”人类其实有超过半数，就活在专制或极权政权之中，而且这些政权成立的时间多半是在电脑网路兴起之前。如果真的要了解演算法与 AI 对人类的影响，除了该问这会对美国与巴西这样的民主政体有何影响，也得看看这对于中国共产党与沙乌地王室有何意义。
2. 流向中心的资讯愈多，处理也就愈困难。极权统治者与极权政党常常会犯下一些昂贵的错误，而极权制度又欠缺能够发现并修正这些错误的机制。相较之下，民主制度是将资讯与决策权分散到许多不同的机构与个人手中，不但能更有效率的处理大量数据，而且如果某个机构做了错误的决定，也可能由其他机构提出修正。 然而，机器学习演算法的兴起，可能正是全球各地斯大林们已经等了太久的好消息。AI 能让科技力量的天平，开始倒向极权制度那一方。就事实来说，人类如果被大量数据淹没，往往就会不知所措，并开始犯错；但 AI 被大量数据淹没的时候，却是效率愈来愈高。于是，AI 似乎也倾向将资讯与决策都集中在一处。
3. 想把所有资讯与权力都集中在一个地方，这曾经是二十世纪极权政权的致命弱点，但到了 AI 时代，却可能成为决定性的优势。与此同时，我们前面也提过，AI 还能让极权政权建立全面监控制度，而使人民几乎不可能反抗
4. 等到政府就是区块链51%的使用者，除了能控制这个区块链的现在，甚至还能控制这个区块链的过去。从古至今，专制者一直都希望拥有改变过去的权力。像是罗马皇帝就经常下令进行记忆抹杀（damnatio memoriae）：把对手与敌人从世人的记忆里抹除。例如皇帝卡拉卡拉，在暗杀了弟弟兼王位竞争对手盖塔之后，就开始抹除所有关于盖塔的记忆。刻有盖塔名字的铭文被凿除，印有盖塔肖像的硬币被熔化，就连提到盖塔的名字都会被判死刑。
5. 虽然 AI 有许多方式有利于中央集权，但是专制政权与极权政权碰上 AI，也并非无往不利。 **首先，独裁政权并没有控制非生物行为者的经验。专制资讯网路是以恐怖统治为基础，但电脑并不怕被关或被杀。**
6. 讲了一个会冒犯到普丁的笑话，又或者批评了普丁领导的团结俄罗斯党多么腐败，普丁政权能对这个聊天机器人程序做什么吗？ 俄罗斯联邦安全局的特工可没办法把这个程序抓起来关、没办法折磨它、也没办法威胁它的家人。普丁政府当然能够封锁或删除这个机器人程序，并且试图去找出并惩罚写出这个程序的人，但总之，要比平常教训人民困难多了。
7. 特别有趣的一点在于，正如欧威尔在《[[一九八四]]》所解释的，极权资讯网路常常都需要依赖双言巧语（doublespeak），例如俄罗斯就是个自称民主、实质独裁的国家。俄罗斯入侵乌克兰，是1945年以来欧洲最大规模的战争，但俄罗斯官方定调这是一场“特别军事行动”；如果有人称之为“战争”就会触犯刑法，最高可处三年以下有期徒刑，或科五万卢布以下的罚金。
    - 双言巧语并不是指双重思想, 这是两个东西, 神奇. 双言巧语（英语：doublespeak）是一种故意扭转或隐藏原意的修辞法，常为政治组织、军队、企业或公关宣传领域使用，有时候可以视为一种委婉或政治正确的表达方式，但在用于政治组织、军队或企业的场合，现代通常称为“双言巧语”。更符合中国的的词是"春秋笔法".
8. 要是极权政府采取了某项极为失败的政策，后来才又改变心意，往往就会把失败推到别人头上，以掩饰自己的过错。人们又常常是经过惨痛的教训，才学会应该忘记那些会给自己带来麻烦的事实。但我们要怎样才能训练聊天机器人程序，要它赶快忘记那些今天被批得一文不值的政策，其实短短一年前还是国家的官方立场？这会是独裁政权难以应对的重大技术挑战，特别是聊天机器人程序还在愈来愈强大、也愈来愈不透明。
9. **==就长期而言，极权政权还可能遇上更大的危险：演算法并不是去批评这些政权，而是直接控制了这些政权。==**
10. 纵观历史，专制者最大的威胁常常来自下属。第5章〈决择〉就提过，并没有哪个罗马皇帝或苏联总书记是被民主革命赶下台，而都是被下属推翻、或成了傀儡。要是二十一世纪的专制者把太多权力交给电脑网路，就有可能成为电脑网路的傀儡。**==独裁者最不乐见的，就是创造出比自己更强大的玩意，或是自己控制不了的强大力量==**
11. 为了说明，请让我举一个有点天马行空的臆想实验当例子，有点像是伯斯特隆姆那个回纹针宇宙末日的极权政体版本。想像时间来到2050年，凌晨4点，伟大领袖被“监控与安全演算法”紧急叫醒。“伟大的领袖，我们遇上紧急状况。我经过计算几兆个数据点，发现了绝对无误的模式：国防部长打算在今天早上，对您发动暗杀夺权。暗杀小队已经准备就绪，等他下令。但只要您一声令下，我就会发动精准攻击，将他肃清。” “可是国防部长是我手下最忠诚的人，”伟大领袖说：“他昨天还跟我说──” “伟大的领袖，我知道他对您说了什么，这世上没有什么是我没听到的。但我也知道他后来对暗杀小队说了什么，而且我在数据里一直发现叫人不安的模式，已经追踪了好几个月。” “你确定你不是被深伪数据给唬弄的吗？” “恐怕我所依据的数据都是100%真实的，”演算法说：“我都使用专门的侦测深伪演算法检查过。虽然我可以详细解释为什么我知道这不是深伪数据，但可能得花上几个星期。要不是我已经确定，绝不想惊扰您，但是所有数据点都指向一个绝对的结论：一场政变就在眼前。除非我们现在立刻采取行动，否则暗杀小队一小时之后就会抵达。但只要您下令，我就会肃清叛徒。” 伟大领袖让监控与安全演算法拥有这么大的权力，也就让自己进退两难。**要是他不相信演算法，就可能被国防部长暗杀；要是他相信演算法、肃清国防部长，就可能成了演算法的傀儡。**
12. **要是演算法真的能发展出以上假设的这些能力，独裁政权成为演算法傀儡的风险，其实远高于民主政权**。如果是像美国这样的分布式民主体系，即便是超越马基维利式君王等级的 AI 也很难夺权；这种等级的 AI 就算学会了如何操弄美国总统，还是得面对国会、最高法院、州长、媒体、各大企业、各种非政府组织的反对。举例来说，如果参议院发动冗长发言来阻挠议事，演算法能怎么办？ 国家的权力如果高度集中，夺权的难度可就低得多。要是所有权力集中于一人之手，只要控制谁能接触这位专制者，就等于控制了专制者，也就等于控制了整个国家。AI 只要学会操弄一个人，就能成功劫持整个体制。一个典型的例子就是罗马皇帝提比略，执政后期成了禁卫军队长塞扬努斯的傀儡。
13. 如果政权仰赖的是人类（ 像是塞扬努斯与马克罗），高明的独裁者就能操弄他们互相对抗，而让自己稳居高位。斯大林的大清洗正是为了这个目的。但如果政权仰赖的是一套力量强大但高深莫测的 AI，所有资讯都由 AI 来搜集与分析，人类独裁者也就有可能失去一切权力。这位独裁者就算依然身在首都，也像是被隔离在一座数位孤岛，只能受到 AI 的控制与操弄。
    - AI 更可信呢? 还是忠实的舔狗更可信呢? AI 会被"权谋术"控制吗? 或者 AI 对控制更多人类会有"兴奋"感吗? 如果给 AI 下达的命令是"辅助我实现对国家的完全控制", 这样一个命令会带来 AI 对独裁者的控制吗?
14. 比起成为演算法的傀儡，接下来几年里，这个世界上的独裁者还会碰上更迫切的问题。**目前的 AI 系统都还没有大规模操控政权的能力，但极权政权却已经出现了太过信任演算法的危机**。民主政权假设任何人都可能犯错，而极权政权却假设执政党或最高领导人永远是对的。基于这种假设而建立起的政权，习于相信领袖是天纵英明的，引领的方向绝对正确，因此没要必创造强大的自我修正机制，来监督规范那位天选之人。
15. **==独裁者一向面对的问题，就是自我修正机制薄弱，而且又得面对下属尾大不掉的威胁，而 AI 的兴起又可能让这些问题变得更为严重==**。所以对独裁者来说，电脑网路其实造成了一个令人无比苦恼的两难困境。独裁者如果想要摆脱尾大不掉的人类下属，可以选择信任理论上绝对正确的资讯技术；但这种时候，他们就可能成为资讯技术的傀儡。而如果独裁者想要成立一个人类机构来监督 AI，就得小心，这个机构对独裁者的权力也会造成限制。

#### 第11章 矽幕──全球帝国、或是全球分裂？

1. 然而这是个紧紧相连的世界，一个国家的决定，就可能对其他国家产生深远的影响。AI 可能造成最严重的危险，有些并不在于某一个社会的内部反应，而在于许多社会互动形成的动态，例如导致新的军备竞赛、新的战争、新的帝国扩张。
2. 新电脑网路崛起之后，将会怎样改变国际政治的形态？除了各种末日场景（ 例如独裁 AI 发动核战，或是恐怖 AI 催生致命全球疫情），电脑网路对目前的国际体系还构成两大挑战。**第一个挑战是：由于电脑网路让资讯与权力更容易集中于单一中央枢纽，人类可能进入一个新的帝国时代**。整个世界就这样落入几个帝国、或甚至是单一帝国之手，而且控制的强度远高于当初的大英帝国或苏联帝国。东加、吐瓦鲁与卡达又将会从独立国家变回殖民地，就像五十年前一样。 **第二个挑战是：一道新的矽幕可能让人类分裂，分属于敌对的数位帝国。随著每个政权对于 AI 一致性问题、独裁者的两难、以及其他技术难题，提出了不同的答案，就可能各自创造出独立又非常不同的电脑网路**。在不同的网路（ 以及这些网路所控制的人类）之间，互动的难度将会愈来愈高。卡达人可能是生活在伊朗或俄罗斯网路里，东加人可能是生活在中国网路里，而吐瓦鲁人则可能是生活在美国网路里，每个网路的生活经验与世界观都大异其趣，于是几乎无法沟通，也难以达成共识。
3. 想要跨越矽幕取得资讯，愈来愈困难。中国与美国分属两侧，俄罗斯与欧盟各属两方。此外，矽幕两侧所用的数位网路与程序码也渐行渐远，各有不同的规范、各有不同的目的。
4. 新帝国之间竞争愈激烈，就愈可能发生武装冲突。当初美苏之间的冷战从未升级成直接的军事对抗，主要得归功于“保证同归于尽”的原则。但 AI 时代冲突升级的危险更大，因为网路战与核战就是有著本质上的不同。 第一，网路武器能做到的远比核弹更多。网路武器除了能瘫痪敌国的电网，还能摧毁秘密研究设施、干扰敌方的感测器、撩拨政治丑闻、操纵选举，又或是骇入智慧型手机。而且这一切都能做得悄无声息，不会有什么蘑菇云或火焰风暴宣告著攻击，也不会出现从发射台到目标之间的明显轨迹。
5. 第二项关键差异，在于可预测性。冷战像是在下一盘超理性的棋，正因为核武冲突的破坏太过明确，也就让发动战争的念头相对极低。但网路战就少了那份明确。没有人真的知道对方在哪里植入了逻辑炸弹、特洛伊木马和恶意软体。也没有人能确定自己的武器在需要的时候，会不会无法发挥作用。中国下令发射飞弹的时候，真的能发射出去吗？搞不好美国已经骇进了飞弹或指挥系统？而美国的航空母舰真的能顺利出航吗？还是会离奇关机或原地打转？
6. **俄罗斯的入侵行动，除了逼迫乌克兰全面提升战备，甚至逼得许多欧洲国家也增加了自己的军事预算。** 军国文化在俄罗斯等地再现，加上全球研发著前所未见的网路武器与自主武器，就可能将我们带进一个新的战争时代，情况比过往都更为严峻。 普丁这些领导者在战争与和平议题上所做的决定，又是取决于他们对历史的理解。也就是说，正如太过乐观的历史观可能是危险的幻想，太过悲观的历史观也可能弄假成真、带来毁灭。
    - 一直不理解普京为什么要入侵乌克兰.
7. 在2022年发动对乌克兰的全面攻势之前，普丁就常表达自己的历史定见，认为俄罗斯与外敌陷在一种永无止尽的纠缠，而所谓的乌克兰民族只是这些外敌捏造的想像。**2021年6月，普丁发表了一篇五千三百字的文章，题为〈论俄罗斯人与乌克兰人的历史统一〉，否认有乌克兰民族的存在，并认为是外国势力一再试图透过扶植乌克兰分离主义，来削弱俄罗斯**。 虽然专业的历史学者否认这些说法，但普丁似乎是真心相信这套历史叙事，于是让他在2022年的政策首要目标，成了入侵乌克兰，而不是为俄罗斯公民提供更好的健康照护、或是带头提出监管 AI 的全球倡议。
    - 很好奇, 为什么要通过历史来论证一个国家的存在, 如果基于这个论证的话, 任何地区都可以找到独立的理由.

### 结语

1. 我既非政客、也非商人，更没有这些职业需要的天赋。但我确实相信，如果能够了解历史，就更能掌握如今的技术、经济与文化发展；更重要的是，有助于改变各种事项在政治上的优先顺序。政治这回事，有很大程度就是要排出优先顺序，例如：我们是不是该削减健康照护预算、增加国防开支？现在更迫切的安全威胁，究竟是恐怖主义还是气候变迁？我们是该把重点放在收复故土，还是与邻国建立共同经济区？ 决定了政治上的优先顺序，就会影响公民怎么投票、商人关心什么议题、政治人物想要有怎样的名声。而我们会排出怎样的优先顺序，往往就是由我们对历史的理解而决定。
2. 我们绝不该认为人类的互动都只是零和的权力斗争；在放下这种想法之后，不仅能够对过去有更全面、更细致的理解，也能对未来感觉更有希望，态度更具建设性。 如果权力是唯一的现实，要解决冲突也就只能靠暴力了。民粹主义与马克思主义都相信，人类的观点是由他们所拥有的特权来决定，如果要改变人民的观点，首先就得剥夺他们的特权──通常也就得透过暴力。然而，人类其实是想知道真理真相的，所以还是有机会透过交谈、承认错误、接受新想法、以及修改我们所相信的故事，而让至少部分的冲突得以和平解决。这正是民主网路与科学机构制度的基本假设，这也是本书写作背后的基本动机。
3. **好消息是，只要我们放下自满、不要绝望，就能够打造有制衡机制的资讯网路，不让权力失控**。要做到这点，并不需要发明其他的奇迹技术，也不需要想出过去世代都想不到的天才主意。想要打造更有智慧的网路，需要的只是我们放下天真与民粹的资讯观，摒弃想要绝对正确不犯错的幻想，并且认真投入一项困难但平凡无奇的工作：为各种机构制度打造强大的自我修正机制。这或许就是本书想提供的最重要启示。


## 笔记

### 理解
- 我认为作者有能力把书中内容再压缩一半, 整体上书中的内容感觉并不新颖, 至少对我来说并没有足够新颖. 书中的重点是信息并不能发现真相, 不管有多少信息都无法保证一定能发现真相或真理. 而更重要的是如何解读信息和信息的流转; 不同的流转带来了不同的制度模式, 民主整体的信息处理更分散, 而独裁整体信息处理会更集中. 用"信息"视角来解释两种政治制度, 对信息有这不同的处理方式, 这也导致了在 AI 的加持下面临这不同程度的问题. AI 导致民主国家社会更难达成共识, 甚至社会因为流言和阴谋论滑向专制或独裁; 而在独裁国家 AI 可能更高效的实现对社会的控制, 但因为独裁国家的决策模式 AI 反而可能会反过来控制独裁者, 最后成为 AI 是国家的真正最高长官. 在我看来书中大部分的内容, 还只是罗列已经出现的各种问题和可能出现的问题, 书中并没有给出一个实际的解决方案.
- 我认为 AI 在独裁国家的使用主要方向并不是生成谣言或信息, 而是集中在监控. 越是悠久的独裁国家就越是没有一个固定理念, 所有都是可以根据最新的最高领导人进行修改的, 之后篡改或隐藏历史文件符合当前的意识形态就可以了, 比如清朝的弘历就通过修"四库全书". AI 生成的内容能快速跟进意识形态的转变, 而且我对于独裁国家意识形态大部分都是谎言, 为了实现 AI 生成符合意识形态的内容, 并且不出现问题可以用来生成的语料实际上并不多, 因为历史文件是不能作为语料训练的(30 年的文件可能已经不符合现在的意识形态了宣传要求了). 基于以上原因 AI 可能用于审查可能比用于宣传更有效果, 而且效率也更高, 当然 AI 不一定能发现最新的语言或行为问题, [[20220715143617|隐喻]] 产生的速度的可能比 AI 学习速度更快.
- 我认为 AI 对民主国家和独裁国家之间最可能产生的情况是, 独裁国家通过 AI 来影响民主国家, 让民主国家滑向专制政府之后堕落成独裁国家. 这样更符合独裁国家的利益, 并且 AI 也更擅长这些, 因为独裁国家可以轻松实现言论的控制, 可以有效对抗认知作战, 而民主国家很难实现这种对抗, 而且要面对大量的谣言和阴谋论.
- AI 最大的影响在我看来是让更多人变成"怀疑论者"或"阴谋论者", 也就是不相信任何东西, 对任何秩序的建立都持反对意见. 而这种态度会导致良好的国家制度不断腐化, 根据 "[[权力如何崩坏人性]]" 心理变态的人更希望得到权力, 在一个无法正常运转的制度下, 独裁者就会产生.
- 如何有效的控制 AI? 我的结论是没有办法, 就像"契诃夫之枪"一样"第一幕挂在墙上的枪，第二幕中一定会发射", 当 AI 出现后, 想阻止他是不可能的. 从商业角度来说, 恶性竞争或劣币驱逐良币的机制下, 只要有人突破下限所有人都会不断的突破下限. 当然我相信社会绝大多数人还是希望秩序存在的, 自然会出现不同的使用方式, 也会找 AI 的正确使用方法. 比如社交媒体会提供 AI 分析信息可靠度这样的工具.
